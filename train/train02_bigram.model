terms such	0.076923
and 2500	0.001445
for disambiguation	0.003610
type validity	0.071429
semi-supervised learning	0.500000
or just	0.004505
Hulth uses	0.333333
PARRY ,	1.000000
of algorithms	0.000891
Hulth used	0.333333
program would	0.045455
-LRB- MPE	0.002710
how strong	0.034483
to found	0.001328
generate form	0.055556
edges are	0.142857
help automatic	0.111111
of hand	0.000891
text-understanding	0.000029
indicates that	1.000000
Input for	0.500000
compare generated	0.142857
typically evaluated	0.055556
Iraq and	0.500000
rates even	0.125000
special ink	0.200000
AT&T	0.000029
for Reading	0.003610
German capitalizes	0.250000
defines components	0.500000
the isolation	0.000692
boards and	1.000000
controversy	0.000029
WER -RRB-	1.000000
University ,	0.111111
around 2	0.125000
Harvey	0.000029
subscription department	1.000000
Recall measures	0.333333
role the	0.250000
, making	0.000561
Office -LRB-	1.000000
distortions	0.000029
question understanding	0.023810
or ,	0.004505
underlying formal	0.333333
The genetic	0.005208
meteorologist	0.000029
see for	0.050000
bottom-up parsers	1.000000
or `	0.004505
financial and	0.250000
Individuals with	1.000000
recognize text	0.111111
processing natural	0.018519
topics ,	0.142857
purposes ,	0.250000
Foucault became	0.333333
to lower	0.001328
of good	0.000891
1954 on	0.333333
L.	0.000029
wrong	0.000029
verb :	0.076923
closest counterparts	0.500000
identify keyphrases	0.083333
CFG	0.000029
of emails	0.000891
The shorter	0.005208
, 5000	0.000561
of giving	0.000891
general personal	0.045455
nonsensical	0.000029
lexicon required	0.111111
language document	0.006757
e.g. from	0.017857
underlies the	1.000000
word and	0.016667
infinitive marker	1.000000
platform for	0.500000
a simulation	0.001227
fundamentally different	1.000000
Schroeder	0.000029
additional costs	0.166667
it agrees	0.008547
have limited	0.009615
as consideration	0.003484
equipment was	0.333333
typically given	0.055556
Jabberwacky	0.000029
move items	1.000000
distance to	0.333333
theory for	0.076923
reasoning schemes	0.142857
Asia	0.000029
learning techniques	0.023256
equivalent questions	0.200000
with part-of-speech	0.005464
the advent	0.000692
corpora and	0.090909
1990s .	0.333333
an arithmetic	0.007576
1990s ,	0.333333
dialog that	0.500000
can tell	0.005525
method that	0.062500
after applying	0.083333
whom ?	0.500000
assignment of	0.500000
Message Understanding	1.000000
shift-reduce	0.000029
on written	0.004717
should correspond	0.052632
literature are	1.000000
encourage	0.000029
adapt	0.000029
versus ``	1.000000
printed records	0.083333
; Michel	0.021277
classes Different	0.200000
level features	0.050000
allowable expression	0.500000
this shifting	0.010989
to fine	0.001328
Cuzco	0.000029
disturbed	0.000029
to benefit	0.001328
computers have	0.111111
considered separately	0.111111
goal -RRB-	0.142857
them which	0.052632
document collections	0.027778
arise because	1.000000
, minimum	0.000561
Aggregation	0.000029
, typical	0.000561
this refined	0.010989
an average	0.007576
of corpora	0.000891
Robyn Carston	1.000000
algorithms optimized	0.028571
of Chinese	0.000891
mobile email	0.500000
to -RRB-	0.001328
feeling	0.000029
Type =	1.000000
interactive clarification	0.250000
USMC ,	1.000000
of outputs	0.000891
`` machine	0.005291
Theo	0.000029
speech naturally	0.006579
many aspects	0.019231
time step	0.030303
Meehan ,	1.000000
on integrating	0.004717
simplify	0.000029
even produce	0.037037
wanted to	1.000000
is search	0.002033
the photos	0.000692
, preparation	0.000561
saying	0.000029
Jurafsky and	1.000000
primarily with	0.500000
POS-tagging	0.000029
between text	0.025641
topics or	0.142857
preselects small	1.000000
Such a	0.125000
estimate ,	0.250000
discussion of	0.500000
to adapt	0.001328
spoke the	1.000000
decisions are	0.100000
Computationally ,	1.000000
Jelinek and	0.500000
L'action GRACE	1.000000
Yehoshua Bar-Hillel	1.000000
as information	0.003484
can compensate	0.005525
-LRB- HAMS	0.002710
personal computing	0.250000
deep approach	0.142857
paying attention	1.000000
approach would	0.028571
diversity during	0.250000
complex question	0.041667
systems and	0.008929
`` diversity	0.005291
system should	0.010753
-LRB- some	0.002710
between ``	0.025641
more subjective	0.010526
customer service	1.000000
successive letters	0.500000
section called	0.166667
is easy	0.002033
customers ,	0.500000
what features	0.031250
E. Brill	0.250000
R. Schroeder	0.166667
smaller more	0.142857
require subjects	0.045455
: compare	0.009804
Rhetoric Stylistics	1.000000
customisation	0.000029
-LRB- Dec.	0.002710
for these	0.003610
English phrase	0.027027
on stochastic	0.004717
NLP Handbook	0.021277
systems -RRB-	0.008929
The approaches	0.005208
and assess	0.001445
on Audio	0.004717
they use	0.025000
QUALM	0.000029
k	0.000029
Human languages	0.200000
considered or	0.111111
angry ,	0.500000
angry .	0.500000
they consider	0.025000
tagging -LRB-	0.040000
we hear	0.022222
specifically developed	0.500000
step the	0.066667
Working with	1.000000
answering systems	0.083333
scores that	0.200000
, Larry	0.000561
combined in	0.500000
and ATIS	0.001445
academic	0.000029
a handheld	0.001227
required for	0.142857
handling differences	0.500000
the RCA	0.000692
projection	0.000029
has specialized	0.011905
first of	0.030303
The Turney	0.005208
LexRank applies	0.083333
stationary process	0.142857
Post Office	0.500000
a German	0.001227
<s> According	0.000769
OCR products	0.020408
translator needs	0.142857
The next	0.005208
their corresponding	0.029412
an implementation	0.007576
a part-of-speech	0.001227
and computational	0.001445
'' appears	0.005376
absorbing Markov	0.333333
evaluated in	0.142857
whether medium	0.076923
proper nouns	0.142857
confusability	0.000029
Steven	0.000029
Swedish	0.000029
acoustic signal	0.166667
and Cary	0.001445
mentions -LRB-	0.333333
Ask.com .	1.000000
Facebook	0.000029
more fine-grained	0.010526
parsers and	0.076923
existing words	0.200000
NLP methods	0.021277
Carla Willig	1.000000
dialing -LRB-	1.000000
they join	0.025000
reCAPTCHA system	1.000000
Hansard corpus	1.000000
speeches ,	1.000000
the envelope	0.000692
them into	0.052632
the degree	0.000692
product of	0.142857
at language	0.014706
beings	0.000029
we take	0.022222
free of	0.250000
Xerox ,	0.500000
<s> DARPA	0.000769
<s> Black-box	0.000769
summarization often	0.020000
heuristic final	0.333333
AFTI -RRB-	1.000000
each such	0.022222
rates greatly	0.125000
, disturbed	0.000561
equivalence relations	0.500000
are free	0.004149
manipulate .	0.333333
solutions .	0.500000
applications fall	0.040000
and Reinvestment	0.001445
Politics -LRB-	1.000000
approximating sentence	1.000000
ambiguity because	0.125000
or adjective	0.004505
Documents ''	1.000000
word boundary	0.016667
more power	0.010526
the reduction	0.000692
reviewed and	1.000000
evaluation Black-box	0.018519
<s> ATNs	0.000769
systems simply	0.008929
chain	0.000029
be maintained	0.004219
be asking	0.004219
'' versus	0.005376
popular strategy	0.111111
the different	0.000692
operated on	0.500000
GenEx	0.000029
flatbed	0.000029
distinct sentences	0.142857
say your	0.142857
is shown	0.002033
corp.	0.000029
Talmy Givón	1.000000
minute	0.000029
questions from	0.038462
real estate	0.111111
<s> Solving	0.000769
subsystem for	1.000000
and actual	0.001445
dependency grammar	0.200000
dozens of	1.000000
use various	0.013889
the Cuzco	0.000692
patient	0.000029
on such	0.004717
only unigrams	0.026316
programs sponsored	0.090909
out loud	0.071429
geography	0.000029
kinds of	1.000000
was evident	0.012987
degraded-images	0.000029
My	0.000029
, whether	0.000561
now largely	0.076923
Precision measures	1.000000
accomplished	0.000029
made indifferent	0.062500
web page	0.125000
commercial version	0.090909
wrong fairly	1.000000
automatic keyphrase	0.043478
at Cognitive	0.014706
An extractive	0.062500
Invoice OCR	1.000000
proliferation of	1.000000
& Critical	0.125000
of producing	0.000891
optimize	0.000029
fully up	0.166667
opposed	0.000029
hitcha '	1.000000
order for	0.071429
when outputting	0.028571
well to	0.035714
-LRB- Campaigns	0.002710
the new	0.000692
off-line character	1.000000
analysis system	0.015385
Wetherell	0.000029
people create	0.062500
contractions ,	0.500000
many forms	0.019231
incremental	0.000029
humans can	0.083333
listens	0.000029
system answers	0.010753
be deployed	0.004219
the terms	0.000692
processing to	0.018519
Significant	0.000029
although capabilities	0.166667
STT	0.000029
fueled	0.000029
work derived	0.041667
pulled	0.000029
travel	0.000029
Its results	0.500000
on general	0.004717
weaker .	1.000000
were called	0.024390
effective decision-support	0.166667
structuring	0.000029
no subtypes	0.076923
appear often	0.062500
open-access journal	1.000000
`` fire	0.005291
Keyphrase extractors	0.250000
surfer model	1.000000
subjectivity\/objectivity identification	1.000000
and\/or religious	0.333333
short-time units	0.500000
short intervals	0.125000
Stages The	1.000000
simultaneously with	0.500000
A linguist	0.020000
examples as	0.041667
possible answers	0.041667
<s> Context-free	0.000769
the simple	0.000692
Agency in	0.500000
been made	0.014706
of analyses	0.000891
requires specialized	0.062500
70s the	1.000000
Steven DeRose	1.000000
Michigan	0.000029
automatically evaluating	0.047619
limits -LRB-	1.000000
internet	0.000029
, Rajman	0.000561
sociology ,	1.000000
exponential time	0.500000
most difficult	0.017241
without the	0.076923
For telephone	0.016393
comprising multiple	0.500000
of Peru	0.000891
against which	0.200000
dictionary .	0.142857
Rabinow	0.000029
reasoning components	0.142857
emotion	0.000029
→ <verb>	0.333333
being the	0.055556
talk page	1.000000
study of	0.250000
documents were	0.026316
unlikely analyses	1.000000
Prior implementations	1.000000
4-gram	0.000029
Intelligent Machines	0.333333
domains ,	0.125000
NAACL	0.000029
view of	0.333333
answering a	0.083333
Eurospeech\/ICSLP -LRB-	1.000000
programs to	0.090909
Italian ;	0.500000
summarizes that	1.000000
recognition models	0.008264
to enumerate	0.001328
answering :	0.083333
document level	0.027778
interactivity -LRB-	1.000000
1980s saw	0.111111
for errors	0.003610
reporting -LRB-	0.333333
these sounds	0.023810
evaluation Depending	0.018519
uninterrupted	0.000029
Treebank data	0.166667
We assume	0.142857
all unknowns	0.023256
pertain strongly	1.000000
printer	0.000029
is subjectivity\/objectivity	0.002033
hand-printed documents	0.250000
dictionary and	0.142857
conditions Accuracy	0.200000
By having	0.333333
sentences begin	0.013158
reasoned views	1.000000
, affective	0.000561
lines and	0.333333
different groups	0.020408
digital assistants	0.142857
large data	0.043478
texts or	0.058824
, Hindle	0.000561
revolutionized	0.000029
A large	0.020000
Louise J.	1.000000
resort to	1.000000
schemata .	1.000000
making up	0.142857
human-like interaction	1.000000
vision	0.000029
within that	0.055556
Constraints e.g.	0.333333
This analysis	0.015873
versions for	0.333333
different way	0.020408
performed more	0.100000
are germane	0.004149
-LRB- ending	0.002710
Unsourced	0.000029
an EHR	0.007576
levels first	0.045455
diagonal covariance	1.000000
expended	0.000029
of criteria	0.000891
rarely the	0.333333
without reference	0.076923
not mark	0.008929
finds many	1.000000
average distance	0.500000
impossibility of	1.000000
Associated Press	1.000000
A.C.	0.000029
commonly taught	0.125000
have on	0.009615
evaluation workshops	0.018519
Analysis Although	0.200000
to erroneous	0.001328
actually correct	0.333333
the postal	0.000692
heard or	1.000000
automatizing	0.000029
photos	0.000029
learning Beginning	0.023256
algorithm could	0.035714
part-of-speech tags	0.066667
corpora in	0.090909
expressed with	0.166667
their products	0.029412
important Web	0.062500
program got	0.045455
Size	0.000029
highly ambiguous	0.111111
be different	0.004219
the multiple	0.000692
requires its	0.062500
N words	0.333333
Profile	0.000029
Reinvestment Act	1.000000
or semantics	0.004505
supplying more	1.000000
example-generation	0.000029
assigns	0.000029
to ease	0.001328
methods .	0.022727
use so-called	0.013889
% range	0.025641
Inclusive choice	1.000000
Back-End	0.000029
agree -RRB-	0.333333
effects	0.000029
<s> Constraints	0.000769
-RRB- up	0.002817
results show	0.047619
translation studies	0.013514
additional citations	0.166667
Unsourced material	1.000000
Computer Science	0.166667
who co-founded	0.100000
Standard Oil	0.500000
system used	0.010753
Oklahoma ,	1.000000
1985 ,	1.000000
Amplitude	0.000029
postal	0.000029
Latin .	0.250000
home ''	1.000000
also because	0.014493
other approaches	0.014286
translation tasks	0.013514
satisfactory	0.000029
Information Subsumption	0.200000
working to	0.142857
, sociolinguistics	0.000561
-RRB- BioCreative	0.002817
simple extraction	0.038462
gradual lessening	1.000000
of multimedia	0.000891
bases ,	1.000000
, fuse	0.000561
semantically	0.000029
a probabilistic	0.001227
machine-generated	0.000029
from technology	0.009615
legal documents	0.333333
gender ,	1.000000
: A	0.009804
product line	0.142857
above .	0.076923
<s> Incorporating	0.000769
multiplying together	1.000000
typically a	0.055556
if indeed	0.035714
NN	0.000029
when multiple	0.028571
NC	0.000029
more input	0.010526
scores as	0.200000
NP	0.000029
asked within	0.333333
improvements in	0.500000
is RDF	0.002033
project and	0.076923
<s> Envelopes	0.000769
, assertion	0.000561
societal	0.000029
Charniak points	1.000000
<s> Up	0.000769
ROUGE-1 only	0.200000
e.g. Phonemes	0.017857
-LRB- DOE	0.002710
NLG the	0.047619
line in	0.333333
and weapons	0.001445
the very	0.000692
alone ,	0.250000
associating	0.000029
formulation	0.000029
3rd rev	1.000000
field because	0.037037
the shipment	0.000692
thresholded	0.000029
campaign was	0.200000
US ports	0.142857
given restaurant	0.041667
of symbols	0.000891
Fowler ,	1.000000
higher than	0.142857
linguists would	0.333333
of Eastern	0.000891
proper lexical	0.142857
be repeated	0.004219
a class	0.001227
and nouns	0.001445
learning the	0.023256
domains such	0.125000
causes	0.000029
morphologically rich	1.000000
related fields	0.066667
a preliminary	0.001227
be gained	0.004219
norm	0.000029
Conversation	0.000029
connected by	0.200000
faster to	0.333333
that revolutionized	0.003546
filling	0.000029
and echoes	0.001445
statistically-based speech	1.000000
analysis include	0.015385
algorithms one	0.028571
displays	0.000029
Swedish pilots	1.000000
pass	0.000029
exploited ;	1.000000
statistical quantity	0.030303
translators and	1.000000
dog to	0.333333
the difficulties	0.000692
modeling salience	0.142857
usually from	0.031250
highly interactive	0.111111
RCA collaborated	0.200000
-LRB- MAHS	0.002710
in visible	0.001873
be confused	0.004219
fighter trainer	0.166667
less expensive	0.083333
report -RRB-	0.250000
the times	0.000692
generic response	0.333333
: Rule-based	0.009804
Kolodner	0.000029
and SpeechTEK	0.001445
Throughout the	1.000000
The relationships	0.005208
The state-of-the-art	0.005208
than what	0.022222
simple keyword	0.038462
TextRank is	0.071429
corrected	0.000029
paragraphs -RRB-	0.250000
in restricted	0.001873
a multi-way	0.001227
existing summaries	0.200000
1993 -RRB-	0.333333
software produces	0.037037
2.0 The	0.500000
whereby words	1.000000
installing	0.000029
by limiting	0.005714
associated word	0.250000
CoNLL shared	1.000000
ambiguity and	0.125000
various term	0.055556
<s> Recognizing	0.000769
records and	0.250000
Aided Machine	0.333333
huge	0.000029
1994 ,	1.000000
written-out	0.000029
and memory	0.001445
efforts were	0.142857
part-of-speech categories	0.066667
stub reader	1.000000
about 95	0.025000
completely nonsensical	1.000000
20th-century newspaper	1.000000
functional languages	0.500000
variant	0.000029
Law and	1.000000
current state	0.142857
system-generated summaries	0.500000
entered John	0.500000
have multiple	0.009615
a web	0.001227
characterize a	0.500000
funding was	0.125000
a likelihood	0.001227
one symbol	0.015385
easy-to-use syntax	1.000000
routed along	0.500000
-RRB- approach	0.002817
Response based	1.000000
the informational	0.000692
electronic medical	0.500000
representation system	0.052632
be explained	0.004219
Morpholympics compared	1.000000
<s> POS-tagging	0.000769
courses	0.000029
create features	0.058824
other scientific	0.014286
that state	0.003546
such system	0.008130
numeric	0.000029
component sentences	0.200000
granted a	1.000000
keywords or	0.500000
standards and	0.200000
using neural	0.016949
ME is	0.500000
the barmaid	0.000692
similar methods	0.037037
view -LRB-	0.333333
opportunities and	1.000000
DeRose 1990	0.200000
, statement	0.000561
-LRB- Sonic	0.002710
individual users	0.083333
exactly as	0.333333
: Statistical	0.009804
and researchers	0.001445
generation because	0.111111
Subjectivity ''	1.000000
implications of	1.000000
Screenshot	0.000029
formal rules	0.111111
gonna do	1.000000
may well	0.019231
rather to	0.062500
basic sub-signals	0.076923
network is	0.166667
of Business-card	0.000891
judgement ,	0.333333
domain and	0.050000
1969 Roger	0.500000
certain sequences	0.142857
it might	0.008547
appropriate number	0.250000
and we	0.001445
robot questions	0.500000
door being	0.250000
sound .	0.050000
into play	0.012821
event .	0.333333
are selected	0.004149
be kept	0.004219
500 samples	0.500000
and get	0.001445
issues of	0.200000
to dozens	0.001328
segmentation task	0.030303
cockpit functions	0.500000
systems remains	0.008929
that character-by-character	0.003546
Ge'ez script	1.000000
Consultant	0.000029
typical large-vocabulary	0.111111
an ellipsis	0.007576
seize	0.000029
task it	0.023810
by Ask.com	0.005714
Voice Translator	0.200000
stutering ,	1.000000
we try	0.022222
deferred speech	1.000000
sort mail	0.333333
involve the	0.166667
guessed at	1.000000
This technique	0.015873
columns	0.000029
's intent	0.019608
, unverified	0.000561
problem may	0.022727
specific theoretical	0.047619
as maximum	0.003484
human-made summaries	0.500000
of children	0.000891
d'évaluation	0.000029
Advanced reasoning	0.200000
sound waves	0.050000
quantity of	0.333333
web blogs	0.125000
vendors .	0.250000
higher error	0.142857
mentions within	0.333333
tag ''	0.062500
<s> Competing	0.000769
about unigrams	0.025000
asking for	0.500000
include distinct	0.037037
register by	1.000000
document browsing	0.027778
follow-the-bouncing-ball video	1.000000
Query	0.000029
EndWar	0.000029
the WYSIWYM	0.000692
described here	0.166667
marks ,	0.250000
Research into	0.125000
by Yehoshua	0.005714
create some	0.058824
Cary	0.000029
rudimentary translation	0.500000
information can	0.021739
counselling	0.000029
spectrum	0.000029
finds	0.000029
untrained	0.000029
things -RRB-	0.333333
interpreter ,	0.500000
to enhance	0.001328
expanded	0.000029
empirical	0.000029
view language	0.333333
intervening punctuation	1.000000
from script	0.009615
higher degree	0.142857
several phases	0.045455
SYSTRAN for	1.000000
release beyond	0.333333
abilities .	1.000000
digital .	0.142857
captioned	0.000029
Royal Australian	0.500000
rules --	0.023256
vowels .	0.333333
Named	0.000029
zero ''	1.000000
adverb ,	1.000000
raters	0.000029
invented Penicillin	0.500000
predict -RRB-	0.166667
bag of	1.000000
About 90	0.500000
coming between	1.000000
generated summary	0.066667
+ Web-based	0.166667
his method	0.083333
<s> Technologies	0.000769
inflection is	1.000000
-LRB- Style	0.002710
qualities making	0.500000
read the	0.142857
an optimal	0.007576
Of	0.000029
sold by	0.333333
here ,	0.500000
sets ;	0.090909
title concentrates	1.000000
emergence	0.000029
interaction The	0.125000
reliable sources	0.250000
`` deep	0.005291
robust to	0.250000
individuals	0.000029
on training	0.004717
implemented by	0.200000
lexical segments	0.076923
of Knowledge	0.000891
`` book	0.005291
harder when	0.142857
manually or	0.250000
Aviation	0.000029
implementing a	1.000000
semantics formalization	0.071429
singular common	0.250000
Harris at	0.111111
How ,	0.142857
handwriting ,	0.500000
handwriting .	0.500000
the noun	0.000692
10msec ,	0.500000
Kurzweil 's	0.142857
domain tends	0.050000
ranks ,	0.500000
semantic equivalence	0.047619
up the	0.045455
span	0.000029
problems Processes	0.058824
Security Agency	1.000000
, weather	0.000561
the effort	0.000692
Solving System	0.500000
opens	0.000029
required many	0.142857
smaller ones	0.142857
by resorting	0.005714
1998 Language	0.250000
lot more	0.333333
Piron 's	0.333333
that spontaneous	0.003546
nautical context	0.500000
identifying relevant	0.166667
the class	0.000692
<s> require	0.000769
Among these	1.000000
sophisticated NLG	0.142857
will need	0.028571
library ,	0.500000
influence	0.000029
in non-Western	0.001873
, combined	0.000561
% still	0.025641
meantime ,	1.000000
the APEXC	0.000692
disambiguation concerns	0.100000
learn about	0.076923
season ,	1.000000
Phrases	0.000029
summarise financial	0.333333
vowels and	0.333333
operators need	1.000000
more qualities	0.010526
<s> and	0.000769
: Top-down	0.009804
to settle	0.001328
may chose	0.019231
was hoping	0.012987
train	0.000029
social work	0.071429
roadmap of	1.000000
process ,	0.027778
give predicted	0.250000
Jim	0.000029
Bolivar	0.000029
<s> Substantial	0.000769
exclamation marks	1.000000
broader	0.000029
the action	0.000692
to move	0.001328
by Environment	0.005714
-- 10	0.040000
Johnstone ,	1.000000
situation where	0.500000
into all	0.012821
all these	0.023256
are sometimes	0.004149
easier on	0.125000
human-language question	1.000000
new set	0.041667
some invalid	0.012048
ARCHILES technique	1.000000
linguistics Cognitive	0.050000
Campaigns	0.000029
coreference	0.000029
system determine	0.010753
difficult problem	0.035714
improved the	0.250000
under ultraviolet	0.200000
a corresponding	0.001227
Disambiguation	0.000029
survey	0.000029
is devoted	0.002033
simple bar	0.038462
the robot	0.000692
referenced .	1.000000
complex task	0.041667
Sample a	1.000000
those human	0.045455
e.g. Querying	0.017857
functioning of	0.333333
becoming more	1.000000
an active	0.007576
-LRB- like	0.002710
flight displays	0.500000
customer	0.000029
by Junqua	0.005714
integrating	0.000029
lists that	1.000000
unknowns	0.000029
smaller sub-sounds	0.142857
to prune	0.001328
painstakingly	0.000029
against feature	0.200000
be adequately	0.004219
17 ambiguous	1.000000
problem overlaps	0.022727
Mutual Information	1.000000
expanding all	1.000000
within an	0.055556
intelligent	0.000029
Automatic tagging	0.111111
, according	0.000561
vs. glass-box	0.083333
two meanings	0.034483
highly redundant	0.111111
a modal	0.001227
, Carnegie	0.000561
realized	0.000029
speech-to-text processing	0.500000
or Web-based	0.004505
`` Did	0.005291
see Handwriting	0.050000
other similar	0.014286
higher level	0.142857
models are	0.038462
Tags usually	1.000000
green fire	1.000000
insight	0.000029
in 1993	0.001873
perfect	0.000029
Current QA	0.200000
a ''	0.001227
Technology Integration	0.333333
meantime	0.000029
users with	0.111111
extracting their	0.200000
helicopters ,	0.500000
physicians	0.000029
is need	0.002033
an 11	0.007576
are analyzed	0.004149
stress injuries	0.500000
Talmy	0.000029
robust against	0.250000
these same	0.023810
deal of	0.250000
reproducing	0.000029
likely part	0.062500
into machine	0.012821
books	0.000029
people untrained	0.062500
thought or	0.333333
, processing	0.000561
relationships among	0.166667
routed through	0.500000
matrix	0.000029
an epidemic	0.007576
then using	0.028571
, grammatical	0.000561
do you	0.038462
document before	0.027778
<s> Harris	0.000769
not seen	0.008929
applying some	0.250000
modern statistical	0.200000
problem for	0.022727
Robinson ,	1.000000
true only	0.500000
learn the	0.076923
and exclamation	0.001445
vendors in	0.250000
Standardization in	1.000000
different tongues	0.020408
systems on	0.008929
the learner	0.000692
of triples	0.000891
pauses .	0.250000
write `	1.000000
commonly serve	0.125000
processing part	0.018519
new odd	0.041667
many times	0.019231
<s> Potentially	0.000769
data set	0.012987
computer can	0.022727
left-to-right .	1.000000
warped ''	1.000000
of cases	0.000891
Popular speech	1.000000
has used	0.011905
one way	0.015385
divider ,	1.000000
OnlineOCR or	0.333333
with attribute	0.005464
to multi-platforms	0.001328
interpreters require	1.000000
to various	0.001328
media such	0.166667
urgent early	1.000000
worldwide	0.000029
Pierce	0.000029
This hierarchy	0.015873
project were	0.076923
insurance bills	1.000000
recognition vary	0.008264
over many	0.083333
placement	0.000029
purely statistical	1.000000
structures in	0.200000
how close	0.034483
original paper	0.076923
i.e. source	0.052632
candidates instead	0.200000
software libraries	0.037037
of high	0.000891
rubric	0.000029
Vauquois '	1.000000
deaf telephony	1.000000
entropy has	0.200000
, follow-the-bouncing-ball	0.000561
maintenance -RRB-	1.000000
of internal	0.000891
PageRank selects	0.166667
examples in	0.041667
of oral	0.000891
Racter ,	1.000000
language learning	0.006757
predict performance	0.166667
complex problem	0.041667
reduce acoustic	1.000000
the informativeness	0.000692
and competitions	0.001445
conditions in	0.200000
The success	0.005208
can understand	0.005525
guessing	0.000029
pronoun	0.000029
the Medical	0.000692
immediate neighbors	1.000000
possessives into	1.000000
<s> BASEBALL	0.000769
why HMMs	0.142857
Cullingford	0.000029
soon become	0.333333
source code	0.041667
input is	0.024390
The unsupervised	0.005208
by their	0.005714
proper names	0.142857
Sonic Extractor	1.000000
More recently	0.111111
a neural	0.001227
Although ,	0.125000
dialogues between	1.000000
Some examples	0.047619
cosine transform	0.333333
other cockpit	0.014286
essentially calculates	0.125000
instead optimize	0.142857
as questions	0.003484
to express	0.001328
the orthography	0.000692
2,663,758	0.000029
-LRB- English	0.002710
error-prone and	1.000000
and Windows	0.001445
Handel also	1.000000
customers .	0.500000
of marketing	0.000891
Number	0.000029
The United	0.005208
focusing on	1.000000
strength at	0.200000
phrases may	0.062500
networks have	0.071429
solve the	0.250000
of images	0.000891
Yehoshua	0.000029
-- or	0.040000
grammars alone	0.071429
, picture	0.000561
-- on	0.040000
be included	0.004219
language into	0.006757
also pioneered	0.014493
is vital	0.002033
a watertight	0.001227
of structured	0.000891
, Politics	0.000561
semantics of	0.071429
other non-textual	0.014286
good for	0.076923
sentiment with	0.040000
accuracy and	0.032258
compactly ,	1.000000
Similarly	0.000029
of document	0.000891
simulation vendors	0.333333
intonation ,	1.000000
start experimenting	0.142857
are accepted	0.004149
parsers which	0.076923
video -RRB-	0.200000
Avionics Research	1.000000
TextRank While	0.071429
a product	0.001227
<s> Aided	0.000769
Handwriting	0.000029
Leading software	1.000000
then can	0.028571
analysis Genre	0.015385
two methods	0.034483
Elinor Ochs	1.000000
some classification-related	0.012048
by trying	0.005714
Paul Hopper	0.200000
small set	0.111111
allows for	0.125000
no pauses	0.076923
FoG triggered	0.500000
many strokes	0.019231
post-secondary look	1.000000
it seems	0.008547
the adjacent	0.000692
a fashion	0.001227
summarization algorithms	0.020000
blocks worlds	0.250000
more compactly	0.010526
written including	0.038462
sometimes ambiguous	0.076923
more ,	0.010526
Schiffrin	0.000029
ranked with	0.200000
on hand-written	0.004717
which itself	0.007246
then taking	0.028571
, consider	0.000561
Paragraph Structure	1.000000
usually rated	0.031250
are efficient	0.004149
a Standard	0.001227
now done	0.076923
Extractive	0.000029
use simple	0.013889
comprehensive theories	0.200000
Lehnert 1981	0.333333
own assumptions	0.166667
Structure	0.000029
a trillion-word	0.001227
them automatically	0.052632
references ,	0.250000
the strengths	0.000692
non-whitespace	0.000029
least five	0.200000
be further	0.004219
tag for	0.062500
dialogue with	0.500000
major component	0.083333
or speed	0.004505
NYU	0.000029
TWA where	1.000000
of identifying	0.000891
embedded .	0.250000
classified into	1.000000
reference for	0.125000
here there	0.500000
of vertices	0.000891
summarizes	0.000029
`` foreign	0.005291
Amharic and	1.000000
steady accumulation	0.500000
use context-free	0.013889
Military	0.000029
incorrectly causing	1.000000
LILOG projects	0.500000
reuse ,	1.000000
forms can	0.166667
Winograd continued	0.333333
D. Das	0.200000
Just which	1.000000
's blocks	0.019608
or opinion	0.004505
, Gender	0.000561
2002 evaluation	0.500000
research groups	0.023810
, French	0.000561
protection	0.000029
vehicle Navigation	1.000000
small knowledge	0.111111
are time-consuming	0.004149
eigenvector centrality	0.500000
the reverse	0.000692
John Pierce	0.125000
work well	0.041667
-- Pointwise	0.040000
encoding world	1.000000
run each	0.200000
removing stopwords	0.500000
focused solely	0.090909
Drum printer	1.000000
processing text	0.018519
or aspects	0.004505
document is	0.027778
corresponds to	1.000000
of unknown	0.000891
line as	0.333333
includes making	0.142857
ambiguities in	0.250000
1995	0.000029
1994	0.000029
1996	0.000029
the Lander	0.000692
is checking	0.002033
era	0.000029
resources are	0.166667
on unsupervised	0.004717
indicates	0.000029
the complex	0.000692
transducers	0.000029
Verbyx	0.000029
random surfer	0.142857
accuracy will	0.032258
the goals	0.000692
Henry Widdowson	0.500000
text classification	0.006289
8 %	1.000000
earlier in	0.250000
that part-of-speech	0.003546
conclusions .	1.000000
Models .	0.333333
overall task	0.166667
Huang etc.	1.000000
and later	0.001445
require advanced	0.045455
A semantic	0.020000
1629 ,	1.000000
innovative	0.000029
those concerning	0.045455
Drew	0.000029
having to	0.200000
at each	0.014706
unless the	1.000000
dependency relations	0.200000
within another	0.055556
process may	0.027778
American English	0.200000
a Markov	0.001227
What learning	0.090909
right-to-left	0.000029
Anaphora	0.000029
Bible Society	1.000000
the inter-texual	0.000692
clarify a	1.000000
convey .	0.333333
Type	0.000029
creating more	0.142857
information appear	0.021739
`` Apparatus	0.005291
comprehensive knowledge	0.200000
It consists	0.026316
the EMR	0.000692
also stems	0.014493
detecting	0.000029
observed vector	1.000000
forecasts used	0.200000
some parsing	0.012048
: To	0.009804
first raised	0.030303
Manfred	0.000029
, maximum	0.000561
the Penpoint	0.000692
where natural	0.028571
US Army	0.142857
CLAWS -LRB-	0.250000
A subtask	0.020000
learning -RRB-	0.023256
, despite	0.000561
Japanese prisoner	0.125000
corresponding systems	0.166667
on each	0.004717
universal language	0.333333
years researchers	0.047619
and Spanish	0.001445
word-category	0.000029
learning such	0.023256
put a	0.250000
historical	0.000029
acoustics	0.000029
25 %	1.000000
used English	0.008850
reading text	0.125000
and worked	0.001445
performance mainly	0.055556
about 12	0.025000
methodology was	0.500000
Poncini ,	1.000000
contents	0.000029
context to	0.030303
several other	0.045455
in both	0.001873
1987 -LRB-	0.333333
terms to	0.076923
subjects	0.000029
page .	0.142857
factor .	0.500000
improve machine	0.076923
acquire	0.000029
ranking process	0.142857
germane	0.000029
paragraph .	0.333333
which had	0.007246
pollen example	0.076923
been based	0.014706
assessed	0.000029
English-like syntax	0.333333
Linguistics -LRB-	0.333333
to adjust\/correct	0.001328
simple world	0.038462
of examples	0.000891
began planning	0.142857
strokes for	1.000000
on-line character	0.333333
signal .	0.166667
the accuracy	0.000692
PAM	0.000029
the feature\/aspect-based	0.000692
DCD	0.000029
language-processing	0.000029
degradation	0.000029
topics discussed	0.142857
other structure	0.014286
runs	0.000029
Spoken Language	1.000000
been taken	0.014706
but discards	0.014706
ignore this	1.000000
visited and	1.000000
Halliday ,	1.000000
for medical	0.003610
is identifying	0.002033
among sentences	0.125000
draws	0.000029
pasted	0.000029
may denote	0.019231
transfer-based ,	0.333333
incomplete sentences	1.000000
drawn	0.000029
averaged .	1.000000
high quality	0.055556
speech Task	0.006579
by Greene	0.005714
and indirect	0.001445
the Mars	0.000692
explicit features	0.200000
word blend	0.016667
after ,	0.083333
because translation	0.033333
phrased in	1.000000
on sentence	0.004717
ASRU .	1.000000
N-best	0.000029
relationship mentions	0.166667
the noise	0.000692
being referred	0.055556
-LRB- grammar	0.002710
Grammar ,	1.000000
from 50	0.009615
relevant content	0.142857
from mild	0.009615
negative ,	0.125000
tokens form	0.142857
and of	0.001445
the ANR-Passage	0.000692
Such systems	0.125000
like being	0.035714
and Japanese	0.001445
we might	0.022222
Another good	0.076923
tagging could	0.040000
tasks have	0.031250
reader -RRB-	0.100000
die or	1.000000
been devoted	0.014706
earlier some	0.250000
that participate	0.003546
combination of	0.200000
whole .	0.111111
counterparts	0.000029
network has	0.166667
whereby	0.000029
<s> QA	0.000769
were started	0.024390
musical	0.000029
typical accuracy	0.111111
turns .	0.333333
thanks	0.000029
step and	0.066667
electronically	0.000029
successful finished	0.111111
Constraint Grammar	1.000000
tag-sets .	1.000000
examples produces	0.041667
about specific	0.025000
Future of	0.500000
objective True\/False	0.200000
, answered	0.000561
usable	0.000029
further subdivided	0.125000
designers	0.000029
a closed-captioning	0.001227
, POS	0.000561
or worse	0.004505
loud .	1.000000
93-95	0.000029
night	0.000029
parser and	0.062500
remarkably similar	1.000000
matching ,	0.200000
and shallowest	0.001445
useful as	0.071429
and widely	0.001445
bore	0.000029
concept ,	0.250000
it aimed	0.008547
Many Electronic	0.083333
individual vertices	0.083333
from United	0.009615
F. ,	1.000000
discuss the	1.000000
Hardy ,	1.000000
rule-based translation	0.142857
cards for	1.000000
Statistics are	0.333333
recognition Main	0.008264
profession	0.000029
direct real-world	0.166667
patented and	1.000000
immunology ,	1.000000
-LRB- GPO	0.002710
for multiple	0.003610
flying in	1.000000
isolated words	0.200000
They can	0.333333
with C4	0.005464
keyphrases assigned	0.028571
of reproducing	0.000891
graph specially	0.076923
this vocabulary	0.010989
document 's	0.027778
campaign is	0.200000
its answer	0.028571
determine ``	0.043478
The recognition	0.005208
guesses	0.000029
request	0.000029
where using	0.028571
technique is	0.142857
path ,	0.500000
guessed	0.000029
expertise	0.000029
characters and	0.062500
and 2009	0.001445
features\/aspects ,	1.000000
Commercial applications	0.500000
and 2002	0.001445
and 2007	0.001445
the financial	0.000692
lead-in fighter	1.000000
preclude using	1.000000
is included	0.002033
first came	0.030303
cohesion	0.000029
which simulates	0.007246
government .	0.333333
Gaussians ,	1.000000
the serial	0.000692
conducted until	0.200000
These waves	0.058824
it aims	0.008547
to decoding	0.001328
vs. spontaneous	0.083333
both linguistic	0.032258
process broken	0.027778
: Microsoft	0.009804
compiler due	0.333333
realistic grammars	1.000000
2000 ,	0.333333
2000 .	0.333333
, studying	0.000561
shallow-transfer	0.000029
posed by	0.333333
NLP ranking	0.021277
semitied covariance	1.000000
academic research	1.000000
Neural Network	0.250000
probabilistically at	1.000000
the memory	0.000692
than of	0.022222
Ford	0.000029
that do	0.003546
both cases	0.032258
summarization research	0.020000
Some SR	0.047619
often characterised	0.022727
remain high	1.000000
answers ,	0.083333
Discursive psychology	1.000000
answers .	0.083333
message understanding	0.500000
significant momentum	0.111111
still have	0.066667
consisted of	1.000000
sense ,	0.125000
Major issues	0.500000
isolated-word	0.000029
isloated	0.000029
H. Levinsohn	0.500000
The context	0.005208
often considered	0.022727
Method -RRB-	1.000000
written-out number	1.000000
Call home	1.000000
highly-specialized	0.000029
French ,	0.125000
using journal	0.016949
as commercial	0.003484
output from	0.038462
known for	0.038462
Jacob	0.000029
MPE	0.000029
grammars often	0.071429
semi-supervised ''	0.500000
that about	0.003546
Each frame	0.166667
specific strengths	0.047619
Throughout	0.000029
challenged and	1.000000
part usually	0.037037
Contains	0.000029
the completion	0.000692
relies on	1.000000
sub-titling	0.000029
unrealistically	0.000029
would then	0.018868
been annotated	0.014706
captured by	1.000000
moves ,	1.000000
of most	0.000891
-LRB- discourse	0.002710
processors	0.000029
being scanned	0.055556
laughter -RRB-	1.000000
machine-learning-based	0.000029
serving	0.000029
neural-network	0.000029
Jay	0.000029
and taking	0.001445
Jan	0.000029
parsing ambiguous	0.035714
extract sentences	0.250000
Guy Cook	1.000000
make them	0.050000
cause the	0.500000
from it	0.009615
non	0.000029
The lexer	0.005208
answer reuse	0.033333
Faber	0.000029
May 2012	0.500000
nor	0.000029
predicting star	0.500000
open-ended questions	1.000000
theories in	0.200000
inputting approximately	1.000000
would ,	0.018868
would .	0.018868
`` warped	0.005291
challenged	0.000029
are ,	0.004149
are 9	0.004149
candidate ,	0.333333
since words	0.100000
product or	0.142857
include Single	0.037037
course be	0.333333
reasoning for	0.142857
`` fastens	0.005291
devised primarily	0.500000
words accidentally	0.009174
critical that	0.250000
is critical	0.002033
a relative	0.001227
transition	0.000029
at that	0.014706
Overall organization	1.000000
<s> Searches	0.000769
, Steven	0.000561
to encode	0.001328
needed ,	0.047619
converted it	0.333333
The model	0.005208
Response	0.000029
volume ,	0.250000
in rank	0.001873
Fournier d'Albe	1.000000
professionals	0.000029
common case	0.040000
that form	0.003546
sophisticated questioners	0.142857
approaches designed	0.035714
well the	0.035714
the sequences	0.000692
C ,	1.000000
as business	0.003484
from this	0.009615
world -LRB-	0.066667
text ''	0.006289
beginning in	0.500000
Unlike	0.000029
the unwanted	0.000692
, on-line	0.000561
importantly	0.000029
the easier	0.000692
text 's	0.006289
Nielsen automatically	1.000000
implications	0.000029
power resulting	0.250000
Jabberwacky .	1.000000
automatically as	0.047619
more severe	0.010526
less uninterrupted	0.083333
outputting one	0.500000
NN for	1.000000
step -LRB-	0.066667
interaction Pronunciation	0.125000
training ''	0.035714
this kind	0.010989
suitable -LRB-	0.250000
a consumer	0.001227
under the	0.200000
libraries GRM	0.500000
, Cynthia	0.000561
1976 -RRB-	0.500000
important part	0.062500
's GenEx	0.019608
or form	0.004505
or FST	0.004505
rephrase	0.000029
translator that	0.142857
languages concepts	0.020000
Englund -LRB-	1.000000
vibration ,	1.000000
effectiveness .	0.333333
first-cut	0.000029
overcome these	0.500000
not produce	0.008929
unclear whether	1.000000
Unicode	0.000029
are outside	0.004149
that appears	0.003546
different distances	0.020408
others -RRB-	0.083333
the statistics	0.000692
exploit	0.000029
domain-specific knowledge	0.500000
150,000 words	1.000000
Then we	0.200000
Pragmatics ,	1.000000
dictator	0.000029
NNS for	1.000000
side effect	1.000000
hopes to	1.000000
collection -RRB-	0.200000
mainly with	0.166667
vagueness	0.000029
Languages with	0.333333
science of	0.100000
starts ,	0.500000
a construct	0.001227
finite set	0.200000
criteria ,	0.250000
Speech processing	0.032258
criteria .	0.250000
kept either	1.000000
<s> See	0.000769
metamodel and	1.000000
agree about	0.333333
summaries using	0.023256
structure is	0.083333
's Mars	0.019608
Pronunciation evaluation	1.000000
, G	0.000561
, E	0.000561
, D	0.000561
, C	0.000561
, Z	0.000561
, V	0.000561
during World	0.100000
, P	0.000561
<s> Throughout	0.000769
contain strings	0.083333
and found	0.001445
in contrast	0.001873
some topic	0.012048
, 7	0.000561
mathematical framework	0.500000
, 4	0.000561
, 3	0.000561
, 2	0.000561
pre-processing e.g.	1.000000
different ways	0.020408
the big	0.000692
Puma	0.000029
Service	0.000029
the mission	0.000692
linked with	0.333333
See Peter	0.166667
larger set	0.062500
to pauses	0.001328
be faster	0.004219
HTK book	0.500000
comes mainly	0.200000
was reading	0.012987
were surprisingly	0.024390
versa	0.000029
profession -LRB-	1.000000
indicate a	0.333333
networks as	0.071429
gonna	0.000029
how air	0.034483
Plot Units	1.000000
<s> Deferred	0.000769
Incorporating diversity	1.000000
low pollen	0.333333
evident way	0.500000
, Carmen	0.000561
much through	0.045455
that answered	0.003546
use splicing	0.013889
major corpus	0.083333
verbal	0.000029
contain periods	0.083333
been extended	0.014706
noun in	0.071429
than 98	0.022222
greatly improved	0.142857
-RRB- Modern	0.002817
discriminate keyphrases	0.333333
, Racter	0.000561
sentence breaks	0.020833
has proven	0.011905
decided a	0.333333
nuggets	0.000029
, heavy-noise	0.000561
problems with	0.058824
easily parsed	0.111111
Approaches Bernard	0.333333
necessarily match	0.500000
POS categories	0.076923
approach 90	0.028571
<s> Precision	0.000769
readers .	0.500000
intent	0.000029
simulated the	0.500000
backup	0.000029
left recursion	0.166667
interaction by	0.125000
, shallow	0.000561
procedural information	1.000000
solutions to	0.500000
be known	0.004219
intervention	0.000029
vector .	0.333333
system involves	0.010753
factor -LRB-	0.500000
podcast	0.000029
sets for	0.090909
use\/mention	0.000029
This strategy	0.015873
largely similar	0.200000
is needed	0.002033
translate more	0.166667
usually creating	0.031250
planning and	0.500000
Obama ,	1.000000
to names	0.001328
LinguaSys ,	1.000000
where much	0.028571
Veterans	0.000029
Annex	0.000029
then end	0.028571
term frequencies	0.055556
poor	0.000029
explicitly mention	0.250000
disassembling and	1.000000
or verb	0.004505
OCR patents	0.020408
endeavors	0.000029
filter preselects	0.500000
registry	0.000029
Robotics Speech-to-text	1.000000
from weather	0.009615
test environment	0.100000
available isolated-word	0.058824
they must	0.025000
installing speech	1.000000
edge if	0.333333
high probability	0.055556
religious	0.000029
captioned telephone	1.000000
While there	0.200000
samples from	0.500000
defined as	0.166667
Parliament .	0.500000
, adverb	0.000561
logical form	0.166667
the screen	0.000692
case in	0.058824
This comparison	0.015873
case is	0.058824
solve properly	0.250000
we rank	0.022222
chatterbots such	0.500000
which parts	0.007246
cues	0.000029
, leaving	0.000561
Cognitive Process	0.333333
Context-free grammars	1.000000
<s> Initial	0.000769
Chilton	0.000029
phonetic-based categories	1.000000
Intrinsic evaluation	0.333333
clear imaging	0.250000
telegraph code	1.000000
assertions ,	0.500000
as debates	0.003484
usually measured	0.031250
canned text	0.500000
several teams	0.045455
inspired	0.000029
Vocalizations vary	1.000000
probabilities are	0.090909
and speech	0.001445
nested one	1.000000
lower than	0.200000
, thereby	0.000561
exist .	1.000000
then include	0.028571
information needed	0.021739
train their	1.000000
conventional	0.000029
by other	0.005714
advanced ''	0.200000
the historical	0.000692
semantic relationship	0.047619
<s> Back-End	0.000769
many debates	0.019231
lowering	0.000029
considerable variation	0.200000
2009 -RRB-	0.333333
Su	0.000029
user ,	0.071429
simulated a	0.500000
in-principle obstacles	1.000000
various attempts	0.055556
EHR .	0.333333
Faber ,	1.000000
Howarth ,	1.000000
Kucera and	1.000000
dynamics and	0.500000
keyphrases from	0.028571
classify properly	0.500000
Monroe and	1.000000
regression	0.000029
<s> Interactive	0.000769
2 --	0.200000
by larger	0.005714
Schools commonly	1.000000
horizontal	0.000029
been believed	0.014706
use ``	0.013889
Narrow but	1.000000
, once	0.000561
extractors	0.000029
actioning	0.000029
the waves	0.000692
Latin pars	0.250000
ROUGE-1 scores	0.200000
than when	0.022222
insight into	1.000000
1970 ,	0.333333
which sentences	0.007246
by Pang	0.005714
23 letters	1.000000
output in	0.038462
frequencies -LRB-	0.500000
conversation ,	0.250000
the syntactic	0.000692
laws calling	1.000000
and comprehension	0.001445
phrase that	0.100000
real difference	0.111111
given sequences	0.041667
d'évaluation de	1.000000
classifier that	0.142857
mark word	0.333333
context data	0.030303
frequently used	0.500000
computer-type OCR	1.000000
often much	0.022727
reducing training	0.500000
-LRB- disambiguation	0.002710
to unfamiliar	0.001328
the approach	0.000692
notoriously ,	1.000000
transcribe	0.000029
product reviews	0.142857
IMR -RRB-	0.500000
hub ''	1.000000
user can	0.071429
, moves	0.000561
settle	0.000029
safety	0.000029
of Sydney	0.000891
, commanding	0.000561
n-gram overlaps	0.500000
, results	0.000561
Technology Center	0.333333
Stages	0.000029
identification is	0.200000
of size	0.000891
and post-secondary	0.001445
compounded by	1.000000
who used	0.100000
Handel	0.000029
for quantitatively	0.003610
accurate simply	0.142857
a user-specified	0.001227
a gradually	0.001227
the opportunity	0.000692
parser with	0.062500
When several	0.142857
as natural	0.003484
paragraph boundaries	0.333333
de l'assignation	0.500000
as division	0.003484
1914	0.000029
very early	0.024390
signal to	0.166667
break sentences	0.500000
the character	0.000692
pragmatics to	0.333333
derive part-of-speech	0.500000
summary sentences	0.023810
procedural	0.000029
digital computers	0.142857
are statistical	0.004149
short time	0.125000
randomly	0.000029
gold-standard against	1.000000
Australian Air	0.500000
Training air	0.500000
several qualities	0.045455
overall topics	0.166667
specific trade	0.047619
fairly trivial	0.250000
many -LRB-	0.019231
an earlier	0.007576
How many	0.142857
Speaker dependence	0.166667
Typically features	1.000000
or otherwise	0.004505
without inter-word	0.076923
disabilities who	0.250000
physics	0.000029
negative or	0.125000
about democratizing	0.025000
lot and	0.333333
choices Designing	0.200000
OnStar	0.000029
suggest that	0.333333
and LR	0.001445
physics that	1.000000
you would	0.076923
be described	0.004219
combinations	0.000029
the literature	0.000692
standard random	0.071429
texts can	0.058824
meet larger	0.250000
lunar science	1.000000
of hyphenation	0.000891
extrinsic ,	0.166667
future tense	0.333333
culture	0.000029
further research	0.125000
pictures	0.000029
interjection	0.000029
rules engine	0.023256
from speech	0.009615
shift-reduce algorithm	1.000000
software technology	0.037037
abruptly	0.000029
league	0.000029
Informally ,	1.000000
the OCR-A	0.000692
; it	0.021277
foster the	1.000000
multi-platforms such	1.000000
Flickinger	0.000029
output to	0.038462
algorithm -RRB-	0.035714
and left	0.001445
clearly not	0.333333
Question Answering	0.142857
word forms	0.016667
with specialised	0.005464
reviews and	0.166667
many researchers	0.019231
relationship to	0.166667
as simply	0.003484
heavily inflected	1.000000
<s> Specifically	0.000769
different features	0.020408
disturbed by	1.000000
carry out	1.000000
noun can	0.071429
storm ,	1.000000
2009 to	0.333333
shift positions	1.000000
costly	0.000029
parser generators	0.062500
Interlingual Main	0.333333
user are	0.071429
Eagles	0.000029
can effectively	0.005525
, grammar	0.000561
most sense	0.017241
http:\/\/haydn.isi.edu\/ROUGE\/	0.000029
maximum mutual	0.166667
`` Part-of-speech	0.005291
extent of	0.250000
language have	0.006757
`` still	0.005291
, OnStar	0.000561
students ,	0.333333
, abstracts	0.000561
`` recommending	0.005291
reviewed	0.000029
Many real	0.083333
term ,	0.055556
learning and	0.023256
coarticulation	0.000029
pseudo-pilot ,	0.500000
-LRB- closer	0.002710
typically the	0.055556
questioned	0.000029
needs the	0.100000
Lancaster-Oslo-Bergen Corpus	1.000000
of taking	0.000891
and Command	0.001445
Winograd was	0.333333
DOE	0.000029
EMR -RRB-	0.333333
phoneme classification	0.500000
very likely	0.024390
Robyn	0.000029
demonstrated at	1.000000
Orleans ''	0.500000
part may	0.037037
DARPA -RRB-	0.250000
published in	0.142857
greatly affect	0.142857
<s> Mention	0.000769
Blommaert ,	1.000000
incorporate logical	1.000000
classifier module	0.142857
decade ,	0.333333
semantic theories	0.047619
informational content	0.500000
competitions	0.000029
continuous text	0.166667
financial message	0.250000
approaches Supervised	0.035714
7 distinct	0.142857
background noise	0.333333
non-textual components	1.000000
drawback of	1.000000
a collect	0.001227
normal speech	0.500000
significant -RRB-	0.111111
task also	0.023810
application for	0.071429
word pronunciations	0.016667
2011 -RRB-	0.500000
which various	0.007246
Such algorithms	0.125000
Chantal Mouffe	1.000000
settle on	1.000000
would only	0.018868
sophisticated measures	0.142857
her judgement	0.500000
Information extraction	0.200000
as overall	0.003484
`` Turn	0.005291
F35 Lightning	1.000000
faces a	1.000000
Gdaniec C.	1.000000
in research	0.001873
accessibility	0.000029
special challenges	0.200000
is about	0.002033
cases -LRB-	0.055556
in Japanese	0.001873
hands ,	1.000000
also prefer	0.014493
do so	0.038462
arithmetic	0.000029
hour or	1.000000
additional clues	0.166667
Corpus Research	0.062500
will determine	0.028571
Open-domain question	1.000000
complicating	0.000029
svg	0.000029
Separate a	0.500000
typical parser	0.111111
the earliest	0.000692
allowing us	0.333333
by Turney	0.005714
has fueled	0.011905
evaluation technique	0.018519
, quite	0.000561
real-world examples	0.166667
Methods such	0.250000
abstracts or	0.500000
typically how	0.055556
of costly	0.000891
overfitting and	0.500000
The result	0.005208
have so-called	0.009615
single datum	0.071429
positions	0.000029
rapid access	1.000000
ambiguity .	0.125000
approach for	0.028571
Substantial efforts	0.500000
2004 -RRB-	0.333333
caught '	1.000000
choose different	0.500000
the Armed	0.000692
U.S. has	0.142857
is felt	0.002033
almost no	1.000000
original scanned	0.076923
statically beforehand	1.000000
Like keyphrase	0.500000
dialog with	0.500000
examples have	0.041667
assumption -LRB-	0.500000
dynamically creating	0.500000
Deferred	0.000029
computer gaming	0.022727
protect New	1.000000
, machine-aided	0.000561
all official	0.023256
Treebank Project	0.166667
resulting in	0.250000
TaleSpin -LRB-	1.000000
, beyond	0.000561
extent to	0.250000
As described	0.055556
sound in	0.050000
patents	0.000029
presented with	0.166667
often of	0.022727
a recall-based	0.001227
Automotive speech	1.000000
manage	0.000029
Europe began	0.200000
using general	0.016949
Lisp hence	1.000000
An increasing	0.062500
entropy classifier	0.200000
-RRB- HMMs	0.002817
Advanced applications	0.200000
the trainee	0.000692
the co-occurrence	0.000692
: Translation	0.009804
term language	0.055556
boundaries are	0.090909
1990 dissertation	0.333333
select ``	0.166667
prisoner-of-war	0.000029
a case	0.001227
averaged	0.000029
arranged hierarchically	1.000000
-LRB- WER	0.002710
grammars -LRB-	0.071429
request can	1.000000
sentiments	0.000029
systems perform	0.008929
functions .	0.500000
but was	0.014706
a year	0.001227
a filter	0.001227
elements of	0.250000
be thousands	0.004219
encyclopedia	0.000029
contents of	1.000000
word error	0.016667
right context	0.100000
, Harrison	0.000561
types including	0.071429
data rather	0.012987
attribute or	0.500000
general-purpose speech	1.000000
RAF	0.000029
Canada .	0.166667
RAE	0.000029
is unable	0.002033
NYU ,	1.000000
Flow of	1.000000
of new	0.000891
target handover	0.090909
MCE -RRB-	1.000000
source for	0.041667
articulation	0.000029
Duranti	0.000029
the application	0.000692
VOLSUNGA	0.000029
`` set	0.005291
ranks the	0.500000
not found	0.008929
for top-down	0.003610
slide	0.000029
extractor might	0.500000
mechanisms ,	0.500000
such phrases	0.008130
would probably	0.018868
NLP ,	0.021277
Postal Service	1.000000
rates can	0.125000
a voice	0.001227
as CLAWS	0.003484
answer temporal	0.033333
problem because	0.022727
dogs the	0.142857
` discourse	0.062500
book-new .	1.000000
the speakers	0.000692
popular ``	0.111111
been previously	0.014706
rarely successful	0.333333
a company	0.001227
` the	0.062500
post -	1.000000
HMMs ,	0.125000
powerful	0.000029
brought together	1.000000
Wikipedia and	0.500000
recognition programs	0.008264
now more	0.076923
a campaign	0.001227
assist human	1.000000
accepts a	0.500000
lists	0.000029
for testing	0.003610
Peru .	0.500000
descriptions	0.000029
Blind -LRB-	0.500000
current major	0.142857
, adverbs	0.000561
effort .	0.250000
effort ,	0.250000
when moved	0.028571
whether to	0.076923
domain-independent and	1.000000
about nearly	0.025000
In speech	0.009524
, displayed	0.000561
an underlying	0.007576
considerably from	1.000000
lexicons -LRB-	0.500000
weights equal	0.200000
Writing -RRB-	1.000000
essentially identical	0.125000
continued development	0.111111
, paragraphs	0.000561
of contextual	0.000891
create summaries	0.058824
the Technolangue\/Easy	0.000692
utilize large	0.500000
C4 .5	1.000000
Aviation Authorities	1.000000
as BLEU	0.003484
for both	0.003610
addressee at	1.000000
Measuring progress	1.000000
more recent	0.010526
new complex	0.041667
morphosyntactic descriptor	1.000000
other potential	0.014286
until 1970	0.500000
for innumerable	0.003610
tuned	0.000029
as normalization	0.003484
Austrian	0.000029
multiplying	0.000029
Aggregation :	1.000000
hand-printed characters	0.250000
-LRB- IMR	0.002710
studies of	0.250000
derivation and	0.250000
and wrote	0.001445
, relay	0.000561
would contain	0.018868
indiscriminate	0.000029
produce vowels	0.045455
test example	0.100000
hits	0.000029
limits	0.000029
to unigram	0.001328
article contains	0.034483
ushered in	1.000000
estimation	0.000029
a deep	0.001227
different realizations	0.020408
relevance assessment	0.333333
may appear	0.019231
the so-called	0.000692
substantial ambiguity	0.200000
Braille texts	1.000000
essentially they	0.125000
teams in	0.500000
controlled	0.000029
its understanding	0.028571
as weights	0.003484
If a	0.100000
Inclusive	0.000029
single speaker	0.071429
The successful	0.005208
printed page	0.083333
considers the	0.500000
forms .	0.166667
be output	0.004219
We then	0.142857
open letter	0.250000
from that	0.009615
picture on	0.250000
problem than	0.022727
classification ,	0.058824
is generally	0.002033
rules through	0.023256
Use ''	0.500000
called machine	0.055556
, Janet	0.000561
Intrinsic vs.	0.333333
several alternative	0.045455
been closely	0.014706
off as	0.500000
business letters	0.250000
features might	0.038462
which could	0.007246
In 2002	0.009524
In 2006	0.009524
but we	0.014706
In 2004	0.009524
a 70	0.001227
discors	0.000029
distant	0.000029
by teletype	0.005714
-RRB- Parsing	0.002817
generate examples	0.055556
perhaps by	0.166667
the Eagles	0.000692
programmed by	0.500000
might vary	0.038462
headed	0.000029
disambiguation :	0.100000
an advanced	0.007576
disambiguation ,	0.100000
different angle	0.020408
disambiguation .	0.100000
, Case	0.000561
Nelson	0.000029
ease interoperability	1.000000
recently updated	0.333333
or existing	0.004505
and intra-texual	0.001445
appends	0.000029
payments	0.000029
in color	0.001873
generation of	0.111111
, approach	0.000561
International continued	1.000000
how summarization	0.034483
Arabic in	0.250000
usually can	0.031250
Translation ''	0.333333
of domain	0.000891
home	0.000029
development in	0.083333
quantitatively comparing	1.000000
had the	0.071429
slide represent	1.000000
getting enough	0.250000
demonstrated	0.000029
the '	0.000692
the .	0.000692
Up	0.000029
Archaeology	0.000029
fluency to	1.000000
to its	0.001328
diversity :	0.250000
etc. ;	0.045455
are designed	0.004149
etc. ,	0.045455
: lessons	0.009804
still contains	0.066667
that output	0.003546
of allowing	0.000891
whereas speed	0.333333
nets .	1.000000
SVOX	0.000029
video sub-titling	0.200000
of artifacts	0.000891
on his	0.004717
sense of	0.125000
language metamodel	0.006757
words being	0.009174
1950s included	0.250000
with which	0.005464
distribution of	0.250000
even languages	0.037037
against noise	0.200000
will approach	0.028571
are those	0.004149
single character	0.071429
that transcended	0.003546
multi-word phrases	1.000000
used about	0.008850
A technique	0.020000
system working	0.010753
pre-structured	0.000029
the sort	0.000692
education	0.000029
platforms .	1.000000
1956 and	1.000000
the ambiguity	0.000692
The Association	0.005208
same way	0.040000
EMNLP ,	1.000000
recursively defines	0.500000
additionally	0.000029
, and\/or	0.000561
by Naomi	0.005714
role of	0.250000
pronunciations or	1.000000
15-20	0.000029
turn requires	0.166667
might generate	0.038462
, support	0.000561
entire words	0.333333
from closely	0.009615
speech-enabled	0.000029
human languages	0.021739
function either	0.125000
of reasoned	0.000891
management task	0.142857
cursive characters	0.200000
Digitize	0.000029
This convinced	0.015873
Conversational	0.000029
grammars of	0.071429
robot in	0.500000
has unambiguously	0.011905
its entirety	0.028571
which kind	0.007246
telephone speech	0.500000
Hopper	0.000029
Keyphrase Extraction	0.250000
enhance	0.000029
department ,	0.500000
of generating	0.000891
nonexistent in	1.000000
turn simplified	0.166667
of heuristics	0.000891
more unmanageable	0.010526
note is	1.000000
indicating important	1.000000
<s> Few	0.000769
Information Science	0.200000
this particular	0.010989
poorly	0.000029
describing graphs	0.250000
to natural	0.001328
as separate	0.003484
interfaces Symantec	0.500000
's Stilstudien	0.019608
worlds ''	1.000000
identify ambiguities	0.083333
specific person	0.047619
each whole	0.022222
Open-domain	0.000029
letters are	0.100000
was demonstrated	0.012987
Constraints may	0.333333
the operation	0.000692
thus be	0.100000
have made	0.009615
to accurately	0.001328
`` depth	0.005291
room	0.000029
navigation ,	0.500000
feature or	0.076923
movies	0.000029
Fournier	0.000029
that interact	0.003546
in 1949	0.001873
exceptions	0.000029
little interference	0.333333
and 1957	0.001445
forth .	1.000000
10,000	0.000029
the learning	0.000692
: Determine	0.009804
linear representation	0.142857
centres require	1.000000
sad ,	1.000000
relevant .	0.142857
production when	0.333333
human beings	0.021739
four steps	0.142857
document\/text genre	0.500000
and Haton	0.001445
E ,	1.000000
unverified or	1.000000
<s> Adverse	0.000769
operate	0.000029
which ,	0.007246
specific tasks	0.047619
, time	0.000561
or 4-gram	0.004505
defined in	0.166667
which ?	0.007246
its designers	0.028571
and maximum	0.001445
grammar in	0.027027
concerning coherence	1.000000
Engineers ,	0.500000
summarization and	0.020000
Arabic ,	0.250000
<s> IBM	0.000769
Windows Mobile	1.000000
concept into	0.250000
typewritten messages	0.200000
not become	0.008929
networks Neural	0.071429
clauses	0.000029
on corpora	0.004717
two enabling	0.034483
its suitability	0.028571
testing .	0.200000
if one	0.035714
source can	0.041667
HMMs learn	0.125000
2004 ,	0.333333
2004 .	0.333333
larger sequences	0.062500
hard and	0.166667
interaction Genres	0.125000
together the	0.125000
with restricted	0.005464
-- only	0.040000
software Desktop	0.037037
of 5	0.000891
of 3	0.000891
of 1	0.000891
would contribute	0.018868
Ncmsan	0.000029
powerful grammars	1.000000
individual characters	0.083333
cares about	1.000000
Army ,	0.250000
paradigm of	0.333333
data about	0.012987
of N	0.000891
evaluation procedures	0.018519
more time-consuming	0.010526
light .	0.333333
facing more	1.000000
of selecting	0.000891
discussed between	0.142857
phonemes is	0.166667
States Postal	0.142857
Shepard ,	0.333333
are good	0.004149
Gripen	0.000029
phonemes in	0.166667
its polarity	0.028571
split ,	0.250000
States and	0.142857
should vertices	0.052632
which occur	0.007246
. .	0.062500
summaries -RRB-	0.023256
32 -RRB-	1.000000
as semiotics	0.003484
all four	0.023256
observation	0.000029
and pragmatics	0.001445
discussed above	0.142857
printed messages	0.083333
purpose of	0.200000
of 98	0.000891
of possibilities	0.000891
an interest	0.007576
in depth	0.001873
part-of-speech assignment	0.066667
timing for	1.000000
of incorrect	0.000891
direct and	0.166667
we normally	0.022222
always the	0.333333
generally lend	0.090909
, hopefully	0.000561
was nearly	0.012987
merges highly	1.000000
problem yet	0.022727
<s> Helicopters	0.000769
to refer	0.001328
recursive-descent parser	1.000000
each character	0.022222
linguistic term	0.062500
distant from	1.000000
sailor dogs	0.200000
ears	0.000029
automate sentiment	0.333333
particular method	0.076923
are needed	0.004149
<s> →	0.000769
a highly	0.001227
and classification	0.001445
improved computer	0.250000
some work	0.012048
Stephen H.	1.000000
a dog	0.001227
Unix operating	0.500000
that merges	0.003546
provides for	0.500000
coherent and	0.200000
McDonald	0.000029
2012 -RRB-	1.000000
Emanuel Schegloff	0.500000
verifiability .	1.000000
good insight	0.076923
remains to	0.250000
marketing .	1.000000
-LRB- CSIS	0.002710
and Plot	0.001445
, humans	0.000561
1952 .	0.500000
such capabilities	0.008130
some sort	0.012048
David H.	0.250000
often argued	0.022727
objects .	0.200000
MorphoChallenge Semi-supervised	1.000000
dismiss	0.000029
Flow	0.000029
this sentence	0.010989
Intelligence Corporation	0.333333
correct values	0.066667
morphemes -LRB-	0.333333
Process	0.000029
such statistical	0.008130
results reported	0.047619
Some classifiers	0.047619
weapon critical	0.500000
track	0.000029
time-scales	0.000029
have some	0.009615
methods assess	0.022727
communication Pragmatics	0.200000
whether each	0.076923
beyond polarity	0.166667
an online	0.007576
ōrātiōnis	0.000029
any significant	0.032258
which entertaining	0.007246
sequences are	0.111111
The target	0.005208
features indicating	0.038462
2500 articles	1.000000
approaches the	0.035714
requires humans	0.062500
or meets	0.004505
written ,	0.038462
other we	0.014286
readability and	1.000000
was declared	0.012987
without intervening	0.076923
In part-of-speech	0.009524
-LRB- unigram	0.002710
more quickly	0.010526
field since	0.037037
than instances	0.022222
text unit	0.006289
save	0.000029
David Nunan	0.250000
other 10	0.014286
Pollen	0.000029
Art	0.000029
c -RRB-	1.000000
as social	0.003484
by Makoto	0.005714
Are	0.000029
-LRB- written	0.002710
Grant ever	1.000000
somehow	0.000029
over most	0.083333
input gracefully	0.024390
linguistic rules	0.062500
weather data	0.142857
The rise	0.005208
translation requires	0.013514
although not	0.166667
and controlling	0.001445
from context	0.009615
often mentioned	0.022727
normal human	0.500000
with either	0.005464
left recursive	0.166667
education ,	1.000000
-LRB- Pallet	0.002710
sets in	0.090909
magazine	0.000029
for machine-translation	0.003610
NLP as	0.021277
Little	0.000029
the object	0.000692
1966 -RRB-	0.333333
refined	0.000029
-LRB- AVRADA	0.002710
anaphora	0.000029
1964 to	1.000000
does n't	0.100000
some NLP	0.012048
use `	0.013889
walking more	0.333333
editor	0.000029
fraction	0.000029
When we	0.142857
evaluated using	0.142857
even level	0.037037
, NAACL	0.000561
and non-annotated	0.001445
analyst	0.000029
not sound	0.008929
at helping	0.014706
distinguished .	1.000000
Independence :	1.000000
over a	0.083333
summary by	0.023810
algorithm As	0.035714
major issues	0.083333
agrees with	1.000000
discourse .	0.027778
basics and	1.000000
not as	0.008929
, George	0.000561
out of	0.071429
not an	0.008929
Word segmentation	0.142857
outside world	0.500000
Mobile Smartphones	0.333333
copying important	1.000000
cases --	0.055556
morphological ,	0.333333
match each	0.166667
following ``	0.066667
a mixture	0.001227
delimited .	0.250000
located anywhere	1.000000
emotional states	0.250000
make `	0.050000
organization -RRB-	0.200000
are difficult	0.004149
Austrian emigre	1.000000
adviser	0.000029
make ;	0.050000
voices or	1.000000
is searched	0.002033
, slowly	0.000561
fighter environment	0.166667
summarization methods	0.020000
display for	0.500000
those utility	0.045455
'' tag	0.005376
Abney S.	1.000000
signal is	0.166667
going over	0.250000
and merging	0.001445
unexpected	0.000029
A useful	0.020000
speech processing	0.006579
A.C. Nielsen	1.000000
targets	0.000029
performs	0.000029
Tagset ''	1.000000
Syntactic ;	1.000000
Black-box evaluation	0.500000
too -RRB-	0.166667
, up	0.000561
hierarchically	0.000029
its best	0.028571
marks and	0.250000
and recursive-descent	0.001445
of small	0.000891
form multi-word	0.050000
sample is	0.333333
of triple	0.000891
trained hidden	0.333333
real-world information	0.166667
For most	0.016393
quoting	0.000029
Abney	0.000029
abbreviation ,	0.500000
inherent expressivity	1.000000
in errata	0.001873
brain is	0.333333
Black-box vs.	0.500000
to program	0.001328
language interaction	0.006757
approximate meaning	0.500000
feedback .	0.500000
computer vision	0.022727
SR systems	0.333333
persuasion	0.000029
consumer ,	1.000000
and reporting	0.001445
UC -RRB-	0.500000
hitcha	0.000029
evaluation looks	0.018519
prior ranking	0.333333
absorbing states	0.333333
In one	0.009524
Software OCR	0.500000
an interlingual	0.007576
can select	0.005525
of overlap	0.000891
listed on	1.000000
visible light	0.333333
the spectrum	0.000692
waves that	0.142857
very sophisticated	0.024390
recorded speech	0.500000
workload	0.000029
individual speaker	0.083333
specialized output	0.500000
the vagueness	0.000692
concept is	0.250000
bridging	0.000029
performs simple	1.000000
` beyond	0.062500
of listening	0.000891
Civil Aviation	1.000000
of various	0.000891
feasible to	0.500000
Ken	0.000029
never went	0.200000
data for	0.012987
lowering of	1.000000
as ACL	0.003484
multi-platforms	0.000029
algorithm implicitly	0.035714
the functioning	0.000692
Sometimes	0.000029
assessing whether	1.000000
second ;	0.100000
Relevance -LRB-	1.000000
system whereby	0.010753
thus speech	0.100000
generic machine-generated	0.333333
-RRB- had	0.002817
or real	0.004505
this graph	0.010989
grammatical contexts	0.090909
summarizing multiple	1.000000
on different	0.004717
often quoted	0.022727
MLLR -RRB-	1.000000
department in	0.500000
segmentation process	0.030303
co-articulation of	1.000000
routing to	0.333333
1995 -RRB-	1.000000
BioCreative	0.000029
Recognizing the	1.000000
of entities	0.000891
... .	0.500000
shared concepts	0.500000
study based	0.250000
has turned	0.011905
specific context	0.047619
Current machine	0.200000
meanings according	0.250000
mining of	0.200000
The more	0.005208
next item	0.142857
Dr. Kenneth	1.000000
1950s by	0.250000
characters for	0.062500
LinguaSys	0.000029
written scripts	0.038462
attractive acoustic	0.333333
Data sources	1.000000
limited in	0.100000
needs additional	0.100000
of artificial	0.000891
'' all	0.005376
as PC	0.003484
document production	0.027778
: Translations	0.009804
Individuals	0.000029
unknown and	1.000000
the Annual	0.000692
markers over	0.333333
matching up	0.200000
, Reader	0.000561
3 ''	0.200000
weighted by	0.333333
Stephen	0.000029
portable .	0.333333
portable ,	0.333333
be ranked	0.004219
person\/persons	0.000029
personal computer	0.250000
converting printed	0.500000
the Morpholympics	0.000692
Eugene Charniak	1.000000
Stylistics	0.000029
and built	0.001445
often contains	0.022727
Grant	0.000029
Stylistics -LRB-	1.000000
Turn around	1.000000
Each concept	0.166667
citations for	0.333333
the larger	0.000692
human summary	0.021739
label	0.000029
generate .	0.055556
GRASSHOPPER algorithm	0.333333
measure based	0.090909
the SR	0.000692
has increased	0.011905
run on	0.200000
five different	0.200000
engineers worked	1.000000
have problems	0.009615
output with	0.038462
low agreement	0.333333
with other	0.005464
error types	0.083333
practice ,	0.500000
complicated statistical	0.333333
ones that	0.100000
an email	0.007576
a semantic	0.001227
voice has	0.076923
declaration	0.000029
, error-prone	0.000561
PageRank\/TextRank on	1.000000
A word	0.020000
matter .	0.333333
Machine Summarization	0.111111
large-vocabulary system	0.333333
paper skew	0.090909
techniques fall	0.043478
with pilots	0.005464
abstract synopsis	1.000000
for multi-document	0.003610
<s> Anaphora	0.000769
a distinction	0.001227
A year	0.020000
vocabulary size	0.125000
`` ask	0.005291
speech attached	0.006579
extended	0.000029
assist	0.000029
parse garden-path	0.111111
a choice	0.001227
that when	0.003546
identifiers	0.000029
other commercial	0.014286
directly comparable	0.200000
consisted	0.000029
children 's	0.500000
computed as	0.500000
syntactic structure	0.076923
by providing	0.005714
eigenvalue	0.000029
most widely	0.017241
content words	0.083333
lexical analyser	0.076923
and character	0.001445
analysts This	0.500000
RCA product	0.200000
input such	0.024390
QA The	0.047619
Eurofighter Typhoon	1.000000
would thus	0.018868
probabilistic and	0.142857
including sentiment	0.071429
psychotherapist ,	1.000000
Smith went	1.000000
the continuously	0.000692
shortened version	1.000000
Palm OS	1.000000
Claude Piron	1.000000
<s> Training	0.000769
English-like sentences	0.333333
machine to	0.012658
mentions ''	0.333333
sequences -LRB-	0.111111
affect is	0.333333
allowable substitutions	0.500000
while the	0.050000
sometimes suggest	0.076923
reverse process	0.500000
are claiming	0.004149
more probabilistic	0.010526
distinctions are	0.500000
word-frequency and	1.000000
skilled	0.000029
and easily	0.001445
no significant	0.076923
those of	0.045455
has increasingly	0.011905
first mechanized	0.030303
computer-aided analysis	0.333333
filter returns	0.500000
probabilities would	0.090909
workshops ,	0.500000
length using	0.125000
arranged	0.000029
one instance	0.015385
day did	1.000000
could just	0.062500
than by	0.022222
Stubbs	0.000029
online news	0.125000
again	0.000029
contextual or	0.500000
dramatically reduced	1.000000
are vulnerable	0.004149
measurement of	0.500000
towards this	1.000000
of global	0.000891
← barmaid	1.000000
% ;	0.025641
J. Phillips	0.333333
that had	0.003546
same meaning	0.040000
Size Grows	1.000000
founder	0.000029
, encoding	0.000561
Norval	0.000029
processing would	0.018519
is computed	0.002033
people 's	0.062500
upon which	1.000000
period may	0.500000
optimistic about	1.000000
QA performance	0.047619
feature segment	0.076923
and turns	0.001445
post-processed by	1.000000
procedures ,	0.250000
The popular	0.005208
human-generated model	0.500000
when processed	0.028571
and system	0.001445
analysis Variation	0.015385
online resource	0.125000
unwanted constructs	1.000000
characterized in	0.250000
less complex	0.083333
zero	0.000029
trainee controller	1.000000
instance text	0.071429
'' such	0.005376
and metrics	0.001445
coefficients ,	0.250000
fonts are	0.333333
coefficients .	0.250000
adjectives and	0.333333
can achieve	0.005525
's Law	0.019608
speech act	0.006579
5000	0.000029
languages words	0.020000
Svenka Savic	1.000000
as adjectives	0.003484
different similarity	0.020408
was made	0.012987
common-sense	0.000029
pictures or	1.000000
actual data	0.200000
are capitalized	0.004149
own it	0.166667
bilingual text	0.500000
given data	0.041667
know document	0.500000
by concatenating	0.005714
often span	0.022727
for language	0.003610
for single	0.003610
in multiscript	0.001873
providing customer	0.500000
hour	0.000029
phrasing	0.000029
is 2,000	0.002033
remain	0.000029
Competing semantic	1.000000
large dictionaries	0.043478
of annotated	0.000891
Incorporating	0.000029
In 1974	0.009524
In 1971	0.009524
In 1970	0.009524
In 1978	0.009524
as knowledge	0.003484
the total	0.000692
keyphrase containing	0.052632
some tasks	0.012048
expected answer	0.142857
formalisms\/languages .	1.000000
that you	0.003546
coming	0.000029
query-biased	0.000029
The common	0.005208
browsing by	1.000000
<s> Computationally	0.000769
a significant	0.001227
Forces	0.000029
special types	0.200000
or 45	0.004505
what sound	0.031250
robustness of	0.250000
SHRDLU and	0.166667
acts ,	0.333333
Interface ,	1.000000
therapy -LRB-	1.000000
most research	0.017241
Aletta	0.000029
generated by	0.066667
containing four	0.125000
usually perform	0.031250
CFG -LRB-	1.000000
engaging	0.000029
necessary subtask	0.100000
-LRB- Schank	0.002710
beginning to	0.500000
that involves	0.003546
only way	0.026316
Cook	0.000029
The best	0.005208
utility and	0.500000
candidate can	0.333333
Sentences	0.000029
often rely	0.022727
perspective .	0.250000
perspective ,	0.250000
analyze a	0.250000
analyze `	0.250000
titles ,	0.500000
`` Red	0.005291
some context	0.012048
adjective ,	0.142857
The second	0.005208
multiple topics	0.076923
adjective ;	0.142857
NASA	0.000029
<s> Military	0.000769
with only	0.005464
Question processing	0.142857
are unambiguous	0.004149
condense a	1.000000
affine and	1.000000
's usually	0.019608
first evaluation	0.030303
a proper	0.001227
a Rogerian	0.001227
score -LRB-	0.166667
normalization it	0.166667
as candidates	0.003484
on upper	0.004717
Transcription -LRB-	1.000000
dictionary is	0.142857
Research ,	0.125000
variation across	1.000000
% on	0.025641
% or	0.025641
Work on	0.500000
develop innovative	0.200000
chosen domains	0.200000
early text-to-speech	0.100000
the relevant	0.000692
the letter	0.000692
specific error	0.047619
lexical segment	0.076923
but only	0.014706
programmers	0.000029
, Elinor	0.000561
chart	0.000029
just ``	0.111111
ROUGE metric	0.200000
right-most derivations	1.000000
pronunciation ,	1.000000
factors which	0.333333
system can	0.010753
the door	0.000692
headlines	0.000029
in quite	0.001873
to human-written	0.001328
merges	0.000029
usually asked	0.031250
so far	0.033333
parsing concatenated	0.035714
merged	0.000029
conference headed	0.500000
: What	0.009804
commonly referred	0.125000
systems analyze	0.008929
news stories	0.076923
QUALM -LRB-	1.000000
lattices	0.000029
proportional to	1.000000
by visual	0.005714
than trying	0.022222
cases on	0.055556
DeRose used	0.200000
release parameters	0.333333
Perceptron	0.000029
Potter ,	1.000000
Morse	0.000029
Question book-new	0.142857
libraries for	0.500000
<s> Head-driven	0.000769
-LRB- corpus	0.002710
expert	0.000029
comprehensive model	0.200000
The 1970s	0.005208
tense ,	0.500000
delimiter .	1.000000
generation technology	0.111111
develop OCR	0.200000
vs. extrinsic	0.083333
selecting and	0.200000
can sometimes	0.005525
for male-female	0.003610
Yet	0.000029
put this	0.250000
human speakers	0.021739
extractive methods	0.142857
, discontinuous	0.000561
data maintained	0.012987
the LOB	0.000692
type as	0.071429
systems explore	0.008929
corresponding increase	0.166667
deferred	0.000029
, Invoice	0.000561
not remember	0.008929
user-specified or	0.500000
syllables ,	0.500000
, dynamic	0.000561
recognition benchmark	0.008264
^ 2	0.333333
and perhaps	0.001445
published .	0.142857
text can	0.006289
annotated and	0.500000
Scotland to	0.200000
GRASSHOPPER incorporates	0.333333
accurate recognition	0.142857
it extremely	0.008547
regions for	0.500000
deployed was	0.500000
negative examples	0.125000
the mechanical	0.000692
provide any	0.166667
scoring function	0.500000
NLP task	0.021277
speaker and	0.055556
, recorded	0.000561
arguably -RRB-	0.500000
explore what	0.250000
shape	0.000029
words appear	0.009174
normalize for	1.000000
cut	0.000029
rich languages	0.200000
of anaphora	0.000891
statistical decision-making	0.030303
Large-scale evaluation	1.000000
, Maximum	0.000561
These edges	0.058824
world ,	0.066667
search method	0.090909
1966 ,	0.333333
1966 .	0.333333
online opinion	0.125000
-LRB- creating	0.002710
as interlingual	0.003484
corpora that	0.090909
Management	0.000029
absolutely	0.000029
then generated	0.028571
: Dictionary-based	0.009804
yet to	0.500000
such problems	0.008130
a fair	0.001227
Harvey Sacks	1.000000
<s> Solutions	0.000769
as articles	0.003484
running Palm	0.333333
Chinese characters	0.142857
of people	0.000891
CKY algorithm	1.000000
aural feedback	1.000000
phones .	0.500000
of understanding	0.000891
the title	0.000692
an entity	0.007576
affects the	1.000000
choice with	0.125000
or printed	0.004505
Increase	0.000029
innovative Web-based	1.000000
NER -RRB-	1.000000
while ``	0.050000
steadily ,	1.000000
<s> Extracted	0.000769
required ,	0.142857
required .	0.142857
pumps last	0.500000
symbols defined	0.333333
their training	0.029412
to query	0.001328
also help	0.014493
spoken sentence	0.071429
positive ,	0.142857
could therefore	0.062500
have tested	0.009615
-LRB- DARPA	0.002710
, object	0.000561
was sold	0.012987
adjacent unigrams	0.166667
thus has	0.100000
votes from	1.000000
composing	0.000029
Commissioned	0.000029
logic ,	0.250000
only 10	0.026316
co-occurring	0.000029
and frequency	0.001445
evaluation methods	0.018519
ratings produced	0.111111
G ,	1.000000
implied	0.000029
Determine	0.000029
system at	0.010753
marking abbreviations	0.500000
document such	0.027778
, Charles	0.000561
The set	0.005208
masculine	0.000029
: Category	0.009804
implicitly	0.000029
startlingly	0.000029
the cost	0.000692
summaries helps	0.023256
as computational	0.003484
radio	0.000029
, isolated	0.000561
and split	0.001445
indicate that	0.333333
Referring expression	1.000000
Tigrinya	0.000029
and what	0.001445
sub-signals	0.000029
non-linear	0.000029
medicine or	1.000000
'' summary	0.005376
length .	0.125000
later became	0.100000
comprehension and	0.142857
It sometimes	0.026316
sentence must	0.020833
collect call	1.000000
that pollen	0.003546
clean it	0.500000
<s> Political	0.000769
accusative	0.000029
direction is	0.333333
, contractions	0.000561
generating natural	0.200000
on paper	0.004717
partial answers	1.000000
-LRB- ATC	0.002710
-LRB- ATN	0.002710
understanding and	0.030303
E	0.000029
rule-based ,	0.142857
Understanding Conference	0.500000
around Documents	0.125000
mid 1980s	1.000000
single word	0.071429
questioners expect	1.000000
collections vary	0.250000
, word	0.000561
The lowest	0.005208
Extract	0.000029
not in	0.008929
example demonstrates	0.012346
equipment based	0.333333
, abstraction	0.000561
Beginning in	0.500000
detected important	0.500000
OnlineOCR With	0.333333
varied	0.000029
two sequences	0.034483
47 %	1.000000
some measure	0.012048
where each	0.028571
ranked adjacent	0.200000
relationship with	0.166667
& Online	0.125000
or larger	0.004505
or XML	0.004505
flatbed scanner	1.000000
would difficult	0.018868
Natural ''	0.076923
because recognition	0.033333
securely ;	1.000000
a lattice	0.001227
getting ranked	0.250000
by Manfred	0.005714
to 150,000	0.001328
human meteorologist	0.021739
An 8	0.062500
equipment would	0.333333
`` automatic	0.005291
the direct	0.000692
preclude	0.000029
Q&A	0.000029
text accordingly	0.006289
Gary	0.000029
technologies --	0.250000
coughing ,	1.000000
highly ranked	0.111111
HTK toolkit	0.500000
developed dynamic	0.038462
ratings usually	0.111111
initial ,	0.333333
ranked by	0.200000
clarify	0.000029
shipment of	1.000000
during handwriting	0.100000
, classroom	0.000561
probabilities returned	0.090909
commands or	0.200000
paper-intensive industry	1.000000
right-most	0.000029
200 billion	0.500000
suffix	0.000029
not readily	0.008929
restricted vocabularies	0.250000
This system	0.015873
free beer	0.250000
FST ,	1.000000
in titles	0.001873
-LRB- UC	0.002710
retrained to	1.000000
scans	0.000029
it works	0.008547
explanation	0.000029
The Future	0.005208
heritage -LRB-	1.000000
are connected	0.004149
mission to	1.000000
SR system	0.333333
mail ,	0.500000
software for	0.037037
these topics	0.023810
These two	0.058824
Tauschek was	0.500000
is better	0.002033
and W.	0.001445
SPHINX toolkit	1.000000
extensive knowledge	0.333333
Ticket	0.000029
of spectral-domain	0.000891
healthcare	0.000029
prisoner	0.000029
by Su	0.005714
payment	0.000029
specification .	0.500000
important subproblem	0.062500
tasks typically	0.031250
software user	0.037037
disease	0.000029
international ATC	0.500000
, TNO	0.000561
list approach	0.090909
using ATC	0.016949
and this	0.001445
this can	0.010989
The interpretation	0.005208
near each	1.000000
graph small	0.076923
Tauschek had	0.500000
dependency parsers	0.200000
Shipibo .	0.500000
a background	0.001227
LexRank is	0.083333
Deciding what	1.000000
schemes to	0.500000
dimensions For	0.333333
simple natural	0.038462
high noise	0.055556
The Brill	0.005208
to it	0.001328
reputations	0.000029
challenging because	1.000000
might contain	0.038462
which merged	0.007246
TaleSpin	0.000029
applied the	0.066667
However such	0.027027
Part-of-speech tagging	0.500000
subjectivity used	0.500000
are ambiguities	0.004149
are actually	0.004149
` best	0.062500
on my	0.004717
to dry	0.001328
ideas ,	0.250000
and answers	0.001445
attribute grammars	0.500000
discussed in	0.142857
sub-sounds ,	1.000000
control ,	0.200000
with storing	0.005464
mainly on	0.166667
and French	0.001445
Bhatia ,	1.000000
the conversion	0.000692
opposed to	1.000000
headlines ,	1.000000
equal	0.000029
many written	0.019231
no distinction	0.076923
universities around	1.000000
current research	0.142857
the equipment	0.000692
-LRB- MCE	0.002710
search for	0.090909
simultaneously meets	0.500000
now looking	0.076923
assessments	0.000029
1983 ,	1.000000
General	0.000029
in politics	0.001873
attractive method	0.333333
interpreted as	1.000000
explored .	0.500000
sometimes confused	0.076923
will give	0.028571
If there	0.100000
's seminal	0.019608
can even	0.005525
be phrased	0.004219
one alternative	0.015385
at phrasing	0.014706
`` text	0.005291
parliament and	1.000000
longest running	1.000000
resources such	0.166667
not just	0.008929
NLP programs	0.021277
interim	0.000029
paraphrasing sections	1.000000
interpret and	1.000000
great importance	0.333333
recommending	0.000029
continued ,	0.111111
smart	0.000029
resolved	0.000029
meaning which	0.043478
background material	0.333333
classification decisions	0.058824
classifier and	0.142857
edit distances	1.000000
has yet	0.011905
displaced	0.000029
and DCD	0.001445
a scale	0.001227
happens	0.000029
some extent	0.012048
hurricane	0.000029
Church used	0.333333
of non-annotated	0.000891
the SPOTLIGHT	0.000692
toolkit is	0.500000
Nations materials	0.500000
relevant summaries	0.142857
' pyramid	0.052632
on Semantic	0.004717
scientific fields	0.500000
picture above	0.250000
you meant	0.076923
there as	0.025000
exclusively to	1.000000
really was	1.000000
Symbian and	1.000000
extrapolate that	1.000000
size -RRB-	0.166667
learned on	0.200000
not new	0.008929
and singular	0.001445
how often	0.034483
Approaches One	0.333333
condense	0.000029
textual summary	0.200000
approach of	0.028571
Electronic Health	0.500000
As well	0.055556
city .	1.000000
but when	0.014706
basic technology	0.076923
basic elements	0.076923
Speech understanding	0.032258
and transmitting	0.001445
front-end SR	1.000000
Paroubek	0.000029
we ultimately	0.022222
survey of	1.000000
included speech	0.125000
since ROUGE-1	0.100000
well-defined	0.000029
forms ,	0.166667
they belong	0.025000
identities	0.000029
possible -LRB-	0.041667
readable English	0.333333
corporation	0.000029
Wireless	0.000029
transformations to	0.500000
very rudimentary	0.024390
cheque	0.000029
interest was	0.090909
as high	0.003484
yesterday and	0.333333
any answer	0.032258
in time	0.001873
history -RRB-	0.250000
device required	0.500000
Lawrence Rabiner	1.000000
understanding can	0.030303
in French	0.001873
General Post	1.000000
caused	0.000029
dispense	0.000029
opinionated ,	1.000000
results suggest	0.047619
ROUGE -LRB-	0.200000
vastly	0.000029
phrase -LRB-	0.100000
, gestures	0.000561
noise -LRB-	0.125000
Alenia	0.000029
intelligent character	1.000000
Designing a	1.000000
itself or	0.200000
A summary	0.020000
speed for	0.142857
between computers	0.025641
like sentence	0.035714
Extracted	0.000029
additionally requires	1.000000
<s> Internet	0.000769
so accurate	0.033333
tools deploy	0.166667
the advantage	0.000692
linguistic discourse	0.062500
'' arguably	0.005376
feature\/aspect	0.000029
disagree with	0.333333
input can	0.024390
Word error	0.142857
be formally	0.004219
often do	0.022727
e.g. feature	0.017857
The readers	0.005208
Generation -LRB-	0.500000
offs	0.000029
either user-specified	0.100000
with equipment	0.005464
containing these	0.125000
'' do	0.005376
presented .	0.166667
adapted to	1.000000
essential difference	1.000000
continuously rendered	1.000000
up differently	0.045455
, real-time	0.000561
acts or	0.333333
excellent	0.000029
a central	0.001227
Mouffe	0.000029
for creating	0.003610
interpretation .	0.500000
estate	0.000029
Greek -LRB-	0.333333
automatically generate	0.047619
i.e. relationship	0.052632
is having	0.002033
possessives	0.000029
About 47	0.500000
reconfiguring them	1.000000
description	0.000029
HMMs involve	0.125000
horoscope	0.000029
accomplish with	1.000000
languages The	0.020000
infer where	1.000000
Working	0.000029
a text-understanding	0.001227
document reader	0.027778
be directed	0.004219
Extraction and	0.333333
phone call	0.250000
In Italy	0.009524
-RRB- question	0.002817
to normalize	0.001328
as from	0.003484
places ,	0.500000
The 10	0.005208
dog ''	0.333333
quickly ,	1.000000
five-star scale	1.000000
many person-years	0.019231
Spontaneous	0.000029
and know	0.001445
evaluation purposes	0.018519
space .	0.200000
determines how	0.333333
, international	0.000561
still to	0.066667
speech interface	0.006579
integrated information	0.333333
is growing	0.002033
independence	0.000029
by its	0.005714
substantial resources	0.200000
analysis algorithms	0.015385
cases one	0.055556
by interactive	0.005714
Described above	1.000000
copied and	0.500000
In about	0.009524
abbreviated	0.000029
fire truck	0.500000
researched	0.000029
To overcome	0.111111
speaker as	0.055556
Similarly ,	1.000000
While this	0.200000
despite the	0.333333
on-line recognition	0.333333
even ,	0.037037
, Driver-license	0.000561
it listens	0.008547
styles itself	1.000000
it takes	0.008547
could often	0.062500
stopwords	0.000029
consonants depends	0.333333
seminal	0.000029
bridge	0.000029
systems currently	0.008929
process new	0.027778
transformation ,	1.000000
demonstration in	0.200000
accusative ,	1.000000
-LRB- Computational	0.002710
enables several	1.000000
p. 32	1.000000
informational structures	0.500000
left-to-right	0.000029
the Defense	0.000692
70 's	0.250000
information need	0.021739
only real	0.026316
answers -RRB-	0.083333
informative enough	0.500000
process The	0.027778
Ticket stock	1.000000
German city	0.250000
the availability	0.000692
spite	0.000029
mark was	0.333333
, communicative	0.000561
-LRB- intonation	0.002710
is recall-based	0.002033
applications of	0.040000
any previous	0.032258
appropriate syntactic	0.250000
reads sections	0.500000
syntactic ,	0.076923
syntactic .	0.076923
have any	0.009615
Moore	0.000029
ongoing as	0.500000
Broadly ,	1.000000
harder and	0.142857
have several	0.009615
were spoken	0.024390
WYSIWYM	0.000029
learn parameters	0.076923
assembling output	1.000000
form ?	0.050000
asked and	0.333333
At Stanford	0.333333
to is	0.001328
to determining	0.001328
easily be	0.111111
approaches are	0.035714
Trek	0.000029
`` case	0.005291
successful demonstration	0.111111
or analysis	0.004505
response Mobile	0.500000
Among	0.000029
psycholinguistics when	0.500000
called morphological	0.055556
dogs →	0.142857
support question	0.250000
of being	0.000891
giving these	0.500000
Extractor -RRB-	1.000000
a reduced	0.001227
Kucera	0.000029
Interactive voice	0.500000
Reukos	0.000029
question and	0.023810
as Lisp	0.003484
inserts those	1.000000
and report	0.001445
B. ,	1.000000
FAS -RRB-	1.000000
, models	0.000561
extraction module	0.032258
different contexts	0.020408
Tell	0.000029
Mobile telephony	0.333333
limited vocabulary	0.100000
drawback	0.000029
order in	0.071429
symbol of	0.250000
decision-making	0.000029
to carry	0.001328
a core	0.001227
the stock	0.000692
best with	0.055556
`` inadequate	0.005291
even where	0.037037
assembling	0.000029
can decide	0.005525
- \/	0.062500
proposes	0.000029
of chatterbots	0.000891
is 7	0.002033
earliest-used algorithms	0.500000
keyphrases by	0.028571
must compute	0.071429
<verb> ←	1.000000
Behind	0.000029
David 's	0.250000
noun reading	0.071429
speech full	0.006579
Tokens are	1.000000
SAM -LRB-	1.000000
sidestepped	0.000029
this regard	0.010989
that overlap	0.003546
envelope based	1.000000
and question	0.001445
Topic	0.000029
Loebner prize	1.000000
speeds .	0.500000
Again	0.000029
rescoring -RRB-	1.000000
excerpt	0.000029
content alone	0.083333
camera ,	0.500000
camera .	0.500000
simply using	0.083333
SCU	0.000029
expressed like	0.166667
Beaugrande	0.000029
sentence with	0.020833
is coherent	0.002033
author wishes	0.333333
ensure	0.000029
Environment	0.000029
examples to	0.041667
annotating	0.000029
& Server	0.125000
in 2006	0.001873
in 2007	0.001873
in 2004	0.001873
chunks of	1.000000
automata	0.000029
by metrics	0.005714
processing news	0.018519
from an	0.009615
Alessandro Duranti	1.000000
have resulted	0.009615
for different	0.003610
factors ,	0.333333
`` New	0.005291
Realtime Speech	1.000000
voice response	0.076923
Subjectivity	0.000029
reader installed	0.100000
An ISO	0.062500
recursive-descent	0.000029
TextRank algorithm	0.071429
W. G.	0.500000
different ones	0.020408
deduction to	1.000000
his book	0.083333
keyphrases attached	0.028571
sensible manner	1.000000
or service	0.004505
-LRB- perhaps	0.002710
service with	0.200000
chatterbots were	0.500000
from all	0.009615
judge its	0.250000
to performance	0.001328
being conducted	0.055556
nouns or	0.111111
polarity classification	0.125000
beyond simple	0.166667
Norman Fairclough	0.500000
Church 's	0.333333
easily retrieved	0.111111
be written	0.004219
row	0.000029
controlling flight	1.000000
passage	0.000029
understanding or	0.030303
general format	0.045455
humans when	0.083333
with neural	0.005464
True\/False is	1.000000
posts	0.000029
`` zero	0.005291
feature\/aspect-based	0.000029
corp. .	1.000000
The ability	0.005208
, Norman	0.000561
radiology report	1.000000
a function	0.001227
involves ``	0.100000
technology providers	0.045455
compare them	0.142857
worth noting	0.500000
causing it	1.000000
<s> Users	0.000769
boundaries may	0.090909
easier task	0.125000
particularly prone	0.200000
considers an	0.500000
interaction with	0.125000
1 -LRB-	0.250000
medium -RRB-	0.333333
walking patterns	0.333333
and proper	0.001445
disruptive to	1.000000
TextRank results	0.071429
must first	0.071429
software finding	0.037037
some heuristic	0.012048
Sentiment Analysis	0.166667
deeply ,	1.000000
helps him	0.500000
variously	0.000029
In 1982	0.009524
broad and	0.250000
'' continued	0.005376
language production	0.006757
theory and	0.076923
As businesses	0.055556
Depending on	1.000000
computer based	0.022727
can then	0.005525
usability	0.000029
Integration	0.000029
different strategies	0.020408
hyphenation	0.000029
developed into	0.038462
Lichtenstein ?	1.000000
larger group	0.062500
vital	0.000029
` nice	0.062500
system with	0.010753
's EndWar	0.019608
or English-like	0.004505
, René	0.000561
on technology	0.004717
clear that	0.250000
Contains Confusable	1.000000
the whole	0.000692
feasible the	0.500000
constructed ,	0.500000
categories in	0.111111
subproblem of	1.000000
ōrātiōnis -RRB-	1.000000
not capitalize	0.008929
Higher	0.000029
Section ,	1.000000
describing each	0.250000
words by	0.009174
speaker-dependent system	1.000000
simple pro	0.038462
task requiring	0.023810
total number	0.500000
second -RRB-	0.100000
computer that	0.022727
exploring the	1.000000
sentiments expressed	1.000000
Profile templates	1.000000
considered -LRB-	0.111111
to predicting	0.001328
upgrade a	1.000000
not wear	0.008929
short time-scales	0.125000
rule-based machine	0.142857
sufficiently well	1.000000
given rise	0.041667
article then	0.034483
`` who	0.005291
statically	0.000029
not agree	0.008929
et al.	1.000000
or emails	0.004505
that for	0.003546
like PDF	0.035714
-LRB- probabilistic	0.002710
detecting the	1.000000
characteristics of	0.500000
program by	0.045455
questions pertaining	0.038462
person does	0.052632
often allows	0.022727
London -RRB-	1.000000
'' 100	0.005376
when translating	0.028571
, natural	0.000561
sounds very	0.066667
Little further	1.000000
compute various	0.500000
domain might	0.050000
quality criteria	0.100000
rank order	0.166667
underlying idea	0.333333
perspective in	0.250000
recognition instead	0.008264
<s> Closed-domain	0.000769
no spaces	0.076923
Australian physician	0.500000
, has	0.000561
support vector	0.250000
Wordnet	0.000029
AT&T libraries	1.000000
science -LRB-	0.100000
languages is	0.020000
animation	0.000029
this basic	0.010989
languages in	0.020000
Syphon	0.000029
correct result	0.066667
first pass	0.030303
and his	0.001445
, pruned	0.000561
both query	0.032258
of system-generated	0.000891
maintained by	0.500000
with American	0.005464
across their	0.200000
the corpus	0.000692
listening to	1.000000
program focuses	0.045455
expansion .	0.333333
CSIS ,	0.500000
for parsing	0.003610
An absorbing	0.062500
similarly effective	1.000000
upper-case letter	1.000000
Laclau	0.000029
summary -LRB-	0.023810
ROUGE measures	0.200000
Annual	0.000029
properties .	0.250000
properties ,	0.250000
Shared tasks	1.000000
jokes	0.000029
then run	0.028571
strong and	0.250000
nasality	0.000029
1928	0.000029
1929	0.000029
, contrast	0.000561
position and	0.250000
proceedings into	1.000000
participate in	1.000000
digital speech-to-text	0.142857
the testing	0.000692
the dominance	0.000692
acquiring	0.000029
computer automated	0.022727
V.J. ,	1.000000
inventor Jacob	1.000000
-- whole	0.040000
<s> Efficient	0.000769
filtering	0.000029
American Recovery	0.200000
relying on	1.000000
gestures in	0.500000
return ?	0.500000
knowledge on	0.037037
its immediate	0.028571
to grow	0.001328
He took	0.125000
paraphrasing	0.000029
So ,	0.333333
spirit	0.000029
identified in	0.200000
sales receipts	0.333333
Open	0.000029
-LRB- stationary	0.002710
section needs	0.166667
that allows	0.003546
generally without	0.090909
surrounding the	0.200000
granted	0.000029
system takes	0.010753
exploration ,	1.000000
dissertation .	0.333333
<s> Collection	0.000769
-LRB- ME	0.002710
relies	0.000029
often represented	0.022727
feature in	0.076923
their context	0.029412
relief	0.000029
more readily	0.010526
rated with	1.000000
appear .	0.062500
appear ,	0.062500
align recorded	1.000000
to break	0.001328
frame has	0.500000
the BORIS	0.000692
remembering ,	1.000000
character groups	0.045455
Tigrinya among	1.000000
's speech	0.019608
summaries humans	0.023256
attained .	1.000000
is slow	0.002033
their linguistic	0.029412
that larger	0.003546
Mars Polar	0.500000
vectors -LRB-	0.333333
they improved	0.025000
returned with	0.250000
becomes harder	0.250000
part-of-speech possibilities	0.066667
speeds made	0.500000
was followed	0.012987
structured into	0.166667
content present	0.083333
registry .	1.000000
Master	0.000029
concatenating the	1.000000
common tag	0.040000
not to	0.008929
and occurs	0.001445
called GRASSHOPPER	0.055556
improvement to	0.250000
Department of	1.000000
but vocabulary	0.014706
moon	0.000029
nor even	1.000000
by induction	0.005714
in isolation	0.001873
Speereo Voice	0.500000
fall in	0.250000
Variation analysis	1.000000
similarities to	0.500000
, Air	0.000561
Artificial neural	0.500000
matter of	0.333333
resulting from	0.250000
strong is	0.250000
increasingly complex	0.333333
healthcare is	1.000000
Compute	0.000029
time-consuming part	0.333333
applied successfully	0.066667
part-of-speech tagger	0.066667
the invention	0.000692
Syphon -LRB-	1.000000
seen the	0.100000
output than	0.038462
affect the	0.333333
more informative	0.010526
features in	0.038462
language such	0.006757
scientific and	0.500000
from improved	0.009615
table is	0.142857
co-occurrence in	0.333333
farther	0.000029
signing off	1.000000
disseminate it	1.000000
Rules post-processed	0.333333
felt -RRB-	1.000000
discrete phonetic	0.333333
wife	0.000029
pre-determined when	1.000000
, generating	0.000561
spaces ,	0.200000
interactive use	0.250000
spaces .	0.200000
Hendrix	0.000029
Linguistics defines	0.333333
2 ,	0.200000
early market	0.100000
or serving	0.004505
simulation of	0.333333
each choice	0.022222
the error	0.000692
list -LRB-	0.090909
system also	0.010753
whole of	0.111111
backward ,	1.000000
informative with	0.500000
novel	0.000029
leads	0.000029
the questions	0.000692
strongly to	0.500000
may generate	0.019231
Carla	0.000029
may all	0.019231
included -LRB-	0.125000
singular forms	0.250000
Deep approaches	1.000000
invention	0.000029
East	0.000029
Rule-based machine	0.500000
rainbow form	1.000000
a radiology	0.001227
diverse ''	0.500000
dry up	1.000000
took Harris	1.000000
and by	0.001445
of hours	0.000891
Amount line	1.000000
at level	0.014706
`` Statistical	0.005291
structure with	0.083333
<s> Topics	0.000769
The edges	0.005208
associated number	0.250000
Linguistics ''	0.333333
reached .	0.500000
non-linearly to	1.000000
because a	0.033333
are domain-independent	0.004149
aim is	0.500000
stages are	0.500000
of immunology	0.000891
information of	0.021739
relevant entities	0.142857
computers -RRB-	0.111111
experiment which	0.200000
Thompson	0.000029
scale rather	0.166667
You	0.000029
the lexicon	0.000692
personal computers	0.250000
R. Harris	0.166667
Granada Different	0.500000
: By	0.009804
specialized algorithms	0.500000
high-quality weather	1.000000
sometimes called	0.076923
ranking -LRB-	0.142857
adjacent sounds	0.166667
Fourier Transform	0.333333
Armed	0.000029
in computers	0.001873
sentence importance	0.020833
template slot	0.250000
a Japanese	0.001227
nouns were	0.111111
unverified	0.000029
Blommaert	0.000029
indifferent to	1.000000
and semi-supervised	0.001445
identify objects	0.083333
at University	0.014706
parser often	0.062500
system usability	0.010753
or dictionary	0.004505
first sentence-end	0.030303
, Carla	0.000561
Cohesion	0.000029
were limited	0.024390
SourceForge .	1.000000
instructions	0.000029
the perception	0.000692
robots ,	1.000000
into punched	0.012821
Dependence vs.	1.000000
of work	0.000891
-LRB- F-16	0.002710
processing ;	0.018519
processing :	0.018519
we do	0.022222
be available	0.004219
be separated	0.004219
had not	0.071429
Often natural	0.333333
public opinion	1.000000
pre-structured database	1.000000
multimedia -LRB-	0.500000
Oklahoma	0.000029
many significant	0.019231
since 1965	0.100000
words just	0.009174
this application	0.010989
widely applied	0.125000
them good	0.052632
transducer verifying	0.500000
methods related	0.022727
is steered	0.002033
counter examples	1.000000
humans deemed	0.083333
tongues	0.000029
Research in	0.125000
Convert information	0.500000
language-specific changes	1.000000
ARRA	0.000029
text ;	0.006289
entirety	0.000029
MAHS	0.000029
Edward Robinson	1.000000
MAHT	0.000029
as references	0.003484
satisfactory in	1.000000
the extremely	0.000692
be manually	0.004219
EMR according	0.333333
in Canada	0.001873
all lower	0.023256
thresholded to	1.000000
product .	0.142857
article is	0.034483
traditional	0.000029
consecutively and	1.000000
decomposition into	1.000000
and applications	0.001445
abstractive keyphrase	0.166667
and printed	0.001445
the annotation	0.000692
grammar-based methods	1.000000
Carbonell ,	1.000000
EARS project	1.000000
milliseconds -RRB-	0.500000
over an	0.083333
speakers might	0.250000
personnel .	1.000000
metrics correlate	0.111111
Biden visited	0.333333
typically based	0.055556
occurred in	1.000000
of allowable	0.000891
and entered	0.001445
or uttered	0.004505
tasks returning	0.031250
named IEEE	0.142857
code readers	0.142857
Koine	0.000029
proposed photographing	0.111111
paradigms	0.000029
At this	0.333333
pre-process data	1.000000
of parse	0.000891
More detailed	0.111111
accuracy include	0.032258
situation .	0.500000
an American	0.007576
extension of	1.000000
Beginning with	0.500000
information then	0.021739
recently there	0.333333
generates summaries	0.333333
Audio Processing	0.500000
, depends	0.000561
NIST role	0.500000
of Mandarin	0.000891
datum is	1.000000
<s> Glass-box	0.000769
proved negligibly	0.333333
concurrently	0.000029
sentenced separated	1.000000
probabilistically	0.000029
a facemask	0.001227
profile captures	0.333333
a cryptanalyst	0.001227
alone may	0.250000
create odd	0.058824
9	0.000029
more accurately	0.010526
most notoriously	0.017241
exigencies	0.000029
single PC	0.071429
's gonna	0.019608
Chinese or	0.142857
ATNs ''	0.333333
and visible	0.001445
project was	0.076923
a phone	0.001227
sophisticated understanding	0.142857
with DTW	0.005464
must make	0.071429
why certain	0.142857
unseen	0.000029
similar application	0.037037
Brain has	1.000000
must also	0.071429
may vary	0.019231
these tools	0.023810
as either	0.003484
predicting ratings	0.500000
past-tense verb	1.000000
and persuasion	0.001445
general with	0.045455
SCU in	1.000000
separately	0.000029
collect	0.000029
program can	0.045455
the successful	0.000692
Racter	0.000029
automatically do	0.047619
Pierce wrote	1.000000
most fundamental	0.017241
-LRB- though	0.002710
possibly others	0.500000
average text	0.500000
type ,	0.071429
to an	0.001328
segmentation between	0.030303
solved first	0.200000
five commands	0.200000
the Romance	0.000692
The loss	0.005208
text rather	0.006289
Learning Some	1.000000
vs. open	0.083333
n't for	0.250000
expect answers	0.333333
relationships between	0.166667
model of	0.033333
Manfred R.	1.000000
recognition equipment	0.008264
as horoscope	0.003484
produced ,	0.111111
long input	0.500000
popular journals	0.111111
approach used	0.028571
modal .	1.000000
comparable .	1.000000
stages of	0.500000
expressivity	0.000029
Voice Command	0.200000
a specialist	0.001227
capitalizes	0.000029
: GRASSHOPPER	0.009804
that depend	0.003546
vs. Independence	0.083333
Harris ,	0.111111
nearly perfect	0.500000
ever appear	1.000000
rainbow	0.000029
marked by	0.333333
it does	0.008547
licensed on	1.000000
On others	0.166667
speakers .	0.250000
ISO sub-committee	0.500000
HAMS =	1.000000
<s> Improved	0.000769
corresponding summaries	0.166667
comparative depths	1.000000
common cases	0.040000
which proposed	0.007246
paragraph summary	0.333333
Based	0.000029
Department	0.000029
have proposed	0.009615
world and	0.066667
requires fairly	0.062500
best word	0.055556
represented themselves	0.166667
exceeded the	1.000000
merge adjacent	1.000000
speaker ,	0.055556
cross-discipline	0.000029
corpus with	0.032258
`` breadth	0.005291
term meaning	0.055556
Barbara Johnstone	1.000000
-RRB- Transcription	0.002817
language without	0.006757
Levinsohn ,	1.000000
statistical output	0.030303
Lehnart	0.000029
one within	0.015385
NLG output	0.047619
document retrieval	0.027778
the wave	0.000692
19th	0.000029
substantial funding	0.200000
being said	0.055556
chose	0.000029
and generic	0.001445
and relevance	0.001445
monetary	0.000029
it statically	0.008547
Hands-free computing	1.000000
summary based	0.023810
a appropriate	0.001227
waves can	0.142857
the unsupervised	0.000692
leaving	0.000029
Palm	0.000029
Senseval and	1.000000
In common	0.009524
the written	0.000692
'' will	0.005376
up-to-date	0.000029
candidate passages	0.333333
human raters	0.021739
regression -LRB-	1.000000
Apart from	1.000000
different dialogues	0.020408
purpose when	0.200000
ask for	0.250000
typically around	0.055556
<s> Voice	0.000769
Eagles Guidelines	1.000000
input sentence	0.024390
Goldberg developed	0.500000
same problem	0.040000
possess -LRB-	1.000000
only do	0.026316
traditional linguistics	1.000000
, cognitive	0.000561
and subsequent	0.001445
Guy	0.000029
injuries to	1.000000
classification of	0.058824
this in	0.010989
Pike ,	1.000000
-LRB- 95	0.002710
notably to	0.333333
used over	0.008850
'' sentiment	0.005376
-LRB- 99	0.002710
imaging is	1.000000
image ,	0.333333
to doctors	0.001328
meet President	0.250000
lexicon representation	0.111111
roughness	0.000029
; no	0.021277
dog bites	0.333333
better guide	0.111111
decision-making ,	1.000000
recognizer	0.000029
working from	0.142857
a storm	0.001227
, Joseph	0.000561
techniques is	0.043478
BLEU measure	0.333333
the construction	0.000692
Black 1991	0.500000
stream of	0.500000
search Sentence	0.090909
social science	0.071429
interpreted	0.000029
computer processing	0.022727
: Sample	0.009804
of regular	0.000891
or Hard	0.004505
are structured	0.004149
when working	0.028571
additional constraints	0.166667
as interactivity	0.003484
well-known application	1.000000
edit	0.000029
as content	0.003484
lattices represented	1.000000
in Liu	0.001873
specific example	0.047619
syntactic coverage	0.076923
be asked	0.004219
prevent incorrect	1.000000
idea but	0.142857
which give	0.007246
Two particular	0.142857
Other measures	0.142857
interfaces such	0.500000
the morphemes	0.000692
in 1971	0.001873
'' vertex	0.005376
and LOB	0.001445
rate these	0.090909
Beigi	0.000029
shapes .	0.333333
absorbing random	0.333333
documents is	0.026316
indeed answer	0.333333
documents in	0.026316
describe words	0.166667
of distinctions	0.000891
thought-to-paper communication	1.000000
edited and	1.000000
American Bible	0.200000
An ongoing	0.062500
unknown	0.000029
T vertices\/unigrams	0.166667
excerpt containing	1.000000
and artificial	0.001445
language modeling	0.006757
measuring similarity	1.000000
decide that	0.250000
and continued	0.001445
the reason	0.000692
Peter	0.000029
some grammar	0.012048
the recognizer	0.000692
in CSR	0.001873
graph can	0.076923
that dispense	0.003546
having a	0.200000
having `	0.200000
person who	0.052632
generally amenable	0.090909
important points	0.062500
sources for	0.166667
as multi-document	0.003484
composing Braille	1.000000
given NLP	0.041667
A relationship	0.020000
period of	0.500000
system will	0.010753
, columns	0.000561
grammar to	0.027027
removing objective	0.500000
DARPA Speech	0.250000
text summarization	0.006289
NLG ;	0.047619
computer language	0.022727
co-occurring neighbors	1.000000
both time	0.032258
In practice	0.009524
agrees	0.000029
vs. objective	0.083333
extract a	0.250000
a widely-reported	0.001227
GPO	0.000029
materials .	0.500000
pseudo-pilot ''	0.500000
either manually	0.100000
knowledge system	0.037037
Dictionary-based machine	0.500000
ATIS	0.000029
translation paradigm	0.013514
neural-network output	1.000000
networks discussions	0.071429
like Ncmsan	0.035714
the gap	0.000692
; Analysis	0.021277
Another important	0.076923
opinions -RRB-	0.500000
Optophone ,	1.000000
's estimate	0.019608
bought	0.000029
opening	0.000029
a system-generated	0.001227
is meaningful	0.002033
sentences for	0.013158
Retrieval	0.000029
straightforward PCFGs	1.000000
unclear	0.000029
word-frequency	0.000029
is testing	0.002033
HMT -RRB-	1.000000
for editing	0.003610
approach allows	0.028571
the expectations	0.000692
, its	0.000561
The translator	0.005208
's methods	0.019608
of whom	0.000891
excellent application	1.000000
that occurs	0.003546
which bore	0.007246
concerns ;	0.500000
lightweight	0.000029
Driver-license OCR	1.000000
generate text	0.055556
largely been	0.200000
isolated-word recognizers	1.000000
procedure for	0.333333
Improved output	1.000000
largest	0.000029
of co-articulation	0.000891
The late	0.005208
machine for	0.012658
The fonts	0.005208
evaluation In	0.018519
is farther	0.002033
users and	0.111111
each sentence	0.022222
writing custom	0.111111
experimented with	1.000000
operation of	0.500000
heavily	0.000029
punctuation characters	0.142857
syntactic parsing	0.076923
I would	1.000000
extent with	0.250000
René Descartes	1.000000
an array	0.007576
to news-gathering	0.001328
One key	0.076923
fly have	1.000000
usage	0.000029
hurts ?	0.500000
evaluators	0.000029
i.e. text	0.052632
In languages	0.009524
Hulth showed	0.333333
Components	0.000029
expression just	0.100000
both very	0.032258
research were	0.023810
ARNS system	1.000000
generated readable	0.066667
natural as	0.013333
search by	0.090909
playing in	1.000000
'' occur	0.005376
12 such	0.200000
any QA	0.032258
summaries but	0.023256
SR while	0.333333
paste	0.000029
over 1,000	0.083333
-LRB- DTW	0.002710
are saying	0.004149
John McCarthy	0.125000
into canned	0.012821
experts of	1.000000
promise	0.000029
analysis tasks	0.015385
systems include	0.008929
improve information	0.076923
a piecewise	0.001227
Multilingual	0.000029
blocks to	0.250000
chosen publications	0.200000
where formal	0.028571
Prominent	0.000029
automates	0.000029
person\/persons rather	1.000000
surprisingly disruptive	0.333333
computer speech	0.022727
voice dialog	0.076923
meaningful relationships	0.125000
modern systems	0.200000
their closest	0.029412
1982 ,	0.333333
result in	0.090909
Vice President	1.000000
: expanded	0.009804
Up to	1.000000
data needed	0.012987
<s> Data	0.000769
beer ,	1.000000
and captioned	0.001445
some fundamental	0.012048
correctly-developed summaries	1.000000
speech dynamics	0.006579
kinds	0.000029
programmers began	1.000000
a negative	0.001227
be robust	0.004219
enabling technologies	1.000000
illustrates how	0.500000
, Adriana	0.000561
Since this	0.200000
sources ,	0.166667
new trend	0.041667
be solved	0.004219
errors per	0.200000
Italian -RRB-	0.500000
major limitation	0.083333
you see	0.076923
, second	0.000561
, UPV	0.000561
phone error	0.250000
applications there	0.040000
This new	0.015873
interpreter .	0.500000
This can	0.015873
prize	0.000029
potentially more	0.333333
required to	0.142857
`` have	0.005291
succession	0.000029
brain .	0.333333
the separate	0.000692
fully solved	0.166667
or legal	0.004505
books a	1.000000
by this	0.005714
Multimodal	0.000029
then used	0.028571
regard .	0.200000
explained	0.000029
one needs	0.015385
existing so	0.200000
fundamental ,	0.500000
spoke	0.000029
abbreviation MT	0.500000
subdivided into	1.000000
technology useful	0.045455
commanding an	1.000000
telegraph	0.000029
standardised text	1.000000
the affect	0.000692
processing uses	0.018519
involves visual	0.100000
are SHRDLU	0.004149
rate still	0.090909
language might	0.006757
organized	0.000029
appear within	0.062500
and waves	0.001445
sentence extraction	0.020833
be approximately	0.004219
rudimentary way	0.500000
as sounds	0.003484
values ,	0.125000
was installed	0.012987
Comparing these	1.000000
preferable	0.000029
word processors	0.016667
manually designed	0.250000
a unit	0.001227
paper legal	0.090909
But from	0.166667
By combining	0.333333
these programs	0.023810
, Mariani	0.000561
with corpus	0.005464
line of	0.333333
claim that	1.000000
which recursively	0.007246
the technology	0.000692
HAMS	0.000029
Extrinsic evaluations	0.500000
Modern speech	0.333333
of code	0.000891
Unicode Consortium	1.000000
as text	0.003484
the SIGGEN	0.000692
that most	0.003546
toward actions	1.000000
create texts	0.058824
used more	0.008850
narrowest	0.000029
A random	0.020000
a newspaper	0.001227
1953 U.S.	1.000000
sound into	0.050000
's NLP	0.019608
two distinct	0.034483
Z ''	1.000000
, speed	0.000561
Functional	0.000029
stationary probability	0.142857
expectancy	0.000029
classify a	0.500000
coherent sequences	0.200000
of general	0.000891
using ``	0.016949
reached 20,000	0.500000
by no	0.005714
, common	0.000561
refined score	1.000000
probability ,	0.142857
effectively utilize	0.333333
the smaller	0.000692
match certain	0.166667
insights .	1.000000
task-effectiveness at	0.500000
the E-set	0.000692
or from	0.004505
\* ''	0.250000
whose usage	0.333333
settings .	1.000000
high recognition	0.055556
in fundamentally	0.001873
specific contexts	0.047619
a dissertation	0.001227
Stemming	0.000029
is phonetically	0.002033
assigned ,	0.500000
on new	0.004717
section of	0.166667
to mention	0.001328
bottom-up	0.000029
of SHRDLU	0.000891
while Snyder	0.050000
to gather	0.001328
listed	0.000029
underlie	0.000029
speech tagger	0.006579
be divided	0.004219
the schematic	0.000692
computer extracting	0.022727
fraction of	1.000000
MT performs	0.200000
annotation has	0.250000
and counter	0.001445
iteration	0.000029
these terms	0.023810
a succession	0.001227
a naval	0.001227
designers ,	1.000000
responsible	0.000029
Loebner	0.000029
and instead	0.001445
causing	0.000029
sentiment classification	0.040000
also continue	0.014493
-LRB- ōrātiōnis	0.002710
is going	0.002033
would use	0.018868
GRACE d'évaluation	1.000000
over sixty	0.083333
to correct	0.001328
also characterized	0.014493
Process .	1.000000
1997 -LRB-	0.500000
professor	0.000029
meaningful symbol	0.125000
patterns in	0.200000
perform functions	0.090909
prolific inventor	1.000000
improve readability	0.076923
copy	0.000029
which may	0.007246
improve performance	0.076923
save time	1.000000
and converted	0.001445
Issues While	0.500000
looking at	0.200000
best model	0.055556
notion that	0.250000
as some	0.003484
also quite	0.014493
, Theo	0.000561
, enables	0.000561
disambiguation -LRB-	0.100000
on content	0.004717
cutoff to	1.000000
remember the	1.000000
, Alessandro	0.000561
process Flow	0.027778
M. De	0.250000
fair	0.000029
7110.65	0.000029
known what	0.038462
intended meaning	0.200000
accuracy was	0.032258
companies to	0.500000
in logical	0.001873
system recognizes	0.010753
actioning it	1.000000
assigned keywords	0.500000
removed .	1.000000
word separators	0.016667
two approaches	0.034483
a consideration	0.001227
simple queries	0.038462
cards	0.000029
subtasks that	0.500000
that assigns	0.003546
of British	0.000891
than speech	0.022222
profile feature	0.333333
With discontinuous	0.142857
learning methods	0.023256
adapted	0.000029
syntactic relations	0.076923
integrate reasoning	1.000000
languages which	0.020000
linguistically	0.000029
's idea	0.019608
involved ,	0.166667
summarization Like	0.020000
Jaworski ,	1.000000
model will	0.033333
among the	0.125000
looks at	0.250000
Regardless of	1.000000
: Digitize	0.009804
keyphrase ,	0.052632
keyphrase .	0.052632
is it	0.002033
turns and	0.333333
than processing	0.022222
in those	0.001873
- Top-down	0.062500
or function	0.004505
sets ,	0.090909
A document	0.020000
, consisting	0.000561
naval battle	0.333333
a top-down	0.001227
, going	0.000561
relevant information	0.142857
, The	0.000561
user profile	0.071429
Books like	1.000000
developed and	0.038462
despite warnings	0.333333
same method	0.040000
conversation or	0.250000
ambiguity than	0.125000
distorted ,	0.500000
mutual information	1.000000
brain recognizes	0.333333
methods is	0.022727
augmented transition	1.000000
the dynamic	0.000692
4 letters	0.200000
conceptual ontologies	0.500000
4 ,	0.200000
a category	0.001227
probabilistic rules	0.142857
's coherence	0.019608
is fairly	0.002033
own right	0.166667
, electrical	0.000561
Algorithms Both	0.500000
Health Organization	0.500000
Apart	0.000029
equivalence is	0.500000
analog wave	0.500000
a revolution	0.001227
rushing to	1.000000
articulated	0.000029
resource consumption	0.200000
two measures	0.034483
typically from	0.055556
Greek and	0.333333
commonplace	0.000029
entropy model	0.200000
<s> Even	0.000769
sociology	0.000029
on automatically	0.004717
traditionally made	0.500000
Records -LRB-	1.000000
2007 and	0.200000
E-set	0.000029
overcome this	0.500000
shifting	0.000029
F-16 VISTA	0.500000
may also	0.019231
the neural-network	0.000692
Canada are	0.166667
Inter-rater reliability	1.000000
Every acoustic	1.000000
simulators with	1.000000
started the	0.250000
A high	0.020000
<s> Battle	0.000769
other are	0.014286
Wireless World	1.000000
icon	0.000029
happy	0.000029
MAHT and	1.000000
explicitly promoting	0.250000
rubric includes	1.000000
meaningful information	0.125000
De Guzman	1.000000
deliberately inserts	1.000000
Language Processor	0.083333
Depending	0.000029
proven	0.000029
like Japanese	0.035714
The parser	0.005208
though the	0.100000
exist	0.000029
strengths and	0.500000
for What	0.003610
the vertices	0.000692
unambiguously	0.000029
task can	0.023810
Reading the	0.500000
late 1950s	0.111111
tagging words	0.040000
use techniques	0.013889
each observed	0.022222
full progress	0.200000
language-processing tasks	1.000000
The improvement	0.005208
explore the	0.250000
: control	0.009804
cross-lingual questions	0.500000
first word	0.030303
meaning and	0.043478
dimensionality	0.000029
of logical	0.000891
his company	0.083333
, Systran	0.000561
process termed	0.027778
Arabic and	0.250000
Bernard Vauquois	1.000000
interface .	0.250000
also includes	0.014493
produced word	0.111111
team	0.000029
statistics -LRB-	0.125000
conveyed via	1.000000
prevent	0.000029
largely an	0.200000
topics in	0.142857
with models	0.005464
into ``	0.012821
contrastive	0.000029
and domain	0.001445
see LMF	0.050000
estimate sentence	0.250000
examples where	0.041667
assertive	0.000029
workday to	1.000000
statistical engine	0.030303
studied	0.000029
related in	0.066667
about machine	0.025000
and Intelligence	0.001445
-LRB- RAE	0.002710
investigates the	1.000000
identification .	0.200000
all been	0.023256
Although these	0.125000
: Error	0.009804
of ISO\/TC37	0.000891
introducing	0.000029
tagger to	0.111111
be assumed	0.004219
recommendations and	1.000000
and world	0.001445
ambitious projects	1.000000
translation MAHT	0.013514
systems depended	0.008929
descriptor	0.000029
believed	0.000029
design and	0.250000
been successfully	0.014706
walks .	0.500000
some states	0.012048
recognition research	0.008264
map one	0.500000
`` generalized	0.005291
necessary ,	0.100000
<s> POS	0.000769
triples that	0.333333
single binary	0.071429
parameter	0.000029
T. 1991	1.000000
differ ,	0.333333
appends the	1.000000
well that	0.035714
words occur	0.009174
& Lehrberger	0.125000
ISO\/TC37	0.000029
yielding	0.000029
decades -LRB-	1.000000
encourage systems	1.000000
better understanding	0.111111
relations -LRB-	0.083333
, resulting	0.000561
text summaries	0.006289
, size	0.000561
ICR make	0.333333
is dependency	0.002033
code of	0.142857
decelerations	0.000029
code on	0.142857
ANR-Passage project	1.000000
decades	0.000029
presented to	0.166667
mention that	0.333333
Angenot ,	1.000000
allows movement	0.125000
Direct Voice	1.000000
PCFGs	0.000029
properly the	0.500000
sequences that	0.111111
Battle management	0.500000
Transcription	0.000029
the draft	0.000692
or automotive	0.004505
Online ,	0.500000
word spaces	0.016667
contained	0.000029
spectrum using	1.000000
Joe	0.000029
interactivity	0.000029
uncertainties	0.000029
Braille	0.000029
the Ohio	0.000692
decision-support aids	1.000000
was considerable	0.012987
analysis model	0.015385
avoid confusion	1.000000
currently the	0.142857
address this	0.250000
science that	0.100000
are exceptions	0.004149
PC can	0.250000
nested	0.000029
answering There	0.083333
blocks ,	0.250000
conditions .	0.200000
text cohesion	0.006289
multiple part-of-speech	0.076923
to maintain	0.001328
tree -LRB-	1.000000
her to	0.500000
product was	0.142857
developed to	0.038462
where an	0.028571
page scanner	0.142857
Xuedong Huang	1.000000
where at	0.028571
systems take	0.008929
considerably	0.000029
similar clues	0.037037
Document structuring	0.250000
intuitive sense	1.000000
English prose	0.027027
in walking	0.001873
morphology -LRB-	0.142857
other to	0.014286
domain-specific keyphrase	0.500000
evaluation has	0.018519
<s> Information	0.000769
have ''	0.009615
then extrapolate	0.028571
use considers	0.013889
<s> Where	0.000769
decisions or	0.100000
re-encode the	1.000000
called recursively	0.055556
Trained	0.000029
distinct parts	0.142857
topic were	0.125000
definite	0.000029
system depend	0.010753
hand-crafted knowledge	0.500000
After the	0.333333
to ignore	0.001328
the AVRADA	0.000692
expressed in	0.166667
or sentences	0.004505
fastens -LRB-	1.000000
of commercial	0.000891
System -RRB-	1.000000
greater than	0.333333
Intelligence and	0.333333
neighbors are	0.333333
easier for	0.125000
rule-based algorithms	0.142857
Specifically	0.000029
Yes\/No	0.000029
happen between	1.000000
voicemail to	1.000000
isloated and	1.000000
components that	0.200000
not always	0.008929
BLEU is	0.333333
stochastic methods	0.125000
Driver-license	0.000029
an autopilot	0.007576
Bible	0.000029
while verbs	0.050000
documents at	0.026316
through its	0.125000
the interlingua	0.000692
lexical resources	0.076923
HMM states	0.333333
deduction	0.000029
<s> Shared	0.000769
<s> Matches	0.000769
to closely	0.001328
comprehensive hand-crafted	0.200000
though such	0.100000
dispense with	1.000000
combines	0.000029
other task	0.014286
same characters	0.040000
Bottom-up parsing	1.000000
startlingly human-like	1.000000
important by	0.062500
waves describe	0.142857
European Parliament	0.333333
or language	0.004505
Projects Agency	1.000000
be apparent	0.004219
consist of	1.000000
Shift-Reduce	0.000029
<s> Introduction	0.000769
project .	0.076923
the pragmatics	0.000692
include SpeechTEK	0.037037
<s> Vulcan	0.000769
be ?	0.004219
exception ,	1.000000
Grows :	1.000000
, keyphrases	0.000561
structures of	0.200000
be .	0.004219
that closely	0.003546
frequencies ,	0.500000
bridge the	1.000000
analysis to	0.015385
Orleans by	0.500000
computer read	0.022727
, searching	0.000561
See chart	0.166667
`` Tell	0.005291
by highly	0.005714
I	0.000029
usually have	0.031250
unmanageable	0.000029
defined to	0.166667
technology development	0.045455
costs	0.000029
Analysis &	0.200000
any learning	0.032258
recognition products	0.008264
What should	0.090909
Judith	0.000029
table ''	0.142857
SVM	0.000029
greatly with	0.142857
unknowns ,	1.000000
may happen	0.019231
responding to	1.000000
projects never	0.500000
then there	0.028571
voice user	0.076923
of 2009	0.000891
Navy ,	1.000000
a precise	0.001227
is functioning	0.002033
`` Computing	0.005291
voice and	0.076923
vendors speech	0.250000
short paragraph	0.125000
function with	0.125000
authenticate	0.000029
it Contains	0.008547
might appear	0.038462
identifying trends	0.166667
Projects	0.000029
Algorithm -RRB-	1.000000
A somewhat	0.020000
Other issues	0.142857
even human	0.037037
below 50	0.200000
Foucault ,	0.333333
this information	0.010989
Jefferson ,	1.000000
of tourism	0.000891
a rate	0.001227
where syllables	0.028571
to think	0.001328
instead recognizes	0.142857
automated language	0.142857
parties	0.000029
its vocabulary	0.028571
like Page\/Lex\/TextRank	0.035714
Decoding of	0.500000
makes use	0.125000
tokens ,	0.142857
research teams	0.023810
Commanders and	1.000000
knowledge or	0.037037
abbreviations -RRB-	0.200000
translation Example-based	0.013514
general speaker	0.045455
help improve	0.111111
corresponding text	0.166667
Therein lies	1.000000
gone	0.000029
World Health	0.142857
-LRB- 1993	0.002710
a syntactic	0.001227
-LRB- 1995	0.002710
poor coverage	1.000000
space exploration	0.200000
Semantic analysis	0.333333
ambiguities and	0.250000
entry from	0.250000
American prisoners	0.200000
classifiers -RRB-	0.500000
slang	0.000029
Telematics	0.000029
1978 Kurzweil	0.333333
related languages	0.066667
funding continued	0.125000
objects listed	0.200000
mimic	0.000029
different vendors	0.020408
about how	0.025000
toy world	0.500000
technology has	0.045455
, various	0.000561
be nested	0.004219
which class	0.007246
than 1	0.022222
-RRB- examples	0.002817
MT Hybrid	0.200000
that involve	0.003546
authenticate or	1.000000
small incremental	0.111111
researchers in	0.100000
condition	0.000029
% -RRB-	0.025641
score based	0.166667
accompanying	0.000029
sentences Grass	0.013158
Vito	0.000029
queries ,	0.333333
`` Dogged	0.005291
sublanguage analysis	0.333333
hopefully	0.000029
not spend	0.008929
the informal	0.000692
into modern	0.012821
OCR-A font	1.000000
training a	0.035714
confirmed by	1.000000
would reduce	0.018868
card spending	0.250000
real ATC	0.111111
human variability	0.021739
different grammatical	0.020408
versions needed	0.333333
While supervised	0.200000
identified is	0.200000
without understanding	0.076923
no knowledge	0.076923
person uses	0.052632
MLLR	0.000029
MLLT	0.000029
training .	0.035714
perfect -LRB-	1.000000
which range	0.007246
research to	0.023810
they take	0.025000
not President	0.008929
also require	0.014493
representation into	0.052632
of part	0.000891
phrases are	0.062500
will contain	0.028571
Meaningful	0.000029
procedure lies	0.333333
features characterize	0.038462
much easier	0.045455
indicating	0.000029
TNO developed	1.000000
produces less	0.250000
prefer to	0.500000
UMLS	0.000029
<s> Grammatical	0.000769
approaches used	0.035714
well captured	0.035714
Nagao in	1.000000
SHRDLU simulated	0.166667
socio-psychological	0.000029
program were	0.045455
rank unigrams	0.166667
the representation	0.000692
imagery	0.000029
<s> the	0.000769
capabilities ,	0.200000
meaningful units	0.125000
and Tigrinya	0.001445
radios	0.000029
In 1949	0.009524
of n-dimensional	0.000891
representation can	0.052632
of identifiers	0.000891
opinion expressed	0.200000
, linguistic	0.000561
, facts	0.000561
pragmatics .	0.333333
formal modeling	0.111111
claiming to	1.000000
output scores	0.038462
common when	0.040000
quite similar	0.125000
been carried	0.014706
tools require	0.166667
Newton	0.000029
blogs ,	0.500000
this would	0.010989
of ability	0.000891
errata	0.000029
often a	0.022727
perhaps trivial	0.166667
parser generates	0.062500
intrinsic properties	0.250000
grouped with	0.500000
Translations	0.000029
Machine Aided	0.111111
linguistic knowledge	0.062500
informativeness .	0.333333
triple probabilities	1.000000
for can	0.003610
often .	0.022727
often ,	0.022727
imaging	0.000029
<s> Stages	0.000769
imagine	0.000029
for English	0.003610
Shepard 's	0.333333
overlaps between	0.500000
<s> Brain	0.000769
pronunciations	0.000029
whole words	0.111111
create ''	0.058824
two given	0.034483
explored using	0.500000
use natural	0.013889
Phonemes ,	1.000000
Corporation originally	0.250000
management Question	0.142857
which creates	0.007246
and insurance	0.001445
declared during	0.500000
-LRB- University	0.002710
immediate	0.000029
consult	0.000029
focusing	0.000029
original .	0.076923
<s> Task	0.000769
KEA	0.000029
for large-vocabulary	0.003610
so-called ROUGE	0.333333
or applying	0.004505
, pollen	0.000561
He tried	0.125000
Transform ,	1.000000
analogy	0.000029
slang .	1.000000
substantial amount	0.200000
play	0.000029
important memorandum	0.062500
than whole	0.022222
that nuggets	0.003546
vertex would	0.333333
cover	0.000029
decisions .	0.100000
fast-evolving field	1.000000
2PR	0.000029
international relations	0.500000
the labor	0.000692
applies to	0.142857
algorithms is	0.028571
endeavors such	1.000000
take as	0.100000
other country	0.014286
five-star	0.000029
they would	0.025000
paper data	0.090909
Major tasks	0.500000
and alignment	0.001445
-LRB- DeRose	0.002710
at characters	0.014706
and R.	0.001445
These rules	0.058824
text printed	0.006289
radio frequencies	1.000000
for gestures	0.003610
invented examples	0.500000
the sampling	0.000692
as Google	0.003484
Anaphora resolution	1.000000
concept -LRB-	0.250000
simply ranks	0.083333
logic structures	0.250000
to error	0.001328
agglutinative languages	1.000000
corresponds	0.000029
community	0.000029
as humans	0.003484
applications it	0.040000
Separate words	0.500000
their lack	0.029412
difference can	0.250000
their stationary	0.029412
as relations	0.003484
XML	0.000029
is distinct	0.002033
shifted priorities	1.000000
, Wendy	0.000561
its users	0.028571
edges with	0.142857
the predicted	0.000692
used all	0.008850
training document	0.035714
formats	0.000029
PangeaMT ,	1.000000
shed light	1.000000
probability what	0.142857
all cases	0.023256
made with	0.062500
Mars Microphone	0.500000
is different	0.002033
expand our	1.000000
more formal	0.010526
features like	0.038462
understanding programs	0.030303
-RRB- \/	0.002817
Campaigns -RRB-	1.000000
is again	0.002033
correlation between	0.500000
single words	0.071429
that represents	0.003546
application may	0.071429
chosen is	0.200000
, Brenton	0.000561
used the	0.008850
order ''	0.071429
dialogue in	0.500000
had plateaued	0.071429
European Union	0.333333
um ''	1.000000
be ``	0.004219
location	0.000029
are hardly	0.004149
textbook is	0.500000
sales reports	0.333333
linguistics -LRB-	0.050000
Larry R.	0.500000
apply the	0.200000
not hear	0.008929
unweighted edges	1.000000
currently in	0.142857
hopefully better	1.000000
often ambiguous	0.022727
have also	0.009615
printed pages	0.083333
simple voice	0.038462
report in	0.250000
tagging has	0.040000
block of	1.000000
interpreters	0.000029
protection from	1.000000
EndWar and	1.000000
adaptation greatly	0.333333
VITO	0.000029
constructed by	0.500000
of virtual	0.000891
major degradation	0.083333
in generating	0.001873
anything	0.000029
of unlabeled	0.000891
just keeping	0.111111
A restricted	0.020000
Jones Street	1.000000
both isloated	0.032258
bites dog	0.333333
adverbs	0.000029
Again ,	1.000000
shops in	1.000000
and trigram	0.001445
build on	0.333333
retrieving	0.000029
from both	0.009615
the ten-year-long	0.000692
1982 Gary	0.333333
translator for	0.142857
problem with	0.022727
to authenticate	0.001328
meaning into	0.043478
relaxed	0.000029
was recognized	0.012987
, Jonathan	0.000561
of negative	0.000891
is at	0.002033
is as	0.002033
merely copy	0.500000
themselves simply	0.250000
with references	0.005464
be taken	0.004219
basic techniques	0.076923
optimizing a	1.000000
customize the	0.500000
small range	0.111111
are multiple	0.004149
knowledge .	0.037037
robots	0.000029
We have	0.142857
methods QA	0.022727
variant of	1.000000
decisions --	0.100000
term first	0.055556
often inaccurate	0.022727
essay	0.000029
`` Application-Oriented	0.005291
noise in	0.125000
Stef	0.000029
with medium	0.005464
must interpret	0.071429
garden	0.000029
categorization ,	1.000000
Speech Writing	0.032258
the translator	0.000692
not describe	0.008929
after John	0.083333
and orthography	0.001445
in information	0.001873
identify new	0.083333
, definition	0.000561
are keyphrase	0.004149
to derive	0.001328
Cross-Sentence Information	1.000000
internet discussion	1.000000
depth of	0.333333
now commonplace	0.076923
an Inuit	0.007576
returned by	0.250000
index	0.000029
funding Measuring	0.125000
Alan	0.000029
better than	0.111111
typically involved	0.055556
textual summaries	0.200000
units --	0.142857
Richard Kittredge	1.000000
non-linearly	0.000029
, PAM	0.000561
, mainly	0.000561
recognition deteriorated	0.008264
Energy	0.000029
EMNLP	0.000029
place at	0.250000
find answers	0.076923
which generates	0.007246
Prominent discourse	1.000000
and simpler	0.001445
editing and	0.500000
became less	0.200000
7110.65 details	1.000000
recently identified	0.333333
Applied Intelligence	0.500000
comes to	0.200000
saw the	1.000000
occurred	0.000029
USAF	0.000029
relationships .	0.166667
had been	0.071429
At the	0.333333
Systems -RRB-	0.083333
reports ,	0.200000
symbols ,	0.333333
the computer-aided	0.000692
is doing	0.002033
-LRB- monetary	0.002710
, recently	0.000561
separated out	0.333333
difficult words	0.035714
He entered	0.125000
While some	0.200000
imagine the	1.000000
generating the	0.200000
four step	0.142857
Ingria	0.000029
technologies to	0.250000
reliable hits	0.250000
efficiently	0.000029
Charles Goodwin	1.000000
handling such	0.500000
worth remembering	0.500000
campaign on	0.200000
first stage	0.030303
business ,	0.250000
the figure	0.000692
text comprehension	0.006289
jet fighter	1.000000
whole word	0.111111
i.e. determining	0.052632
be compared	0.004219
the pollen	0.000692
, answer	0.000561
Vito Technology	1.000000
merge	0.000029
computerization of	1.000000
stochastic .	0.125000
forms than	0.166667
opportunity rather	0.500000
were SHRDLU	0.024390
as Robert	0.003484
knowledge that	0.037037
, partially	0.000561
interactions	0.000029
Processor is	1.000000
discourse grammar	0.027778
Lander Automatic	0.500000
interactions between	1.000000
once you	1.000000
Internet financial	0.500000
representing printed	0.500000
individual lines	0.083333
analyze the	0.250000
a letter	0.001227
Automated Summarizers	0.500000
Graesser ,	1.000000
amongst a	1.000000
, Louise	0.000561
sentence Grass	0.020833
requires in-depth	0.062500
The topic	0.005208
that by	0.003546
and must	0.001445
best modern	0.055556
used SYSTRAN	0.008850
2010 -RRB-	0.333333
methods try	0.022727
models have	0.038462
particular event	0.076923
food and	1.000000
automatically to	0.047619
initial capital	0.333333
Orientation	0.000029
language expression	0.006757
with specific	0.005464
coreference resolution	1.000000
<s> All	0.000769
, low-resolution	0.000561
way .	0.041667
phonetically	0.000029
genre .	0.500000
spelled	0.000029
have complex	0.009615
conversations such	0.333333
keep a	0.333333
given text	0.041667
studying	0.000029
mechanism	0.000029
decomposing	0.000029
a robotic	0.001227
on dictionary	0.004717
competence	0.000029
controlled by	1.000000
algorithms used	0.028571
after 2,000	0.083333
said	0.000029
appear near	0.062500
so-called discriminative	0.333333
each for	0.022222
Society ,	1.000000
2007 is	0.200000
but much	0.014706
coefficients to	0.250000
would check	0.018868
to infer	0.001328
application .	0.071429
at different	0.014706
was painstakingly	0.012987
theories on	0.200000
reasoning approach	0.142857
ROUGE-1 values	0.200000
Independence	0.000029
the earlier	0.000692
dependent system	0.333333
not possible	0.008929
speech data	0.006579
: Overall	0.009804
other possible	0.014286
use following	0.013889
Establishment -LRB-	1.000000
Afghanistan	0.000029
analysis aims	0.015385
larger collection	0.062500
create more	0.058824
edition	0.000029
D. Faber	0.200000
which use	0.007246
Words in	0.250000
require some	0.045455
standard written	0.071429
taken to	0.333333
popular example	0.111111
are discussed	0.004149
, Englund	0.000561
success in	0.200000
like in	0.035714
In 1929	0.009524
answer highlighted	0.033333
book ''	0.125000
two classes	0.034483
restrictions	0.000029
Another research	0.076923
Jim Martin	1.000000
match up	0.166667
become clear	0.250000
ca	0.000029
description and	1.000000
architecture Regardless	0.500000
system might	0.010753
to eigenvalue	0.001328
fire ''	0.500000
better scoring	0.111111
phrase appears	0.100000
Gee	0.000029
on extractive	0.004717
conceptual dependency	0.500000
only to	0.026316
psychotherapist	0.000029
door of	0.250000
are beyond	0.004149
photocells ,	1.000000
of software	0.000891
learning disabilities	0.023256
where it	0.028571
by spaces	0.005714
IEEE ASRU	0.333333
linguistic and	0.062500
shared tasks	0.500000
software .	0.037037
maintain tractability	1.000000
glue text	1.000000
off on	0.500000
included a	0.125000
highlighted	0.000029
included :	0.125000
field are	0.037037
utility with	0.500000
proposal for	1.000000
of front-end	0.000891
intra-texual	0.000029
angle .	1.000000
a bunch	0.001227
multiple references	0.076923
, similarity	0.000561
in two	0.001873
surprisingly difficult	0.333333
calculator or	0.500000
encyclopedia ''	1.000000
glue	0.000029
or lowering	0.004505
isolation .	0.500000
arm to	1.000000
of at	0.000891
comprehend Morse	1.000000
<s> People	0.000769
Unfortunately	0.000029
professional translator	1.000000
breadth and	0.500000
Text-to-speech	0.000029
or they	0.004505
'' each	0.005376
judge fluency	0.250000
imagery ,	1.000000
manipulate it	0.333333
relations are	0.083333
make decisions	0.050000
corpus .	0.032258
Michael Dyer	0.250000
exercises on	1.000000
filtered from	0.333333
, pre-defined	0.000561
text lacks	0.006289
not also	0.008929
database industry	0.100000
leverages	0.000029
data analysis	0.012987
for an	0.003610
textual corpora	0.200000
, definitional	0.000561
carefully design	1.000000
and FAA	0.001445
useful only	0.071429
learning that	0.023256
this .	0.010989
may explore	0.019231
for abbreviations	0.003610
good translation	0.076923
to paper-intensive	0.001328
or profession	0.004505
Lakoff ,	1.000000
damping factor	1.000000
a real-time	0.001227
these devices	0.023810
, wrote	0.000561
segmentation systems	0.030303
vector of	0.333333
resorting to	1.000000
recognizing hand-printed	0.200000
official	0.000029
However sentence	0.027027
Kintsch ,	1.000000
+5 scale	1.000000
question focus	0.023810
grammar Text	0.027027
events .	1.000000
universal encyclopedia	0.333333
Paul Drew	0.200000
, speech-to-text	0.000561
Universal Part-of-Speech	1.000000
our life	0.200000
deterministic decisions	0.250000
in October	0.001873
arrive at	1.000000
the augmented	0.000692
method simply	0.062500
Page	0.000029
fundamentally	0.000029
as focusing	0.003484
keyphrases as	0.028571
document set	0.027778
larger tasks	0.062500
triples or	0.333333
perfectly ,	1.000000
to expand	0.001328
arbitrary piece	0.333333
Back-End or	1.000000
arbitrary length	0.333333
more software	0.010526
for naval	0.003610
Descartes proposed	1.000000
animation ,	1.000000
tagger .	0.111111
adjust\/correct the	1.000000
other scripts	0.014286
requiring knowledge	0.500000
lessening of	1.000000
several variables	0.045455
role as	0.250000
index entries	1.000000
upload	0.000029
that serve	0.003546
in sentiment	0.001873
and Speech	0.001445
established	0.000029
Mirage aircraft	1.000000
phonetic segments	0.500000
Ensemble	0.000029
to model	0.001328
the summers	0.000692
training techniques	0.035714
are performed	0.004149
of disparate	0.000891
Langues vol-2	1.000000
characterizes its	1.000000
parameters related	0.250000
if uttered	0.035714
output ,	0.038462
desired identification	0.200000
overall contextual	0.166667
to specific	0.001328
benchmark tests	1.000000
to discrete	0.001328
threshold is	0.250000
statistics of	0.125000
states such	0.250000
be run	0.004219
applies directly	0.142857
false starts	0.500000
annotation process	0.250000
but article	0.014706
Conference Technolangue\/Easy	0.500000
phrase-structure grammars	1.000000
Rabiner	0.000029
boundary information	0.166667
check for	0.500000
Digital Syphon	1.000000
direct a	0.166667
service .	0.200000
identified the	0.200000
Even though	1.000000
analytical artificial	0.500000
<s> Again	0.000769
sentence-ending markers	1.000000
analyze all	0.250000
sequential lines	1.000000
Another project	0.076923
indifferent	0.000029
automata that	1.000000
term artificial	0.055556
changes which	1.000000
negligence ''	1.000000
TextRank does	0.071429
Realisation :	1.000000
is strong	0.002033
SHRDLU provided	0.166667
speech of	0.006579
as needed	0.003484
-LRB- OCR	0.002710
are some	0.004149
expressivity of	1.000000
as mentioned	0.003484
nascent	0.000029
a restricted	0.001227
conducted with	0.200000
<s> Extractive	0.000769
digitalized :	1.000000
consonants and	0.333333
result -LRB-	0.090909
Variation	0.000029
human --	0.021739
later users	0.100000
, Teun	0.000561
part that	0.037037
and simply	0.001445
newspaper pages	0.333333
sub-field	0.000029
VISTA -RRB-	1.000000
unmanageable .	1.000000
affected	0.000029
is broken	0.002033
contain multiple	0.083333
amenable	0.000029
Environmental	0.000029
models ...	0.038462
at run-time	0.014706
this case	0.010989
classified	0.000029
backgrounds	0.000029
<s> Discursive	0.000769
MARGIE	0.000029
Language ,	0.083333
ATNs and	0.333333
classifies	0.000029
Words ,	0.250000
while Church	0.050000
Words :	0.250000
posts and	1.000000
reasonable approximation	0.500000
ones focus	0.100000
DUC 2001	1.000000
to and	0.001328
forth	0.000029
entities ''	0.142857
language constructs	0.006757
that says	0.003546
was walking	0.012987
to very	0.001328
When a	0.142857
incorporates	0.000029
Eastern	0.000029
noise problem	0.125000
prisoner of	1.000000
still quite	0.066667
a hidden	0.001227
simply requires	0.083333
logical ,	0.166667
' lengths	0.052632
two steps	0.034483
polarity and	0.125000
Vocabulary size	0.333333
rev ,	1.000000
appropriately ,	0.500000
simply guessed	0.083333
the HTK	0.000692
B	0.000029
locate the	1.000000
patterns of	0.200000
of democracy	0.000891
add them	1.000000
the similarity	0.000692
pre-determined	0.000029
will replace	0.028571
been changed	0.014706
solely	0.000029
Challenges shared-task	1.000000
graphics	0.000029
to himself	0.001328
appropriately spelled	0.500000
Correct	0.000029
given corpus	0.041667
related data	0.066667
`` Mr.	0.005291
response ,	0.500000
questioner 's	0.250000
to government	0.001328
Mr. Smith	0.500000
René	0.000029
translation programs	0.013514
required the	0.142857
Verbyx VRX	1.000000
possible sentences	0.041667
specification is	0.500000
latent	0.000029
existing multilingual	0.200000
standard corpora	0.071429
<s> Correct	0.000769
etc. --	0.045455
figure out	0.500000
splitting may	0.500000
ability of	0.250000
such keyphrases	0.008130
paper-intensive	0.000029
Rule-based The	0.500000
du	0.000029
Statistics derived	0.333333
to much	0.001328
so has	0.033333
user needs	0.071429
Using almost	0.500000
using both	0.016949
QA -RRB-	0.047619
room acoustics	1.000000
High-performance	0.000029
the Pyramid	0.000692
by highlighting	0.005714
researchers undertake	0.100000
increasing G-loads	0.333333
a sample	0.001227
demonstrations ,	1.000000
correct summary	0.066667
medial and	1.000000
restricted world	0.250000
particularly effective	0.200000
Navy	0.000029
con	0.000029
it up	0.008547
Initial	0.000029
eyes-busy	0.000029
polynomial	0.000029
top ranking	0.200000
their system	0.029412
STT ''	1.000000
XML documents	1.000000
dozens	0.000029
sounds on	0.066667
Greek ,	0.333333
Turkish ,	1.000000
computer databases	0.022727
or identical	0.004505
translation tries	0.013514
principle ,	1.000000
This article	0.015873
physician	0.000029
and Lao	0.001445
and classifying	0.001445
-LRB- Microsoft	0.002710
first -LRB-	0.030303
algorithms which	0.028571
usually do	0.031250
compared syntactic	0.142857
, mail	0.000561
Rubin	0.000029
prepare formal	1.000000
Number =	1.000000
80 %	1.000000
comparative	0.000029
confirmed	0.000029
meaningless tokens	1.000000
ambiguities or	0.250000
black holes	1.000000
is quite	0.002033
representations such	0.250000
detail but	0.500000
kept	0.000029
1979	0.000029
local collection	0.333333
1977	0.000029
1975	0.000029
1974	0.000029
questions and	0.038462
Many ATC	0.083333
for POS	0.003610
Forces Security	1.000000
become well	0.250000
on less	0.004717
label discourse	1.000000
life scientists	0.250000
transformed	0.000029
helped the	0.333333
more appropriately	0.010526
variables such	1.000000
pronoun ,	1.000000
caps	0.000029
PageRank on	0.166667
The hidden	0.005208
<s> Referring	0.000769
limit is	0.250000
Sept. 1955	1.000000
security	0.000029
see it	0.050000
, signed	0.000561
see is	0.050000
text analytics	0.006289
Web-based +	0.333333
Sound is	0.333333
, rhetoric	0.000561
, roughness	0.000561
productions	0.000029
Lee	0.000029
Relationship	0.000029
Leo	0.000029
slot represents	1.000000
produce one	0.045455
questions can	0.038462
The human	0.005208
and differing	0.001445
to mental	0.001328
summarization task	0.020000
clean hand-printed	0.500000
a horizontal	0.001227
among named	0.125000
the common	0.000692
degree .	0.166667
typewritten reports	0.200000
avoids overfitting	1.000000
when summarizing	0.028571
strongly than	0.500000
<s> Dictionary-based	0.000769
test as	0.100000
difficult task	0.035714
accordingly	0.000029
, sales	0.000561
150,000	0.000029
and represented	0.001445
Harris beginning	0.111111
analytical approaches	0.500000
waves and	0.142857
as statistical	0.003484
general cursive	0.045455
mapping each	0.500000
responding	0.000029
two possibilities	0.034483
MCE	0.000029
automate about	0.333333
-RRB- applications	0.002817
in abstractive	0.001873
Helicopters The	1.000000
salience .	1.000000
productions .	1.000000
Accuracy for	0.142857
structure that	0.083333
words immediately	0.009174
Style Studies	1.000000
handmade	0.000029
Running	0.000029
interested	0.000029
on casual	0.004717
state-of-the-art abstractive	0.500000
Airline	0.000029
or stochastic	0.004505
Schank ,	0.200000
been heard	0.014706
Although humans	0.125000
unsupervised ``	0.125000
anymore ,	1.000000
by extracting	0.005714
requires each	0.062500
On what	0.166667
demonstration that	0.200000
`` Spoken	0.005291
datum	0.000029
human-like	0.000029
include Chinese	0.037037
this character	0.010989
of idioms	0.000891
wreck a	1.000000
life experience	0.250000
questions in	0.038462
, Brazil	0.000561
Encouraging results	1.000000
is limited	0.002033
orthogonal	0.000029
as opposed	0.003484
classroom lectures	1.000000
and find	0.001445
began selling	0.142857
fail during	0.333333
procedures used	0.250000
negative sentiment	0.125000
This research	0.015873
syntax are	0.090909
objective document	0.200000
revolution	0.000029
any capitalization	0.032258
solid state	1.000000
parser proposes	0.062500
can help	0.005525
for clarification	0.003610
Vocabulary Size	0.333333
filling may	1.000000
Early work	0.500000
two -LRB-	0.034483
standard is	0.071429
while some	0.050000
change	0.000029
or weapon	0.004505
precursor	0.000029
Cynthia	0.000029
and features	0.001445
, Walter	0.000561
the English-French	0.000692
Aided summarization	0.333333
management applications	0.142857
forums -LRB-	1.000000
included question-answering	0.125000
many higher	0.019231
Creating the	0.500000
to ask	0.001328
to proper	0.001328
syllables but	0.500000
rate the	0.090909
thus returning	0.100000
precisely an	1.000000
comes into	0.200000
specific right	0.047619
& Hollenbach	0.125000
, Malcolm	0.000561
in spirit	0.001873
of edge	0.000891
MMR	0.000029
MMI	0.000029
, rushing	0.000561
be correct	0.004219
expanding	0.000029
editor ,	1.000000
from 71	0.009615
accurate program	0.142857
retail sales	1.000000
-LRB- speed	0.002710
designed for	0.142857
found recognition	0.071429
collection sizes	0.200000
just seen	0.111111
expensive and	0.142857
different times	0.020408
Jump to	1.000000
Rescoring is	1.000000
geological analysis	1.000000
, resource	0.000561
get bunch	0.142857
dominance of	1.000000
are robust	0.004149
Grace	0.000029
N-best list	1.000000
writer with	1.000000
<s> Knowing	0.000769
Digest coupons	0.333333
algorithm ?	0.035714
and model	0.001445
significantly	0.000029
entrants companies	1.000000
the longest	0.000692
et	0.000029
Leeuwen	0.000029
opened	0.000029
but machines	0.014706
more strongly	0.010526
shows	0.000029
to multi-document	0.001328
U.S. Army	0.142857
Hafiz	0.000029
all such	0.023256
keep track	0.333333
both affine	0.032258
into rule-based	0.012821
going backward	0.250000
Even	0.000029
Microphone	0.000029
with 17	0.005464
omitted	0.000029
following -LRB-	0.066667
Optophone	0.000029
require that	0.045455
Rates	0.000029
comprises	0.000029
category that	0.500000
governmental proceedings	1.000000
be statistically	0.004219
GRACE	0.000029
are simple	0.004149
` hit	0.062500
relative position	0.333333
One study	0.076923
subjectivity of	0.500000
Further restricted-domain	0.333333
is compounded	0.002033
be parsed	0.004219
it word	0.008547
the periods	0.000692
Human judgement	0.200000
generating index	0.200000
PhD	0.000029
Querying application	1.000000
Call	0.000029
, other	0.000561
evaluation Intrinsic	0.018519
software Annotate	0.037037
are BASEBALL	0.004149
often it	0.022727
successfully for	0.333333
omitted -RRB-	1.000000
have the	0.009615
best -RRB-	0.055556
clearly many	0.333333
often using	0.022727
contain words	0.083333
offered the	1.000000
appear as	0.062500
combinations of	1.000000
notations of	0.500000
retrieval results	0.142857
fundamental errors	0.500000
elements containing	0.250000
simple procedure	0.038462
methods when	0.022727
ground	0.000029
be unique	0.004219
these every	0.023810
much useful	0.045455
fusion techniques	1.000000
verbs are	0.200000
Some critics	0.047619
from some	0.009615
Language Constraints	0.083333
converts a	1.000000
rate -LRB-	0.090909
, stemming	0.000561
Another area	0.076923
techniques .	0.043478
for heavily	0.003610
The 26	0.005208
concern	0.000029
parsing and	0.035714
realizations as	1.000000
'' it	0.005376
Weizenbaum sidestepped	0.333333
uses the	0.071429
vertices be	0.111111
applications including	0.040000
was dramatically	0.012987
are four	0.004149
what linguistic	0.031250
and attempt	0.001445
Santoni	0.000029
is edited	0.002033
rejecting those	0.333333
voicemail	0.000029
be difficult	0.004219
it should	0.008547
pre-existing corpus	0.500000
<s> Rescoring	0.000769
an eyes-busy	0.007576
increase recognition	0.250000
non-whitespace character	1.000000
, symbols	0.000561
assumed that	1.000000
Known	0.000029
use multiple	0.013889
center ,	1.000000
accuracy may	0.032258
the management	0.000692
recogniton vary	0.500000
input sales	0.024390
CWA -RRB-	1.000000
an arbitrarily	0.007576
both speech	0.032258
The NIST	0.005208
what sense	0.031250
suitable translation	0.250000
both individual	0.032258
or emotion	0.004505
1954 involved	0.333333
organization documents	0.200000
emphasize different	1.000000
all perform	0.023256
simply do	0.083333
<s> Conferences	0.000769
answers are	0.083333
looks natural	0.250000
grown .	1.000000
answering -LRB-	0.083333
their spoken	0.029412
quality standards	0.100000
text corresponds	0.006289
pre-marked .	1.000000
archiving and	1.000000
, cultural	0.000561
was hand-written	0.012987
Virtually any	1.000000
software has	0.037037
the contents	0.000692
character alone	0.045455
is recognizing	0.002033
count for	0.200000
environment ,	0.166667
software had	0.037037
simplified the	0.500000
others seem	0.083333
Multilingual -LRB-	1.000000
desktop	0.000029
momentum	0.000029
usefully	0.000029
be thought	0.004219
wide variance	0.250000
, Jef	0.000561
centrality ''	0.500000
-LRB- predict	0.002710
to save	0.001328
monetary value	1.000000
MT has	0.200000
can assign	0.005525
mixture of	1.000000
reduced set	0.250000
Interface	0.000029
toy project	0.500000
Marilyn	0.000029
Morpholympics	0.000029
a positive	0.001227
full comprehension	0.200000
embedded lists	0.250000
`` bag	0.005291
often difficult	0.022727
Orientation --	1.000000
Solutions	0.000029
internalize	0.000029
normally requires	0.500000
and news	0.001445
contain subjective	0.083333
prepare	0.000029
1997 ,	0.500000
greater risk	0.333333
relaxed parser	1.000000
each feature\/aspect	0.022222
surprisingly ,	0.333333
either explicit	0.100000
programer 's	1.000000
fairly often	0.250000
run an	0.200000
least to	0.200000
waves .	0.142857
Veterans Administration	1.000000
to incorporate	0.001328
tables to	0.333333
vocabulary ,	0.125000
moved	0.000029
for simple	0.003610
moves	0.000029
or ICR	0.004505
new insights	0.041667
modeling are	0.142857
Research Projects	0.125000
or ''	0.004505
the human-readable	0.000692
the article	0.000692
processed Airline	0.166667
parameters ,	0.250000
by ears	0.005714
to OCR	0.001328
answering methods	0.083333
first-order logic	1.000000
-RRB- the	0.002817
This sequence	0.015873
and sources	0.001445
red .	1.000000
information usually	0.021739
capitalization can	0.333333
act theory	0.250000
existing hand-written	0.200000
sequence alignment	0.125000
being processed	0.055556
much better	0.045455
Sentence boundary	0.200000
Francis ,	1.000000
product became	0.142857
higher order	0.142857
<s> Chinese	0.000769
speech is	0.006579
and HLT	0.001445
involve working	0.166667
generally achieved	0.090909
tagger is	0.111111
involve grammar	0.166667
market their	0.333333
up In	0.045455
2,026,329	0.000029
job ;	0.500000
away -LRB-	0.500000
job ,	0.500000
the wife	0.000692
financial benefits	0.250000
sentence breaking	0.020833
choices that	0.200000
usually thought	0.031250
unit vertices	0.333333
a classification	0.001227
but IR	0.014706
into linguistically	0.012821
each phoneme	0.022222
many advantages	0.019231
be sequences	0.004219
but IE	0.014706
canonical	0.000029
, USMC	0.000561
HLDA	0.000029
the F35	0.000692
, relationship	0.000561
Schiffrin ,	1.000000
a cosine	0.001227
actual measurement	0.200000
and ushered	0.001445
Hafiz ,	1.000000
the nouns	0.000692
columns and	1.000000
naturalness .	1.000000
used through	0.008850
, Santoni	0.000561
But unfortunately	0.166667
chunks	0.000029
checked after	0.500000
the voice	0.000692
is why	0.002033
easy-to-use	0.000029
Network classifies	1.000000
a well-defined	0.001227
hours of	0.500000
-LRB- Kittredge	0.002710
by inputting	0.005714
document 7110.65	0.027778
one another	0.015385
commonly defined	0.125000
nine	0.000029
dynamic study	0.200000
to conduct	0.001328
greatly on	0.142857
lacks	0.000029
1957 and	1.000000
linguistic informational	0.062500
explained by	1.000000
belong to	1.000000
or program	0.004505
formal or	0.111111
were identified	0.024390
rather can	0.062500
the dynamics	0.000692
important words	0.062500
in-depth analysis	0.333333
keyboard and	0.333333
Deep	0.000029
be retrained	0.004219
contains embedded	0.100000
be required	0.004219
final language	0.111111
web ,	0.125000
believed that	1.000000
by increasing	0.005714
using conventional	0.016949
similarity scores	0.100000
subsequent concepts	0.500000
by Jurafsky	0.005714
role in	0.250000
Glass-box	0.000029
food	0.000029
Ratliff originally	1.000000
results in	0.047619
that connects	0.003546
Beatrice Santorini	1.000000
overfitting the	0.500000
Slembrouck	0.000029
segmentation approaches	0.030303
language during	0.006757
great success	0.333333
to parsers	0.001328
local document	0.333333
video captioning	0.200000
Rescoring	0.000029
to database	0.001328
system typically	0.010753
as pseudo-pilot	0.003484
grammatical analysis	0.090909
reranking in	1.000000
efforts based	0.142857
Computed every	1.000000
file to	1.000000
Ingria R.	1.000000
assertion ,	1.000000
and usefulness	0.001445
Many documents	0.083333
input-stream	0.000029
binary judgement	0.250000
LexisNexis	0.000029
from randomly	0.009615
, Stef	0.000561
Answering QA	1.000000
developing new	0.250000
schemata	0.000029
and substitution	0.001445
characteristics .	0.500000
be representative	0.004219
encoding	0.000029
resulting graph	0.250000
frame ;	0.500000
for continuous	0.003610
Corpus developed	0.062500
Schober ,	1.000000
together with	0.125000
CANDIDE	0.000029
shifted	0.000029
storm	0.000029
would generate	0.018868
interactive program	0.250000
one reference	0.015385
be approximated	0.004219
; in	0.021277
specific letter	0.047619
can condense	0.005525
still not	0.066667
A second	0.020000
CSIS -RRB-	0.500000
issues were	0.200000
and analytical	0.001445
<s> Inclusive	0.000769
vulnerable	0.000029
sentences flow	0.013158
Big wave	1.000000
evaluation with	0.018519
Some writing	0.047619
, rejecting	0.000561
will indicate	0.028571
and confusability	0.001445
put the	0.250000
towards	0.000029
text -RRB-	0.006289
closed-captioning of	1.000000
understand why	0.142857
VTLN -RRB-	1.000000
Sager at	0.500000
ratings on	0.111111
Such strategy	0.125000
early 1990s	0.100000
, producing	0.000561
OCR accuracy	0.020408
of pilot	0.000891
ROUGE-1 -LRB-	0.200000
completion	0.000029
necessary therefore	0.100000
Mention	0.000029
its speakers	0.028571
industry .	0.333333
just validated	0.111111
ambiguity in	0.125000
cases make	0.055556
translate between	0.166667
, Edward	0.000561
coherent summary	0.200000
with one	0.005464
which sounds	0.007246
tagging systems	0.040000
Romanseval	0.000029
in advanced	0.001873
1 -RRB-	0.250000
its utility	0.028571
Xerox eventually	0.500000
assistants	0.000029
Fighter	0.000029
notoriously	0.000029
Segmentation	0.000029
are measured	0.004149
approximation thereof	0.166667
paradigm calls	0.333333
automatically created	0.047619
still somewhat	0.066667
One way	0.076923
time in	0.030303
is best	0.002033
as 10	0.003484
many types	0.019231
dynamic character	0.200000
- EVALITA	0.062500
behavior of	0.500000
US baseball	0.142857
products in	0.250000
<s> Morphological	0.000769
ontologies '	0.166667
involves deciding	0.100000
Efficient algorithms	1.000000
translations using	0.500000
maintenance	0.000029
the objectives	0.000692
, real	0.000561
+ Mobile	0.166667
partly	0.000029
word ``	0.016667
probabilities ,	0.090909
the reCAPTCHA	0.000692
If probabilities	0.100000
our knowledge	0.200000
the single	0.000692
Since 2000	0.200000
these algorithms	0.023810
van Dijk	0.500000
→ dogs	0.333333
evaluation metrics	0.018519
assume there	0.500000
provided significant	0.200000
anymore	0.000029
belong	0.000029
by giving	0.005714
the conceptual	0.000692
become more	0.250000
HMT	0.000029
Word-sense	0.000029
underlies	0.000029
power increased	0.250000
Giro	0.000029
top level	0.200000
PhD thesis	1.000000
than precision	0.022222
exhibited good	1.000000
important .	0.062500
extract the	0.250000
or its	0.004505
transformation	0.000029
interlingua .	1.000000
interference between	1.000000
automatically answer	0.047619
overriding	0.000029
with applications	0.005464
-RRB- coefficients	0.002817
Learning	0.000029
past thirty	0.333333
January ,	0.250000
the grammar-based	0.000692
enumerate every	1.000000
trends	0.000029
centers of	1.000000
the Austrian	0.000692
over vertices	0.083333
models Main	0.038462
deciding where	0.166667
Australia	0.000029
Human sentences	0.200000
book does	0.125000
notations ,	0.500000
Search collections	0.500000
71	0.000029
while capturing	0.050000
draft document	0.500000
area include	0.090909
potential redundancy	0.142857
lend well	1.000000
heritage	0.000029
researchers to	0.100000
finalized .	1.000000
tag of	0.062500
`` look	0.005291
and LILOG	0.001445
, matching	0.000561
minute ,	1.000000
Grammatical	0.000029
Attribute	0.000029
Rajman	0.000029
it even	0.008547
several ways	0.045455
and LUNAR	0.001445
have included	0.009615
multilingual questions	0.333333
that area	0.003546
Speaking	0.000029
vector machines	0.333333
path sentences	0.500000
Federation of	1.000000
allowing for	0.333333
in virtually	0.001873
incremental improvements	1.000000
using digital	0.016949
reliance on	1.000000
analyser to	1.000000
early successes	0.100000
that preclude	0.003546
discourse are	0.027778
that domain	0.003546
decomposing it	1.000000
or length	0.004505
semiotic event	1.000000
can translate	0.005525
says phrases	1.000000
shorter and	0.500000
France has	0.250000
entirety ,	1.000000
reasons that	0.500000
program ,	0.045455
originally developed	0.500000
say that	0.142857
In terms	0.009524
Technologies that	1.000000
management environments	0.142857
fueled interest	1.000000
document formats	0.027778
produce useful	0.045455
see List	0.050000
tonal	0.000029
generating examples	0.200000
extrinsic performance	0.166667
becomes .	0.250000
'' standards	0.005376
translation Automotive	0.013514
with maximal	0.005464
should not	0.052632
1974 Ray	1.000000
n-gram ROUGE	0.500000
always a	0.333333
setting radio	0.200000
example -LRB-	0.012346
this makes	0.010989
spoken text	0.071429
recognition efforts	0.008264
which do	0.007246
Cynthia Hardy	1.000000
always ,	0.333333
' properties	0.052632
summarization :	0.020000
SIGGEN	0.000029
and human	0.001445
general term	0.045455
a trivial	0.001227
anomalies	0.000029
<s> metrics	0.000769
its performance	0.028571
being based	0.055556
, NNS	0.000561
entertaining last	0.500000
domotic appliance	1.000000
Sentences ;	1.000000
optimizing	0.000029
<s> Based	0.000769
a count	0.001227
and regions	0.001445
benchmark	0.000029
printing ,	1.000000
target value	0.090909
and volume	0.001445
implemented on	0.200000
other medium	0.014286
<s> Comparing	0.000769
ISO\/TC37\/SC4	0.000029
Evaluation An	0.111111
providers	0.000029
would allow	0.018868
When the	0.142857
short ,	0.125000
Accuracy is	0.142857
poetry	0.000029
located	0.000029
<s> Like	0.000769
clusters .	1.000000
Document Understanding	0.250000
likely be	0.062500
whether documents	0.076923
vary from	0.166667
difficult for	0.035714
summarization involves	0.020000
spelling	0.000029
are implemented	0.004149
numerous approaches	1.000000
Corpus ,	0.062500
Corpus .	0.062500
given -LRB-	0.041667
Smith	0.000029
sub-problems ,	1.000000
sorting center	1.000000
interface Home	0.250000
tag to	0.062500
automatic methodology	0.043478
that looks	0.003546
of marking	0.000891
to overcome	0.001328
succession of	1.000000
speech Adverse	0.006579
or might	0.004505
removes the	1.000000
connects to	1.000000
values for	0.125000
recording conditions	1.000000
Why do	0.142857
problem from	0.022727
the breadth	0.000692
We also	0.142857
what information	0.031250
to overfitting	0.001328
, Speereo	0.000561
assumptions about	0.200000
handles both	1.000000
the reference	0.000692
diagonal	0.000029
containing words	0.125000
of real-world	0.000891
likely not	0.062500
Lamb	0.000029
at .	0.014706
probability of	0.142857
Callaghan which	1.000000
MUC	0.000029
of conversations	0.000891
smaller .	0.142857
high ranks	0.055556
saying .	1.000000
data will	0.012987
DUC	0.000029
contain names	0.083333
funding has	0.125000
R	0.000029
of standard	0.000891
In short	0.009524
address field	0.250000
movies ,	1.000000
particular types	0.076923
common components	0.040000
distinguished	0.000029
of assertions	0.000891
closely approximates	0.200000
constrained	0.000029
that investigates	0.003546
newswire reports	1.000000
in overall	0.001873
Givón ,	1.000000
although these	0.166667
going thus	0.250000
1975 -RRB-	1.000000
is Reiter	0.002033
on whether	0.004717
those influenced	0.045455
a logical	0.001227
effect of	0.500000
major constituents	0.083333
proceedings	0.000029
sample of	0.333333
a Cognitive	0.001227
mostly as	0.500000
pioneered this	0.333333
highest probability	0.333333
choose from	0.500000
material may	0.500000
commands are	0.200000
such systems	0.008130
a technique	0.001227
dynamics of	0.500000
be around	0.004219
attained	0.000029
differently on	1.000000
can improve	0.005525
Robert de	0.250000
automates the	1.000000
to publish	0.001328
on complex	0.004717
input and\/or	0.024390
she	0.000029
to narrative	0.001328
of repeated	0.000891
by statistics	0.005714
d'Albe developed	1.000000
and unexpected	0.001445
of public	0.000891
DTW -RRB-	0.333333
usefulness	0.000029
looking waves	0.200000
its use	0.028571
, incomplete	0.000561
and cross-lingual	0.001445
James Deese	0.250000
the concepts	0.000692
time-consuming .	0.333333
correctly	0.000029
ISRI -RRB-	1.000000
particular part	0.076923
, LinguaSys	0.000561
describing language	0.250000
an upper-case	0.007576
computational concerns	0.100000
much like	0.045455
Realisation	0.000029
forecast -LRB-	1.000000
be computed	0.004219
scanner that	0.333333
impersonate a	1.000000
when integrated	0.028571
an experiment	0.007576
going to	0.250000
scores significantly	0.200000
synthesizer .	1.000000
: Speech	0.009804
do research	0.038462
the 2006	0.000692
large variety	0.043478
two benefits	0.034483
speech single	0.006579
Subsequently	0.000029
, maybe	0.000561
documents obtained	0.026316
pass .	1.000000
Corpus -LRB-	0.062500
in predicate	0.001873
first-cut can	1.000000
CCD flatbed	1.000000
words surrounding	0.009174
statistical analysis	0.030303
, rapidly	0.000561
own sentence	0.166667
are reported	0.004149
given formal	0.041667
whereas when	0.333333
approaches can	0.035714
or Arabic	0.004505
significant effort	0.111111
the quantitative	0.000692
`` He	0.005291
underlying knowledge	0.333333
-RRB- may	0.002817
Emergent	0.000029
`` diverse	0.005291
module that	0.333333
number should	0.023256
of 500,000	0.000891
documents onto	0.026316
topics and	0.142857
segmentation Sentence	0.030303
independence Isolated	1.000000
ushered	0.000029
kick	0.000029
as weapon	0.003484
news-gathering	0.000029
accuracy using	0.032258
National Federation	0.333333
full-text search	1.000000
still largely	0.066667
answers might	0.083333
article by	0.034483
what Biden	0.031250
-LRB- ParaEval	0.002710
health and	1.000000
non-Western scripts	1.000000
nodes represents	0.142857
language representation	0.006757
to different	0.001328
associated score	0.250000
both learn	0.032258
CyberEmotions project	1.000000
updated textbook	1.000000
digitized ,	1.000000
deterministic rule	0.250000
metrics are	0.111111
Ensemble methods	1.000000
be modified	0.004219
Its main	0.500000
EVALITA campaign	0.500000
-RRB- Critical	0.002817
successfully in	0.333333
Graph	0.000029
, pronoun	0.000561
, people	0.000561
of objects	0.000891
intelligence systems	0.125000
Lawrence	0.000029
speakers to	0.250000
fast-evolving	0.000029
merging the	0.500000
there may	0.025000
Hence the	0.500000
poetry passages	1.000000
will usually	0.028571
the company	0.000692
choices -LRB-	0.200000
- processing	0.062500
in any	0.001873
`` sounds	0.005291
by numbers	0.005714
speech recognition-related	0.006579
operate on	1.000000
attitude may	0.500000
typewritten text	0.200000
on broad	0.004717
then given	0.028571
A Universal	0.020000
-LRB- http:\/\/haydn.isi.edu\/ROUGE\/	0.002710
worse	0.000029
no incorrect	0.076923
would also	0.018868
, Shipibo	0.000561
complete sentences	1.000000
Smartphones .	1.000000
useful work	0.071429
Perhaps the	1.000000
PageRank ,	0.166667
PageRank .	0.166667
above -RRB-	0.076923
covariance Gaussians	0.500000
that approximate	0.003546
headed by	1.000000
tasks -LRB-	0.031250
assign labels	0.200000
possible without	0.041667
about following	0.025000
Adam Jaworski	1.000000
stochastic taggers	0.125000
on smaller	0.004717
grammar formalisms	0.027027
and discontinuous	0.001445
certain e-communities	0.142857
solution	0.000029
Keyphrases	0.000029
among humans	0.125000
one typically	0.015385
recognition we	0.008264
categories ;	0.111111
, Roger	0.000561
categories ,	0.111111
times a	0.200000
best single	0.055556
Booth	0.000029
a certain	0.001227
to upload	0.001328
different languages	0.020408
interpret	0.000029
fighter applications	0.166667
times ,	0.200000
more interest	0.010526
the 100	0.000692
Business-card OCR	1.000000
these natural	0.023810
shortened	0.000029
professionals .	1.000000
than polarity	0.022222
many speech	0.019231
counts	0.000029
languages like	0.020000
lightweight ontologies	1.000000
consecutive words	0.500000
research also	0.023810
and interaction	0.001445
pre-processing	0.000029
and broadband	0.001445
impact of	0.500000
impact on	0.500000
Annotate	0.000029
performance continued	0.055556
possibly linked	0.500000
decision-support	0.000029
or -LRB-	0.004505
answer corpus	0.033333
often work	0.022727
<s> Deep	0.000769
comparing its	0.500000
large percentage	0.043478
those pauses	0.045455
does the	0.100000
created .	0.142857
individual cursive	0.083333
it conducted	0.008547
are averaged	0.004149
provide manually	0.166667
elaboration ,	1.000000
feature\/aspect is	1.000000
information -LRB-	0.021739
needs of	0.100000
Besides the	1.000000
with matching	0.005464
regions .	0.500000
internalize the	1.000000
cosine similarity	0.333333
DTW has	0.333333
non -	1.000000
spectral-domain of	1.000000
courses of	1.000000
given CFG	0.041667
vertices are	0.111111
turn also	0.166667
Query expansion	1.000000
grammar '	0.027027
-LRB- natural	0.002710
company to	0.333333
and answer	0.001445
setting steer-point	0.200000
rhetoric	0.000029
on part-of-speech	0.004717
subtasks .	0.500000
The examples	0.005208
which its	0.007246
Michigan ,	1.000000
not a	0.008929
sophisticated methods	0.142857
2009 -LRB-	0.333333
parties du	1.000000
at its	0.014706
= singular	0.111111
`` correct	0.005291
occur ,	0.200000
and experience	0.001445
a sub-field	0.001227
Goodwin	0.000029
, recommendations	0.000561
research necessary	0.023810
very complex	0.024390
Determine the	1.000000
language question-answering	0.006757
linguistics and	0.050000
also obtained	0.014493
judges ,	0.500000
found most	0.071429
can produce	0.005525
slowly but	0.500000
holes ''	1.000000
and Italian	0.001445
simply focused	0.083333
analyzed ,	0.200000
Discontinuous	0.000029
conditions Environmental	0.200000
teach that	1.000000
loud	0.000029
of stock	0.000891
then appear	0.028571
systems sold	0.008929
set on	0.025641
environment as	0.166667
features would	0.038462
for results	0.003610
as subject	0.003484
progressed over	1.000000
still be	0.066667
restricted-domain	0.000029
keyword	0.000029
instructed to	1.000000
descriptions ;	1.000000
<s> Subsequently	0.000769
aural	0.000029
<s> Prior	0.000769
Clancy 's	1.000000
in essentially	0.001873
it vibrates	0.008547
identified .	0.200000
algorithm essentially	0.035714
predict keyphrases	0.166667
methods presented	0.022727
on computational	0.004717
two include	0.034483
technology This	0.045455
increasingly difficult	0.333333
be given	0.004219
, developed	0.000561
mining ,	0.200000
mining .	0.200000
Why did	0.142857
hurricane season	1.000000
only as	0.026316
car or	1.000000
only at	0.026316
multilingual textual	0.333333
decoding	0.000029
SPOTLIGHT	0.000029
no evident	0.076923
TextRank .	0.071429
integrate	0.000029
on Speech	0.004717
expertise ,	1.000000
standard techniques	0.071429
guesses '	1.000000
Organization	0.000029
Johnstone	0.000029
n't vice	0.250000
a Fourier	0.001227
cover .	1.000000
rhetoric ,	1.000000
simple domains	0.038462
, opening	0.000561
It proved	0.026316
Basically ,	1.000000
Environment Canada	1.000000
very specific	0.024390
10,000 to	1.000000
Eurofighter	0.000029
Lifeline as	1.000000
tied to	1.000000
mouse driven	1.000000
AVRADA -RRB-	0.500000
placement of	1.000000
software ,	0.037037
, yielding	0.000561
of original	0.000891
edition published	1.000000
culture of	1.000000
they relate	0.025000
The SATZ	0.005208
are spoken	0.004149
, mathematical	0.000561
as discussed	0.003484
top of	0.200000
1960s .	0.333333
both algorithms	0.032258
final keyphrase	0.111111
as just	0.003484
Translator -RRB-	1.000000
Ontology	0.000029
formalized	0.000029
Units -LRB-	1.000000
night .	1.000000
news ,	0.076923
based speech	0.018519
exception	0.000029
example above	0.012346
-LRB- EMR	0.002710
other in	0.014286
beings ,	1.000000
near	0.000029
neat	0.000029
many authors	0.019231
entropy-based	0.000029
scans paper	1.000000
Woods introduced	1.000000
summary -RRB-	0.023810
many chatterbots	0.019231
linguistic resources	0.062500
an AI-complete	0.007576
relationships of	0.166667
is definite	0.002033
recognizing named	0.200000
cognitive operation	0.500000
be broken	0.004219
entities employed	0.142857
data category	0.012987
of sentence	0.000891
R. Howarth	0.166667
, list	0.000561
of anomalies	0.000891
QA Questions	0.047619
De	0.000029
mail since	0.500000
treat words	0.500000
facts	0.000029
realm of	1.000000
on ;	0.004717
templates may	1.000000
A comprehensive	0.020000
Dec. 2011	1.000000
track of	1.000000
Grishman	0.000029
Current state	0.200000
In such	0.009524
ATNs used	0.333333
Applications The	0.500000
contain densely	0.083333
directed .	1.000000
input into	0.024390
Server OCR	1.000000
is true	0.002033
Jef	0.000029
most importantly	0.017241
or deferred	0.004505
transition network	1.000000
power The	0.250000
include overt	0.037037
schematic organization	1.000000
Problem Solving	1.000000
their part	0.029412
telephone .	0.500000
English are	0.027027
10 .	0.125000
political discourse	0.333333
judgement often	0.333333
systems dynamically	0.008929
text generation	0.006289
keyphrases to	0.028571
multitude of	1.000000
psychotherapy .	1.000000
was CANDIDE	0.012987
is crucial	0.002033
Dynamic Programming	0.200000
taggers can	0.142857
parsing written	0.035714
parses the	0.500000
that causes	0.003546
: fact	0.009804
about it	0.025000
were ``	0.024390
<s> n	0.000769
be measured	0.004219
rule-based machine-translation	0.142857
<s> N	0.000769
cartoon animation	1.000000
what extent	0.031250
such large	0.008130
Aided Human	0.333333
<s> ,	0.000769
entry .	0.250000
Screenshot OCR	1.000000
the Gene	0.000692
language using	0.006757
tests ,	0.250000
tests .	0.250000
lattice -RRB-	1.000000
-RRB- dogs	0.002817
what you	0.031250
1970 -LRB-	0.333333
based therapy	0.018519
Pallet D.S.	0.500000
Anthology	0.000029
Lifeline	0.000029
critical tasks	0.250000
require in	0.045455
text image	0.006289
correct -RRB-	0.066667
one feasibility	0.015385
of TF-IDF	0.000891
Haton	0.000029
, needed	0.000561
approximates the	0.500000
felt	0.000029
on contrastive	0.004717
this meaning	0.010989
Guidelines for	0.500000
billion	0.000029
G	0.000029
frequency with	0.500000
<s> Significant	0.000769
receivers .	1.000000
correlation is	0.500000
a societal	0.001227
skip	0.000029
typically finds	0.055556
Center ,	1.000000
condensation operations	1.000000
10 digits	0.125000
EAGLi for	1.000000
only because	0.026316
time-scales -LRB-	1.000000
written English	0.038462
because two	0.033333
sets from	0.090909
sentences presented	0.013158
Where	0.000029
extractive keyphrase	0.142857
of distinct	0.000891
accidentally	0.000029
Harris had	0.111111
sets to	0.090909
looks for	0.250000
word context	0.016667
involves doing	0.100000
new part	0.041667
broadband technologies	1.000000
Romance	0.000029
by parser	0.005714
and generating	0.001445
untagged corpus	1.000000
better decisions	0.111111
industry ,	0.333333
scanned page	0.333333
automatic procedures	0.043478
matter how	0.333333
the Parseval\/GEIG	0.000692
Makoto	0.000029
of TextRank	0.000891
summaries or	0.023256
across a	0.200000
which soon	0.007246
the mid-1960s	0.000692
encode	0.000029
of 1956	0.000891
Processes	0.000029
Constraint	0.000029
the segmentation	0.000692
or names	0.004505
step neural	0.066667
think that	0.333333
then noun	0.028571
capturing	0.000029
using punctuation	0.016949
often disagree	0.022727
arithmetic expression	1.000000
of semantics	0.000891
in driving	0.001873
Evaluation As	0.111111
information request	0.021739
A. Woods	0.200000
result will	0.090909
normalize	0.000029
`` Sentiment	0.005291
a display	0.001227
Intrinsic evaluations	0.333333
more easily	0.010526
Verschueren	0.000029
applications seek	0.040000
Junqua and	1.000000
generation ,	0.111111
`` Meaningful	0.005291
grow	0.000029
's software	0.019608
text are	0.006289
maybe	0.000029
fluent	0.000029
and linguistic	0.001445
are particularly	0.004149
understanding evaluation	0.030303
pointed	0.000029
stability	0.000029
Relevance	0.000029
heavy-noise	0.000029
resolution is	0.250000
Newton pioneered	1.000000
semantic ;	0.047619
reviews respectively	0.166667
like HTML	0.035714
to integrate	0.001328
cognition	0.000029
sentences so	0.013158
-LRB- basically	0.002710
analyzed and	0.200000
deployed in	0.500000
detected ,	0.500000
processing the	0.018519
meaningful .	0.125000
answers can	0.083333
requirements .	0.500000
tasks ;	0.031250
interference	0.000029
generate translations	0.055556
3 or	0.200000
's voices	0.019608
communicative event	0.333333
conventional computer	1.000000
least partly	0.200000
time window	0.030303
deal primarily	0.250000
and rule	0.001445
Deciding	0.000029
promising line	1.000000
the leaders	0.000692
techniques offer	0.043478
content-analysis	0.000029
actually more	0.333333
of disassembling	0.000891
Sandra Thompson	1.000000
Both QA	0.333333
carry	0.000029
started to	0.250000
to threshold	0.001328
yielding thousands	1.000000
approach using	0.028571
to tell	0.001328
see wide	0.050000
printer using	1.000000
have explicit	0.009615
Deirdre	0.000029
of features	0.000891
Bayes classifier	0.333333
selects the	0.500000
scanning solution	0.500000
or cross-lingual	0.004505
, SAM	0.000561
words not	0.009174
and Dragon	0.001445
translator need	0.142857
Thai do	0.500000
`` black	0.005291
Sociologist Harold	1.000000
an allowable	0.007576
subtopic	0.000029
robotic arm	1.000000
adequately solved	1.000000
The paradigm	0.005208
2001 and	0.500000
human-written ones	0.500000
far from	0.125000
recognition such	0.008264
high rank	0.055556
book a	0.125000
and documents	0.001445
divided up	0.333333
by Lawrence	0.005714
baseball league	1.000000
runs PageRank	1.000000
correctly-developed	0.000029
thus makes	0.100000
stands for	1.000000
black	0.000029
Aletta Norval	1.000000
= 2PR	0.111111
image representing	0.333333
their ratings	0.029412
by both	0.005714
e.g. person	0.017857
based approach	0.018519
to automatizing	0.001328
holder of	1.000000
ID card	1.000000
user-provided number	1.000000
tagset by	1.000000
College -LRB-	0.500000
no assumptions	0.076923
and TextRank	0.001445
its grammatical	0.028571
invalid constructs	1.000000
sidestepped the	1.000000
substitutions .	1.000000
Some ISO	0.047619
possessive	0.000029
200 ,	0.500000
by The	0.005714
-RRB- Telematics	0.002817
progress is	0.142857
perform automated	0.090909
offered	0.000029
the equivalent	0.000692
bilingual corpus	0.500000
can of	0.005525
are certain	0.004149
allow discriminative	0.200000
far too	0.125000
as ME	0.003484
readable summary	0.333333
Mr. is	0.500000
available resources	0.058824
can identify	0.005525
methods In	0.022727
Liu 's	1.000000
the emergence	0.000692
or keyphrases	0.004505
- for	0.062500
of proper	0.000891
years after	0.047619
operating on	0.500000
driven ,	1.000000
card number	0.250000
Solutions have	1.000000
lexical functional	0.076923
element of	1.000000
rule that	0.333333
\/ -LRB-	0.333333
answers that	0.083333
text on	0.006289
safety critical	1.000000
parse natural	0.111111
-LRB- Keyphrase	0.002710
text of	0.006289
aspect ,	0.500000
feature transformation	0.076923
novel proposal	1.000000
differ from	0.333333
that OCR	0.003546
containing examples	0.125000
Summarization of	0.250000
pilot effectiveness	0.200000
BORIS system	1.000000
Lehnart .	1.000000
and Civil	0.001445
its communicative	0.028571
their ``	0.029412
specified	0.000029
referring expressions	0.500000
with language	0.005464
-5 to	1.000000
, factors	0.000561
has two	0.011905
Sentence boundaries	0.200000
lunar	0.000029
seconds	0.000029
data where	0.012987
paper is	0.090909
understanding system	0.030303
separately from	1.000000
require to	0.045455
Basic sound	1.000000
book applies	0.125000
which consisted	0.007246
; applies	0.021277
where ``	0.028571
as categories	0.003484
some glue	0.012048
course of	0.333333
TNO	0.000029
other sentences	0.014286
assessments of	1.000000
tense of	0.500000
became the	0.200000
aircraft Substantial	0.142857
flexibility and	1.000000
but far	0.014706
sub-titling ,	1.000000
platform to	0.500000
discriminate between	0.333333
Correct answers	1.000000
the measurement	0.000692
Technolangue\/Easy Text	0.500000
involves paraphrasing	0.100000
projects in	0.500000
also growing	0.014493
assessing	0.000029
filtering out	1.000000
USMC	0.000029
school-age	0.000029
fast and	1.000000
ICASSP	0.000029
narrative	0.000029
building a	1.000000
handmade list	1.000000
derive meaning	0.500000
Higher rates	1.000000
, Barbara	0.000561
business rules	0.250000
one there	0.015385
starting	0.000029
other disciplines	0.014286
Wayne	0.000029
from printed	0.009615
competitions devoted	1.000000
December 2010	1.000000
More advanced	0.111111
is no	0.002033
they create	0.025000
Company for	0.500000
that ten	0.003546
desired language	0.200000
for sound	0.003610
, QUALM	0.000561
per page	0.250000
Text linguistics	0.166667
titled	0.000029
the magazine	0.000692
d'Albe	0.000029
Envelopes may	1.000000
summaries known	0.023256
surfer	0.000029
OCR -RRB-	0.020408
Makoto Nagao	1.000000
EHR will	0.333333
unigram ``	0.200000
person reads	0.052632
flow together	1.000000
a paper	0.001227
<s> consider	0.000769
anaphora .	1.000000
contain punctuation	0.083333
conduct with	1.000000
seek to	1.000000
read text	0.142857
they rely	0.025000
Larry Page	0.500000
in US	0.001873
be semantic	0.004219
controlling	0.000029
from computer	0.009615
the UC	0.000692
to video	0.001328
that corresponded	0.003546
Truecasing Statistical	1.000000
diversity as	0.250000
the Tablet	0.000692
des	0.000029
effectiveness in	0.333333
best candidate	0.055556
the challenge	0.000692
breathing	0.000029
Recent applications	0.333333
<s> Today	0.000769
both appear	0.032258
standard result	0.071429
attempted by	1.000000
is whether	0.002033
vary considerably	0.166667
letter ?	0.166667
see and	0.050000
letter ,	0.166667
semantic disambiguation	0.047619
<s> Besides	0.000769
and Sentences	0.001445
sometimes open-ended	0.076923
Dependent ''	1.000000
-LRB- Hirschman	0.002710
In all	0.009524
per minute	0.250000
Genres of	1.000000
Typical questions	0.500000
much funding	0.045455
analogy and	1.000000
most often	0.017241
finalized	0.000029
, among	0.000561
pilots in	0.500000
humans would	0.083333
handheld	0.000029
very attractive	0.024390
transcriptions -LRB-	0.500000
tasks due	0.031250
spoken natural	0.071429
1990s there	0.333333
morphologically	0.000029
character-by-character	0.000029
into basic	0.012821
Spontaneous Speech	1.000000
expectancy of	1.000000
Gdaniec	0.000029
incorporates a	1.000000
-LRB- rescoring	0.002710
cross-lingual -RRB-	0.500000
and non-linear	0.001445
can increase	0.005525
logical inference	0.166667
http:\/\/arxiv.org\/abs\/1104.2086	0.000029
voice is	0.076923
voice in	0.076923
insurance	0.000029
Machinery and	1.000000
Our evaluation	0.333333
McDonald -LRB-	1.000000
could recognize	0.062500
that Piron	0.003546
`` up	0.005291
`` uh	0.005291
`` um	0.005291
Semi-supervised and	1.000000
verbalization .	1.000000
are dealing	0.004149
Further applications	0.333333
to action	0.001328
a genetic	0.001227
very slow	0.024390
formulaic language	1.000000
<s> Dragon	0.000769
only complete	0.026316
newswire	0.000029
based only	0.018519
e-communities die	0.500000
<s> Keyphrases	0.000769
b	0.000029
such signals	0.008130
information display	0.021739
ink -LRB-	1.000000
Pike	0.000029
-RRB- tagger	0.002817
sentence-end after	1.000000
well-defined problem	1.000000
with any	0.005464
field ,	0.037037
together to	0.125000
vertices in	0.111111
extracted	0.000029
vertices is	0.111111
boolean syntactic	1.000000
depths	0.000029
specialised expertise	0.500000
, extracting	0.000561
used similar	0.008850
is permuted	0.002033
Robinson	0.000029
, taking	0.000561
or POST	0.004505
of neural	0.000891
human-made model	0.500000
oral talk-in-interaction	1.000000
are pre-marked	0.004149
corresponded	0.000029
a human-language	0.001227
carefully	0.000029
measurement is	0.500000
ambiguous context-free	0.083333
all about	0.023256
, LUNAR	0.000561
proper evaluation	0.142857
achieve performance	0.500000
campaign dedicated	0.200000
computerization	0.000029
market for	0.333333
Kurzweil sold	0.142857
do ''	0.038462
Wayne Ratliff	1.000000
Retrieval Conference	1.000000
learns a	1.000000
as classifying	0.003484
authoritative of	1.000000
blend into	0.333333
Consortium has	1.000000
word was	0.016667
normalization to	0.166667
that accuracy	0.003546
it appropriately	0.008547
clauses ,	1.000000
needs .	0.100000
correct output	0.066667
picture quality	0.250000
permuted automatically	1.000000
: rule-based	0.009804
a page	0.001227
interoperability between	1.000000
construction ,	0.333333
throughout	0.000029
AFTI	0.000029
, Gina	0.000561
feeling that	1.000000
discourse processing	0.027778
legends and	1.000000
translated ,	0.250000
, conversation	0.000561
Symantec Corporation	0.500000
translation when	0.013514
the relative	0.000692
reformulate the	1.000000
well known	0.035714
annotation or	0.250000
, tables	0.000561
the computerization	0.000692
order logic	0.071429
Tagset	0.000029
learn features	0.076923
states are	0.250000
evaluated by	0.142857
different method	0.020408
approaches based	0.035714
subtopic of	1.000000
medium or	0.333333
speaker or	0.055556
emphasize	0.000029
copying	0.000029
made explicit	0.062500
into individual	0.012821
dissertation at	0.333333
hybrid system	0.500000
may suffer	0.019231
software resources	0.037037
environment in	0.166667
that PageRank	0.003546
spend	0.000029
the string	0.000692
formatted output	1.000000
French in	0.125000
sound to	0.050000
a reader	0.001227
: Decoding	0.009804
being expended	0.055556
termed coarticulation	0.250000
In 1955	0.009524
Solving this	0.500000
injuries	0.000029
overall polarity	0.166667
still very	0.066667
where successively	0.028571
instance when	0.071429
further clues	0.125000
of processing	0.000891
machine-learning approach	0.250000
a cheque	0.001227
The extrinsic	0.005208
of language-processing	0.000891
in languages	0.001873
the N-best	0.000692
alphabetic	0.000029
leaving the	1.000000
meets the	0.500000
President Obama	0.250000
is orthogonal	0.002033
at A.C.	0.014706
integration	0.000029
Interspeech -RRB-	1.000000
linked because	0.333333
ellipsis	0.000029
advanced pattern	0.200000
video the	0.200000
narrowest and	1.000000
e.g. space	0.017857
speaker deliberately	0.055556
<s> Eight	0.000769
and used	0.001445
keyphrase using	0.052632
are less	0.004149
through sentiment	0.125000
-LRB- CWA	0.002710
Word Error	0.142857
or characters	0.004505
Speaker Dependent	0.166667
requiring all	0.500000
more widely	0.010526
mathematical rules	0.500000
<s> Higher	0.000769
Shared	0.000029
jokes -LRB-	1.000000
somewhat recent	0.500000
Joe Biden	1.000000
associate or	0.500000
, news	0.000561
forward	0.000029
extract subjective	0.250000
semantic similarity	0.047619
paper-to-computer	0.000029
Pyramid Method	1.000000
of formalisms\/languages	0.000891
content-analysis .	1.000000
language search	0.006757
Web as	0.111111
input -RRB-	0.024390
guessing wrong	1.000000
or phrase	0.004505
to search	0.001328
is embedded	0.002033
skilled linguist	1.000000
The Eurofighter	0.005208
a frame	0.001227
the morphology	0.000692
fail for	0.333333
it off	0.008547
them -LRB-	0.052632
inter-texual ones	0.500000
by keyphrase	0.005714
Tell me	1.000000
one has	0.015385
probabilities to	0.090909
of HMM-based	0.000891
needed without	0.047619
years various	0.047619
discards	0.000029
algorithm or	0.035714
Their methods	0.500000
are marked	0.004149
with diversity	0.005464
wear a	1.000000
attention to	0.500000
Ernesto	0.000029
of four	0.000891
or MLLT	0.004505
a rudimentary	0.001227
Angenot	0.000029
determine keyphrases	0.043478
Grishman R.	1.000000
a pollen	0.001227
with Swedish	0.005464
bites ''	0.333333
networks make	0.071429
demonstrations	0.000029
the fields	0.000692
might shed	0.038462
and Zacharov	0.001445
dictionary entries	0.142857
Why unsupervised	0.142857
computer code	0.022727
adaptive document\/text	0.333333
in smaller	0.001873
involved disabilities	0.166667
50 to	0.333333
research efforts	0.023810
Where such	1.000000
-LRB- MEAD	0.002710
with morphological	0.005464
nonexistent	0.000029
World War	0.142857
10 -RRB-	0.125000
taggers .	0.142857
past the	0.333333
about an	0.025000
evaluation considers	0.018519
Given enough	0.071429
Research Corporation	0.125000
theoretical underpinnings	0.333333
notably by	0.333333
Europe was	0.200000
from first	0.009615
different approaches	0.020408
of Pennsylvania	0.000891
picture distortion	0.250000
database queries	0.100000
Text-to-speech Text-proofing	1.000000
Some tag	0.047619
RDF .	1.000000
pages concluded	0.142857
computer performance	0.022727
accuracy under	0.032258
-LRB- VTLN	0.002710
Both acoustic	0.333333
given amount	0.041667
outside the	0.500000
levels are	0.045455
detect the	1.000000
discors pour	1.000000
analyzing a	0.200000
making them	0.142857
for measuring	0.003610
13 parsers	0.500000
most later	0.017241
providers began	1.000000
Authorities	0.000029
: Why	0.009804
an intermediary	0.007576
precursor to	1.000000
the open-access	0.000692
the ACL	0.000692
ISO standards	0.500000
RAE -RRB-	1.000000
using paraphrases	0.016949
aid users	0.250000
discourse studies	0.027778
parsers is	0.076923
techniques from	0.043478
similarity or	0.100000
parsers in	0.076923
Hindle	0.000029
le	0.000029
enough to	0.200000
resorting	0.000029
the abbreviation	0.000692
both its	0.032258
labor involved	0.500000
processing Statistical	0.018519
intensive as	1.000000
OCR machines	0.020408
an investigation	0.007576
doctors -RRB-	0.333333
rev	0.000029
automate the	0.333333
red	0.000029
different methods	0.020408
generate textual	0.055556
retrieved	0.000029
implied challenges	1.000000
receipts	0.000029
innumerable studies	1.000000
from NLP	0.009615
Ochs	0.000029
retail	0.000029
to impersonate	0.001328
various levels	0.055556
more deeply	0.010526
Administration	0.000029
a worldwide	0.001227
might co-occur	0.038462
to prepare	0.001328
though ROUGE-1	0.100000
semantic model	0.047619
the expectancy	0.000692
Universal	0.000029
hyphenation .	1.000000
practical systems	0.500000
the removal	0.000692
OCR .	0.020408
the ROUGE-1	0.000692
include .	0.037037
of filtering	0.000891
assessment ,	1.000000
interface for	0.250000
a referring	0.001227
first choice	0.030303
emerge that	1.000000
sciences concurrently	0.500000
VOLSUNGA .	1.000000
'' other	0.005376
by transfer-based	0.005714
is Hard	0.002033
it learns	0.008547
techniques in	0.043478
Elinor	0.000029
It thus	0.026316
supported	0.000029
MARGIE -LRB-	1.000000
details of	0.500000
<s> Markov	0.000769
L. 1998	1.000000
due especially	0.200000
what day	0.031250
content selection	0.083333
the Standard	0.000692
Adriana	0.000029
is too	0.002033
can still	0.005525
by whom	0.005714
pruned to	1.000000
medical informatics	0.166667
Bois	0.000029
organised by	1.000000
entering a	0.500000
would both	0.018868
an excerpt	0.007576
the analog	0.000692
summarization based	0.020000
bank .	1.000000
exploited	0.000029
more widespread	0.010526
on OCR	0.004717
conversion .	0.333333
knowledge to	0.037037
which to	0.007246
, inter-texual	0.000561
compare various	0.142857
because fast	0.033333
implementing	0.000029
Merging	0.000029
different co-occurring	0.020408
or structured	0.004505
range .	0.142857
freely	0.000029
early systems	0.100000
might learn	0.038462
famous QA	0.333333
dBase	0.000029
RAF employs	1.000000
, discourse	0.000561
filtered out	0.333333
in polynomial	0.001873
the Amount	0.000692
use in	0.013889
several seconds	0.045455
use is	0.013889
Harris 1991	0.111111
piecewise	0.000029
problems of	0.058824
<s> Jump	0.000769
Increase as	1.000000
preliminary ,	0.333333
one 10msec	0.015385
Center	0.000029
structured documents	0.166667
meet a	0.250000
no effects	0.076923
emotion ,	1.000000
highlighted ,	1.000000
-LRB- SWER	0.002710
Human Aided	0.200000
thousands or	0.333333
500 texts	0.500000
prose	0.000029
valuable new	0.500000
than optimizing	0.022222
unreferenced section	1.000000
98.5 %	1.000000
+ Cloud	0.166667
parses -LRB-	0.500000
been superseded	0.014706
man-hours	0.000029
algorithms work	0.028571
knowledge source	0.037037
center	0.000029
-RRB- amongst	0.002817
human summaries	0.021739
letter to	0.166667
have specific	0.009615
and support	0.001445
written conversation	0.038462
approximate at	0.500000
that consider	0.003546
as voice	0.003484
languages text	0.020000
as Greek	0.003484
, semantically	0.000561
as blogs	0.003484
submit them	0.500000
elementary sounds	1.000000
MIT wrote	0.500000
worlds	0.000029
began offering	0.142857
the true	0.000692
10 parsers	0.125000
above techniques	0.076923
automatic lip-synch	0.043478
that combine	0.003546
are interpreted	0.004149
on finding	0.004717
direction of	0.333333
output by	0.038462
hear this	0.500000
of Speech	0.000891
imprints	0.000029
domain-independent	0.000029
JSF -RRB-	1.000000
or words	0.004505
Further information	0.333333
Conferences ,	0.500000
measure ,	0.090909
for tagging	0.003610
character error	0.045455
encouraging	0.000029
are rarely	0.004149
them out	0.052632
tell it	0.333333
morphology of	0.142857
pilot workload	0.200000
depths of	1.000000
of Natural	0.000891
measure a	0.090909
only study	0.026316
core elements	0.500000
processes such	0.200000
output distribution	0.038462
\/ target-language-independent	0.333333
sound that	0.050000
all possibilities	0.023256
Questions	0.000029
rendered	0.000029
dataset	0.000029
not invented	0.008929
phrase-structure	0.000029
the Senseval	0.000692
for 1-July-2005	0.003610
1984	0.000029
1985	0.000029
1983	0.000029
online assistant	0.125000
was later	0.012987
on Hidden	0.004717
potential and	0.142857
and associated	0.001445
human capabilities	0.021739
1949 .	0.500000
a score	0.001227
partially	0.000029
noun phrases	0.071429
same information	0.040000
or 100000	0.004505
allowing greater	0.333333
similar measure	0.037037
or it	0.004505
or in	0.004505
autopilot system	1.000000
which of	0.007246
a topic	0.001227
full sentenced	0.200000
virtual	0.000029
Schank 's	0.200000
assess the	0.333333
report finalized	0.250000
dependency for	0.200000
variation	0.000029
Act	0.000029
or nonexistent	0.004505
<s> Winograd	0.000769
same topic	0.040000
system whose	0.010753
presentation of	1.000000
augmented	0.000029
probably use	0.250000
, potentially	0.000561
<s> Virtually	0.000769
to mimic	0.001328
analyses ,	0.200000
Introduction and	1.000000
produce textual	0.045455
shown that	0.200000
the parts	0.000692
current efforts	0.142857
linguistic analysis	0.062500
Another resource	0.076923
final sounds	0.111111
and paste	0.001445
and power	0.001445
Some notably	0.047619
writing SHRDLU	0.111111
to seize	0.001328
leaders	0.000029
logical deduction	0.166667
Gaussians	0.000029
related .	0.066667
estimated	0.000029
publication devoted	0.333333
Continuous	0.000029
<s> Apart	0.000769
both rules	0.032258
their more	0.029412
conduct	0.000029
house -LRB-	0.500000
the nautical	0.000692
remains another	0.250000
four together	0.142857
<s> Basically	0.000769
Beatrice	0.000029
recognized draft	0.166667
than supervised	0.022222
-RRB- showed	0.002817
-RRB- classifier	0.002817
the Optophone	0.000692
'' sentence	0.005376
-LRB- one	0.002710
lessening	0.000029
as shallow-transfer	0.003484
possibilities multiply	0.200000
, HMM-based	0.000561
<s> From	0.000769
size of	0.166667
about 25	0.025000
revolutionized bill	1.000000
me	0.000029
was drawn	0.012987
join	0.000029
my	0.000029
space complexity	0.200000
become repetitive	0.250000
be specified	0.004219
left-recursion and	1.000000
key words	0.166667
deemed most	0.500000
Dog bites	1.000000
right -LRB-	0.100000
entering the	0.500000
statistics :	0.125000
, Art	0.000561
statistics ,	0.125000
Deborah Tannen	0.500000
pre-existing keyphrases	0.500000
Essentially	0.000029
can greatly	0.005525
reduced amount	0.250000
thereby editing	1.000000
task usually	0.023810
Semantic Evaluation	0.333333
Prolog generally	1.000000
religious services	1.000000
as doctors	0.003484
bootstrap	0.000029
maybe to	1.000000
or syntactic	0.004505
quantitative one	0.250000
descriptor in	1.000000
thesis	0.000029
such name	0.008130
comprehend	0.000029
<s> DTW	0.000769
fade	0.000029
to assist	0.001328
`` unsupervised	0.005291
to compiled	0.001328
`` nine	0.005291
parse individual	0.111111
of mobile	0.000891
decimal point	1.000000
unreferenced	0.000029
of action	0.000891
wave and	0.111111
single ``	0.071429
Carmen Rosa	1.000000
signing	0.000029
-- including	0.040000
structured real-world	0.166667
the use\/mention	0.000692
1929 Gustav	1.000000
authors provide	0.200000
object ``	0.500000
got	0.000029
semantic representation	0.047619
word British	0.016667
to carefully	0.001328
directly from	0.200000
each state	0.022222
with Tom	0.005464
mining have	0.200000
revolution in	1.000000
system had	0.010753
typically agree	0.055556
was unveiled	0.012987
coding	0.000029
accurate even	0.142857
new methods	0.041667
Widdowson ,	1.000000
Summarization systems	0.250000
-LRB- MLLR	0.002710
aircraft .	0.142857
verbs -LRB-	0.200000
Lexical segmentation	0.500000
of certain	0.000891
words two	0.009174
several classifiers	0.045455
to corpus	0.001328
took	0.000029
triples and	0.333333
human linguists	0.021739
Sydney Lamb	1.000000
Features	0.000029
summary '	0.023810
where clear	0.028571
these heuristics	0.023810
others they	0.083333
a trend	0.001227
this data	0.010989
fashion	0.000029
nonsensical to	1.000000
talking	0.000029
single document	0.071429
1,915,993 -RRB-	1.000000
behavior even	0.500000
and time-consuming	0.001445
oriented	0.000029
Dale -LRB-	1.000000
coarse-grained	0.000029
preliminary recognition	0.333333
of dependency	0.000891
been popular	0.014706
can indeed	0.005525
summarization Machine	0.020000
ways by	0.125000
movement to	1.000000
CWA	0.000029
, leading	0.000561
this technology	0.010989
used during	0.008850
flow	0.000029
enterprise	0.000029
allow spoken	0.200000
the Latin	0.000692
nice properties	0.250000
design the	0.250000
salience	0.000029
pages getting	0.142857
semantics -RRB-	0.071429
statistical properties	0.030303
mixture	0.000029
; while	0.021277
followed perhaps	0.250000
, Henry	0.000561
Kolodner .	1.000000
perhaps because	0.166667
The USAF	0.005208
learned is	0.200000
omni-font OCR	1.000000
of laws	0.000891
analysis Sublanguage	0.015385
when it	0.028571
smaller tag-sets	0.142857
larger corpora	0.062500
limiting	0.000029
benefits :	0.500000
made available	0.062500
data within	0.012987
a matter	0.001227
Sound Graph	0.333333
confusion	0.000029
better measure	0.111111
things ,	0.333333
Telephone Company	1.000000
is both	0.002033
built in	0.333333
20,000 words	1.000000
protect	0.000029
itself is	0.200000
each known	0.022222
the stationary	0.000692
skip the	1.000000
epidemic	0.000029
Each sample	0.166667
another he	0.076923
beer	0.000029
overlap ,	0.250000
overlap .	0.250000
i.e. it	0.052632
User profiling	0.500000
Interactional sociolinguistics	1.000000
objects of	0.200000
turns-at-talk	0.000029
, resolve	0.000561
were then	0.024390
their reputations	0.029412
translation capabilities	0.013514
easily ,	0.111111
relevance or	0.333333
recursion	0.000029
it affects	0.008547
government and	0.333333
<s> Big	0.000769
from large	0.009615
-LRB- 2000	0.002710
-LRB- 2001	0.002710
-LRB- 2004	0.002710
-LRB- 2005	0.002710
-LRB- 2008	0.002710
compiler ,	0.333333
expected -LRB-	0.142857
models derived	0.038462
answers the	0.083333
impressive results	0.500000
Statistical Methods	0.111111
Success Rate	1.000000
approximation of	0.166667
idea is	0.142857
than metrics	0.022222
a naive	0.001227
Speech recogniton	0.032258
up an	0.045455
G. ,	0.500000
applies those	0.142857
National Giro	0.333333
in software	0.001873
Research on	0.125000
a 3	0.001227
topic boundaries	0.125000
a 4	0.001227
template containing	0.250000
D	0.000029
the entities	0.000692
while on-line	0.050000
estimation and	1.000000
as it	0.003484
<s> Main	0.000769
article on	0.034483
This parses	0.015873
Gismo .	0.500000
F-16 aircraft	0.500000
fixed static	0.500000
indirect	0.000029
identified which	0.200000
the strings	0.000692
more words	0.010526
implemented in	0.200000
agreement is	0.333333
, content	0.000561
outputs of	1.000000
translation method	0.013514
Formal equivalence	1.000000
data at	0.012987
Journal .	0.333333
Hollenbach	0.000029
that without	0.003546
-RRB- Cohesion	0.002817
limitation	0.000029
run-time	0.000029
the implications	0.000692
objects and	0.200000
of AI	0.000891
left-most and	0.500000
geospatial questions	1.000000
than other	0.022222
primitive	0.000029
Much effort	0.333333
readily produces	0.333333
modern approaches	0.200000
Given the	0.071429
wishes to	1.000000
Language modeling	0.083333
categorization	0.000029
words have	0.009174
ambiguous when	0.083333
Competing	0.000029
statistical and	0.030303
radios ,	1.000000
, Pang	0.000561
computer OCR	0.022727
authors decide	0.200000
generate keyphrases	0.055556
increasingly focused	0.333333
, large-vocabulary	0.000561
classification looks	0.058824
production has	0.333333
requires an	0.062500
print a	1.000000
time are	0.030303
of special	0.000891
further discussed	0.125000
translation components	0.013514
besides words	1.000000
preceding	0.000029
-RRB- Commissioned	0.002817
reason is	0.250000
more such	0.010526
e.g. vocabulary	0.017857
typically one	0.055556
Latin very	0.250000
assumptions such	0.200000
region in	1.000000
discussions about	0.333333
taggers for	0.142857
Artificial Intelligence	0.500000
algebra .	0.500000
varying	0.000029
like relevance	0.035714
and one	0.001445
web 2.0	0.125000
case-based reasoning	1.000000
procedure still	0.333333
Japanese -RRB-	0.125000
of concern	0.000891
vital .	1.000000
discrete terms	0.333333
your system	0.500000
as noun	0.003484
Chinese is	0.142857
faster but	0.333333
extraction Answer	0.032258
was greatly	0.012987
political forums	0.333333
It follows	0.026316
accumulation	0.000029
tasks has	0.031250
likely uttered	0.062500
more generally	0.010526
to acquire	0.001328
Red	0.000029
shorter the	0.500000
creates a	0.500000
isolated NLP	0.200000
realizations	0.000029
for Greek	0.003610
normally do	0.500000
articulation ,	1.000000
thirty	0.000029
what happens	0.031250
delimiter	0.000029
efforts are	0.142857
offs in	1.000000
strong feeling	0.250000
Much remains	0.333333
speaker reads	0.055556
this understanding	0.010989
ACL ,	0.500000
stored	0.000029
into smaller	0.012821
tagging for	0.040000
available on	0.058824
are limited	0.004149
; An	0.021277
documents than	0.026316
on linguistic	0.004717
were undertaken	0.024390
an English-like	0.007576
successful NLG	0.111111
major influence	0.083333
Digitized Sound	1.000000
from several	0.009615
classification error	0.058824
successful NLP	0.111111
domain or	0.050000
laughter	0.000029
sub-signals .	1.000000
learning approaches	0.023256
-LRB- selecting	0.002710
some local	0.012048
an easy	0.007576
foreign ''	0.500000
few sentences	1.000000
require significant	0.045455
innumerable	0.000029
many similar	0.019231
's the	0.019608
patents .	1.000000
computers and	0.111111
aircraft platforms	0.142857
news release	0.076923
also programs	0.014493
methodology to	0.500000
targets to	1.000000
both LexRank	0.032258
training and	0.035714
shows ,	1.000000
word co-occurrence	0.016667
best algorithms	0.055556
coordinates	0.000029
Who invented	0.500000
symbol in	0.250000
original voice	0.076923
common plural	0.040000
detailed background	0.500000
Web is	0.111111
until the	0.500000
language documents	0.006757
noise and	0.125000
as early	0.003484
out ''	0.071429
dictionary-based	0.000029
of John	0.000891
coherent or	0.200000
Critical discourse	0.500000
adequately	0.000029
lexicon ,	0.111111
ultimately	0.000029
lexicon .	0.111111
belongs to	1.000000
replicated his	1.000000
basic approach	0.076923
essentially to	0.125000
morphemes and	0.333333
word-category disambiguation	1.000000
the addressee	0.000692
speech the	0.006579
units ,	0.142857
English this	0.027027
units ;	0.142857
searching and	0.333333
automatic metric	0.043478
person-years of	1.000000
little inflectional	0.333333
language in	0.006757
their associated	0.029412
and Canada	0.001445
convention	0.000029
proposed .	0.111111
LexRank has	0.083333
who ''	0.100000
and analysis	0.001445
QA computer	0.047619
holder	0.000029
cryptanalyst	0.000029
pre	0.000029
Computationally	0.000029
's students	0.019608
pro	0.000029
machine speech	0.012658
recognition conferences	0.008264
context that	0.030303
semantic lexicons	0.047619
or continuous	0.004505
informal behavior	0.500000
, political	0.000561
choice :	0.125000
expression or	0.100000
regards to	1.000000
comprises all	1.000000
payment systems	1.000000
isolated word	0.200000
banking system	1.000000
or places	0.004505
require their	0.045455
distribution ;	0.250000
and count	0.001445
can present	0.005525
several million	0.045455
the approximate	0.000692
June 1990	1.000000
his ``	0.083333
business data	0.250000
, allowing	0.000561
formed Symantec	0.200000
that capture	0.003546
any font	0.032258
movie reviews	0.333333
V.J.	0.000029
Roger Fowler	0.250000
1998 The	0.250000
estimating the	1.000000
others ,	0.083333
floods	0.000029
is preferable	0.002033
Mirage	0.000029
disambiguation on	0.100000
are displayed	0.004149
years to	0.047619
undertook	0.000029
stream is	0.500000
detect	0.000029
rules are	0.023256
in source	0.001873
artificial neural	0.090909
and RCA	0.001445
was one	0.012987
Voice Control	0.200000
English for	0.027027
between Internet	0.025641
T to	0.166667
Chomskyan	0.000029
receivers	0.000029
the legends	0.000692
least historically	0.200000
content of	0.083333
and removed	0.001445
to interface	0.001328
opinions or	0.500000
successes	0.000029
region	0.000029
confusions with	1.000000
at NYU	0.014706
not pursued	0.008929
separate out	0.100000
new .	0.041667
color	0.000029
Transform	0.000029
, Ernesto	0.000561
some new	0.012048
are explicitly	0.004149
Typhoon	0.000029
mean of	0.500000
hardly	0.000029
output simply	0.038462
define several	0.500000
smart keyboard	1.000000
QA Before	0.047619
put together	0.250000
a podcast	0.001227
evaluations ,	0.166667
evaluations .	0.166667
Barbara	0.000029
paying	0.000029
Computer Problem	0.166667
exploits the	1.000000
, evaluation	0.000561
thus it	0.100000
technique in	0.142857
tested in	0.500000
LexRank The	0.083333
for Amharic	0.003610
values correlate	0.125000
punched	0.000029
via the	1.000000
and Natural	0.001445
POS-tagging algorithms	1.000000
is insufficient	0.002033
the choice	0.000692
events	0.000029
Sentence breaking	0.200000
about to	0.025000
Homayoon	0.000029
in accordance	0.001873
of robustness	0.000891
changing	0.000029
on either	0.004717
discourse analyst	0.027778
Automatic vs.	0.111111
much time	0.045455
at emotional	0.014706
guided	0.000029
On January	0.166667
language usually	0.006757
uh ''	1.000000
Piron mentions	0.333333
, Naive	0.000561
13 ,	0.500000
% correct	0.025641
except	0.000029
, individual	0.000561
system on	0.010753
includes -LRB-	0.142857
UC and	0.500000
, dimensions	0.000561
recent news	0.125000
available soon	0.058824
desired structure	0.200000
success and	0.200000
also attempt	0.014493
Nikolas	0.000029
defined by	0.166667
mechanisms of	0.500000
successful .	0.111111
voice commands	0.076923
subtypes	0.000029
disambiguate parts	0.333333
prolific	0.000029
systems included	0.008929
'' where	0.005376
programming language	0.200000
item may	1.000000
low-resolution	0.000029
Schegloff ,	1.000000
analyzing human-written	0.200000
real-world applications	0.166667
and languages	0.001445
vs. independence	0.083333
<s> User	0.000769
six -LRB-	0.500000
use an	0.013889
originally as	0.500000
separate tokens	0.100000
categories could	0.111111
of 21	0.000891
from limited	0.009615
Sandra	0.000029
typically uses	0.055556
against a	0.200000
of prisoner-of-war	0.000891
or classified	0.004505
's subscription	0.019608
recognition scores	0.008264
superseded by	1.000000
politics	0.000029
methods parse	0.022727
negative to	0.125000
printed texts	0.083333
feature statistical	0.076923
recognize all	0.111111
art .	0.500000
has already	0.011905
to reliable	0.001328
usually abbreviated	0.031250
worldwide view	1.000000
for input	0.003610
see above	0.050000
abbreviated to	1.000000
Brain	0.000029
-RRB- do	0.002817
open ,	0.250000
OS or	0.500000
independently developed	1.000000
canonical form	1.000000
those organised	0.045455
devices take	0.250000
removal	0.000029
presentation	0.000029
scores are	0.200000
Michael Halliday	0.250000
in further	0.001873
system proposed	0.010753
distinction with	0.200000
spoken version	0.071429
a training	0.001227
Record or	1.000000
Ontology -RRB-	1.000000
ten	0.000029
embedded quotations	0.250000
theory -RRB-	0.076923
<s> Sometimes	0.000769
's necessary	0.019608
meanings of	0.250000
humanities and	1.000000
Morpheme	0.000029
software started	0.037037
are popular	0.004149
deeply	0.000029
the position	0.000692
task depends	0.023810
recent development	0.125000
developing a	0.250000
phones and	0.500000
speaking -RRB-	0.125000
and named	0.001445
, imagery	0.000561
summaries do	0.023256
not resulted	0.008929
modified in	1.000000
understanding systems	0.030303
Style	0.000029
for evaluation	0.003610
without limits	0.076923
and Church	0.001445
accomplished in	1.000000
and Chinese	0.001445
associate discrete	0.500000
evaluation -LRB-	0.018519
is formed	0.002033
for special	0.003610
-LRB- Adda	0.002710
happens when	1.000000
support personnel	0.250000
repetitive stress	0.500000
Confusable	0.000029
= accusative	0.111111
with using	0.005464
networks are	0.071429
and introducing	0.001445
mimic the	1.000000
Of particular	1.000000
features describing	0.038462
Jacob Rabinow	1.000000
other English	0.014286
type provided	0.071429
good source	0.076923
, predicting	0.000561
've seen	0.500000
taggers are	0.142857
predicate	0.000029
arise	0.000029
and going	0.001445
combining the	0.250000
have humans	0.009615
publishing ,	1.000000
grammatical constituents	0.090909
reported for	0.200000
textual weather	0.200000
continued with	0.111111
for sentence	0.003610
the mid	0.000692
available -LRB-	0.058824
was only	0.012987
engaging in	1.000000
capitalize	0.000029
reader processed	0.100000
ontologies -LRB-	0.166667
ports .	1.000000
tokens 12	0.142857
understanding :	0.030303
segment in	0.111111
mission	0.000029
spoken sentences	0.071429
summaries available	0.023256
model mechanisms	0.033333
Caldas-Coulthard ,	1.000000
attempts have	0.166667
Cleave	0.000029
Front-End speech	1.000000
character .	0.045455
for grammars	0.003610
1954 -RRB-	0.333333
even ``	0.037037
why automatic	0.142857
affected by	1.000000
inherent	0.000029
10msec section	0.500000
of languages	0.000891
sublanguage domains	0.333333
Jefferson	0.000029
issue for	0.125000
include all	0.037037
is 8000	0.002033
naive Bayes	0.500000
an attractive	0.007576
health	0.000029
hand-compiled	0.000029
experimenting	0.000029
such application	0.008130
in text	0.001873
profile may	0.333333
teach	0.000029
SemEval -RRB-	1.000000
captures data	1.000000
typical to	0.111111
Evaluation exercises	0.111111
writing rules	0.111111
significantly .	1.000000
both summarization	0.032258
, hypothetical	0.000561
spelling .	1.000000
degradation in	1.000000
Frost	0.000029
themselves .	0.250000
speech sounds	0.006579
information Popular	0.021739
by describing	0.005714
the undercarriage	0.000692
Armed Forces	1.000000
One step	0.076923
information are	0.021739
Romance languages	1.000000
includes Turney	0.142857
first such	0.030303
-- computer	0.040000
usually takes	0.031250
or query	0.004505
VISTA	0.000029
versa first-cut	1.000000
of shared	0.000891
expected for	0.142857
F-score ,	1.000000
, Talmy	0.000561
process -LRB-	0.027778
, contains	0.000561
what might	0.031250
available from	0.058824
later the	0.100000
sense a	0.125000
may then	0.019231
person .	0.052632
also important	0.014493
email Multimodal	0.500000
, Gdaniec	0.000561
fluent native	1.000000
children ,	0.500000
team led	1.000000
other POS	0.014286
work at	0.041667
difficulty using	0.142857
worked by	0.200000
memorandum	0.000029
Morse Code	1.000000
, from	0.000561
To perform	0.111111
and architecture	0.001445
concentrates on	1.000000
Why it	0.142857
walk is	0.200000
Grace project	1.000000
-LRB- SemEval	0.002710
of bottom-up	0.000891
Why ,	0.142857
following is	0.066667
function for	0.125000
an Electronic	0.007576
and life	0.001445
TF-IDF	0.000029
1,000,000	0.000029
periods in	0.333333
whereas in	0.333333
simulation is	0.333333
approached in	0.500000
2,663,758 .	1.000000
be quite	0.004219
grammatical structure	0.090909
generally used	0.090909
see Inter-rater	0.050000
breadth ''	0.500000
oriented systems	1.000000
on Mirage	0.004717
a group	0.001227
billing purposes	1.000000
Willig	0.000029
restricted-domain QA	1.000000
by combining	0.005714
metric for	0.333333
tokens that	0.142857
era of	1.000000
text-to-speech synthesizer	0.250000
of war	0.000891
has characterized	0.011905
character stream	0.045455
p.	0.000029
pronouns and	0.500000
Biden was	0.333333
A morphosyntactic	0.020000
Hindle D.	1.000000
blocks world	0.250000
turns-at-talk .	1.000000
technologies have	0.250000
pumps ''	0.500000
with sentences	0.005464
from social	0.009615
answers rather	0.083333
exactly this	0.333333
linguistic controversy	0.062500
efficient manner	0.333333
languages using	0.020000
Man bites	0.500000
characters \*	0.062500
optimization methods	1.000000
tools mostly	0.166667
aim of	0.500000
Constraints are	0.333333
also granted	0.014493
Parsing :	0.200000
whom -RRB-	0.500000
abilities	0.000029
<s> First	0.000769
, comprehend	0.000561
produce such	0.045455
one distinguishes	0.015385
stationary probabilities	0.142857
analyzed with	0.200000
exclusively	0.000029
in conference	0.001873
could read	0.062500
some large	0.012048
larger chunk	0.062500
, Richard	0.000561
tongues sharing	1.000000
Penn -RRB-	0.111111
integer	0.000029
Often a	0.333333
phrasing the	1.000000
translators	0.000029
ones in	0.100000
only five	0.026316
understood	0.000029
of canned	0.000891
gradually	0.000029
translates to	1.000000
prisoner-of-war camp	1.000000
tends	0.000029
fragments	0.000029
for .	0.003610
itself as	0.200000
an early	0.007576
for 5	0.003610
for mental	0.003610
also need	0.014493
One task	0.076923
being psychotherapy	0.055556
the typewritten	0.000692
a prior	0.001227
each pilot	0.022222
fast	0.000029
keyphrases of	0.028571
Every	0.000029
paraphrase .	1.000000
OCR Document	0.020408
as weighted	0.003484
platforms	0.000029
to language	0.001328
priorities .	1.000000
Syntactic	0.000029
Encouraging	0.000029
word-forms	0.000029
Establishment	0.000029
Marilyn Monroe	1.000000
form logical	0.050000
research articles	0.023810
, idioms	0.000561
all governmental	0.023256
called query-biased	0.055556
multiple languages	0.076923
ground established	1.000000
helping people	1.000000
conversational content	1.000000
Rogerian	0.000029
The systems	0.005208
methods more	0.022727
expert that	1.000000
issued	0.000029
tables with	0.333333
were later	0.024390
-LRB- JSF	0.002710
work based	0.041667
democratizing publishing	0.500000
levels or	0.045455
, preposition	0.000561
division rather	0.500000
, exploring	0.000561
some programming	0.012048
check how	0.500000
car	0.000029
farther forward	1.000000
Google used	0.250000
reliability ,	0.500000
idea ,	0.142857
correct software	0.066667
alternative approach	0.333333
for commercial	0.003610
rephrase sentences	1.000000
<s> Shepard	0.000769
subjective sentences	0.166667
-LRB- end	0.002710
stochastic matrix	0.125000
on Shepard	0.004717
The profile	0.005208
and see	0.001445
earliest example	0.500000
Eastern Peru	1.000000
or highly	0.004505
quality .	0.100000
covers speech	0.250000
Hybrid MT	0.500000
Treebank project	0.166667
in Jones	0.001873
were rare	0.024390
reading credit	0.125000
addressee	0.000029
biomedical domain	1.000000
GenEx algorithm	1.000000
few	0.000029
Objectives The	1.000000
timing	0.000029
specially designed	1.000000
schematic	0.000029
recorded all	0.500000
Blind In	0.500000
Supervised	0.000029
Tannen	0.000029
of reasons	0.000891
barmaid .	0.166667
with many	0.005464
Deferred speech	1.000000
need context	0.047619
iteration ,	1.000000
tagging program	0.040000
initially clear	1.000000
visit Iraq	0.500000
Emanuel Goldberg	0.500000
entirely committed	0.500000
canned phrases	0.500000
summers	0.000029
in embedded	0.001873
edge cases	0.333333
capitalizes all	1.000000
, Google	0.000561
, hence	0.000561
possible improvement	0.041667
tractability	0.000029
and probably	0.001445
marks are	0.250000
and direction	0.001445
and practice	0.001445
applications can	0.040000
gold standards	0.166667
neighbors .	0.333333
neighbors ,	0.333333
aloud from	1.000000
or uncertainties	0.004505
Did Marilyn	1.000000
but could	0.014706
more precise	0.010526
Optical Character	0.333333
sub-categories	0.000029
estimating	0.000029
has wide	0.011905
orange	0.000029
GRM library	1.000000
defining	0.000029
singular ,	0.250000
did fail	0.200000
given ,	0.041667
the cosine	0.000692
all caps	0.023256
<s> Books	0.000769
unfortunately ,	1.000000
; that	0.021277
and whether	0.001445
human knowledge	0.021739
`` centrality	0.005291
algorithms --	0.028571
sentences with	0.013158
be defined	0.004219
a lunar	0.001227
starts with	0.500000
plant OCR	1.000000
that users	0.003546
numbers on	0.142857
relay services	1.000000
, grammars	0.000561
which research	0.007246
one may	0.015385
contains additional	0.100000
phrased	0.000029
John Du	0.125000
pieces as	1.000000
of off-line	0.000891
cognition and	1.000000
It converted	0.026316
of Question	0.000891
of London	0.000891
cited the	1.000000
ICASSP ,	1.000000
Intra-texual	0.000029
its decomposition	0.028571
regards	0.000029
intonation	0.000029
tables of	0.333333
to submit	0.001328
casual speech	1.000000
hearings	0.000029
study ,	0.250000
narrative text	1.000000
<s> Anaphor	0.000769
By 1985	0.333333
mention in	0.333333
talk-in-interaction .	1.000000
for descriptive	0.003610
2PR \/	1.000000
the Alenia	0.000692
first use	0.030303
the relevance	0.000692
impossible when	0.500000
deteriorated with	1.000000
would correspond	0.018868
Parseval\/GEIG	0.000029
historical data	1.000000
key phrases	0.166667
data redundancy	0.012987
prose text	1.000000
known keyphrase	0.038462
of finite	0.000891
often possible	0.022727
be referred	0.004219
sailor →	0.200000
aims at	0.333333
not obvious	0.008929
wingmen	0.000029
no.	0.000029
, Court	0.000561
Recovery	0.000029
of perspective	0.000891
then chosen	0.028571
left to	0.166667
spun	0.000029
verification .	1.000000
but to	0.014706
non-existent words	1.000000
users sometimes	0.111111
generate jokes	0.055556
termed Direct	0.250000
split it	0.250000
make no	0.050000
version ;	0.333333
Desktop &	1.000000
on specific	0.004717
fail to	0.333333
machines to	0.250000
reducing the	0.500000
Units	0.000029
the stage	0.000692
: Deciding	0.009804
cepstral normalization	0.500000
unigrams and	0.083333
Programming methods	0.333333
, sentiment	0.000561
industry currently	0.333333
NASA 's	1.000000
medical professionals	0.166667
the additional	0.000692
keeping a	0.500000
before .	0.166667
dividing written	0.333333
Voice2Go -RRB-	1.000000
most upper	0.017241
interpretable rules	1.000000
sentence also	0.020833
some interrogative	0.012048
why Vice	0.142857
the authors	0.000692
to guide	0.001328
it began	0.008547
contexts in	0.142857
very widely	0.024390
language as	0.006757
Klavans	0.000029
Gripen cockpit	1.000000
inadequate	0.000029
<s> Coreference	0.000769
analysis as	0.015385
, Chantal	0.000561
<s> Decoding	0.000769
whether they	0.076923
for breathing	0.003610
15-20 million	1.000000
or most	0.004505
declared before	0.500000
possessive ,	1.000000
not worked	0.008929
results were	0.047619
untagged	0.000029
Matches between	1.000000
information deemed	0.021739
Reinvestment	0.000029
Electronic Medical	0.500000
a member	0.001227
company Kurzweil	0.333333
Scotland ,	0.200000
member	0.000029
that much	0.003546
still just	0.066667
reliability -RRB-	0.500000
by analogy	0.005714
only be	0.026316
TF-IDF vectors	1.000000
even disappear	0.037037
at input	0.014706
navigation systems	0.500000
general concepts	0.045455
before or	0.166667
each year	0.022222
the token	0.000692
meaningful symbols	0.125000
of online	0.000891
queries on	0.333333
rapid	0.000029
Morphological	0.000029
or moderate	0.004505
, spacecraft	0.000561
But recognition	0.166667
yes-no	0.000029
uses search	0.071429
presume	0.000029
2007 -RRB-	0.200000
Energy -LRB-	1.000000
or generators	0.004505
have approached	0.009615
undirected and	1.000000
lowest level	1.000000
Section	0.000029
entry -LRB-	0.250000
the mid-90s	0.000692
to physicians	0.001328
text normalization	0.006289
information contained	0.021739
\* -LRB-	0.250000
as 1946	0.003484
Algorithm	0.000029
conveyed	0.000029
Lightning II	1.000000
analyser	0.000029
perspectives	0.000029
extension	0.000029
column	0.000029
Zacharov	0.000029
generally rely	0.090909
that sentences	0.003546
a bank	0.001227
Star Trek	1.000000
consecutively	0.000029
SRI International	1.000000
disagree on	0.333333
EHR -RRB-	0.333333
smoothing	0.000029
in 1953	0.001873
in 1952	0.001873
, possibly	0.000561
compare their	0.142857
conferences held	1.000000
or word-category	0.004505
triggered	0.000029
Intuitively ,	1.000000
bill stub	0.500000
machine printed	0.012658
-RRB- mark	0.002817
in popular	0.001873
articles from	0.125000
obvious at	1.000000
documents or	0.026316
came from	0.500000
the Reader	0.000692
computer analysis	0.022727
demonstrate	0.000029
Once the	0.200000
, medial	0.000561
better data	0.111111
freely available	1.000000
knowledge specific	0.037037
Potentially	0.000029
pilot ,	0.200000
given loss	0.041667
widespread .	1.000000
horoscope machines	1.000000
software that	0.037037
a tonal	0.001227
: Information	0.009804
texts so	0.058824
or transfer-based	0.004505
opened ,	1.000000
scale -LRB-	0.166667
Attribute grammars	1.000000
or nature	0.004505
the probable	0.000692
language require	0.006757
often marked	0.022727
Hard to	0.500000
Test of	1.000000
sampling rate	1.000000
Apparatus for	1.000000
between positive	0.025641
MIT .	0.500000
the EVALITA	0.000692
basics	0.000029
inadequate protection	1.000000
alphabet are	0.333333
Models In	0.333333
specially	0.000029
`` higher	0.005291
as dynamic	0.003484
connected regions	0.200000
who applied	0.100000
typical sentences	0.111111
the unigram	0.000692
an opinion	0.007576
whether -LRB-	0.076923
similar kind	0.037037
between 1964	0.025641
real progress	0.111111
GRM	0.000029
seize the	1.000000
starting to	1.000000
techniques used	0.043478
elaborate	0.000029
of parameters	0.000891
identification pattern	0.200000
addition might	0.166667
advantages	0.000029
Dyer developed	1.000000
queries to	0.333333
replace	0.000029
their features\/aspects	0.029412
could usefully	0.062500
, punctuation	0.000561
; we	0.021277
framework based	0.250000
that access	0.003546
false positives	0.500000
Inc. and	0.500000
NLG applications	0.047619
combining decisions	0.250000
<s> Before	0.000769
any sentences	0.032258
to correlate	0.001328
LMF	0.000029
help determine	0.111111
currency	0.000029
the fly	0.000692
, sometimes	0.000561
sentiment is	0.040000
cryptanalyst at	1.000000
ones already	0.100000
mid-90s	0.000029
the relationships	0.000692
include straightforward	0.037037
English or	0.027027
-LRB- Speereo	0.002710
English of	0.027027
orally	0.000029
objectives :	0.500000
English on	0.027027
wave in	0.111111
of tasks	0.000891
was quite	0.012987
-LRB- HMT	0.002710
Machines Research	1.000000
subjects with	1.000000
MySpace -RRB-	1.000000
experiment -LRB-	0.200000
to merge	0.001328
entire banking	0.333333
e.g. ``	0.017857
proper declaration	0.142857
is focused	0.002033
next token	0.142857
light on	0.333333
lexical segmentation	0.076923
definitional	0.000029
Recognizing	0.000029
substantially	0.000029
running English	0.333333
scaling system	1.000000
Home automation	1.000000
suffer .	1.000000
Peter Turney	1.000000
measured in	0.166667
LDA-based projection	1.000000
the dialog	0.000692
enormous	0.000029
Chafe ,	1.000000
`` Customized	0.005291
from advertisements	0.009615
superimpose one	1.000000
Closed-domain question	1.000000
caught	0.000029
comparison ,	0.333333
Due	0.000029
combines the	1.000000
triggered other	1.000000
Nations and	0.500000
levels but	0.045455
hypothetical	0.000029
different people	0.020408
more complicated	0.010526
the talk	0.000692
and performance	0.001445
Intra-texual methods	1.000000
to re-encode	0.001328
the holder	0.000692
it quite	0.008547
those two	0.045455
tree	0.000029
`` beyond	0.005291
chosen domain	0.200000
GRASSHOPPER for	0.333333
readily conveyed	0.333333
hypothetical ,	1.000000
state transducers	0.071429
of campaigns	0.000891
virtually impossible	0.500000
anything ,	1.000000
process correctly	0.027778
first-order	0.000029
appropriate action	0.250000
ANR-Passage	0.000029
the polarity	0.000692
visit .	0.500000
Jones	0.000029
du discors	1.000000
without documents	0.076923
's promise	0.019608
campaigns were	0.500000
gracefully with	1.000000
testing the	0.200000
and combining	0.001445
incorporate	0.000029
descriptive rather	0.333333
but these	0.014706
examples Performance	0.041667
participate	0.000029
explicitly delimited	0.250000
`` speech	0.005291
constructs can	0.333333
lessons	0.000029
samples per	0.500000
by expanding	0.005714
Running PageRank\/TextRank	1.000000
particular dataset	0.076923
by A.	0.005714
commands issued	0.200000
meant and	0.500000
Henry Kucera	0.500000
are exploited	0.004149
physician ,	1.000000
even several	0.037037
experimenting .	1.000000
not aid	0.008929
OCR Accuracy	0.020408
translating texts	0.250000
transcriptions is	0.500000
training in	0.035714
similarity score	0.100000
large set	0.043478
text normally	0.006289
software often	0.037037
Battle Management	0.500000
spite of	1.000000
probably the	0.250000
semantic constraints	0.047619
held each	1.000000
the tasks	0.000692
un-supervised ''	1.000000
adverb	0.000029
one must	0.015385
indirect left-recursion	1.000000
this work	0.010989
` local	0.062500
approximation .	0.166667
generate high-quality	0.055556
references .	0.250000
table that	0.142857
texts seems	0.058824
lengths -RRB-	1.000000
running publication	0.333333
so-called delta	0.333333
number 20	0.023256
HMMs underlie	0.125000
NLP using	0.021277
Harrison	0.000029
several sub-problems	0.045455
hear sound	0.500000
and does	0.001445
and above	0.001445
what new	0.031250
computationally ;	0.500000
Video games	1.000000
a printed	0.001227
out that	0.071429
used include	0.008850
maintains that	1.000000
simulates	0.000029
<s> Therein	0.000769
of trying	0.000891
world currently	0.066667
controversial .	1.000000
historically used	0.500000
`` Conversational	0.005291
the frequency	0.000692
selecting duplicate	0.200000
that ,	0.003546
and space	0.001445
produces usable	0.250000
dependence vs.	1.000000
year or	0.166667
teletype typewritten	1.000000
<s> Perhaps	0.000769
used being	0.008850
connected Web	0.200000
in Star	0.001873
text conversion	0.006289
make better	0.050000
determine whether	0.043478
percentage of	1.000000
collection .	0.200000
`` semi-supervised	0.005291
as machine	0.003484
Evaluation of	0.111111
instead for	0.142857
decade to	0.333333
to involved	0.001328
rate .	0.090909
in translating	0.001873
of grammatical	0.000891
input six	0.024390
The vectors	0.005208
fine degrees	0.500000
speech a	0.006579
somewhat shallow	0.500000
multiple subtasks	0.076923
accuracy because	0.032258
entrants	0.000029
by grid	0.005714
approximates that	0.500000
to consistently	0.001328
-LRB- allowing	0.002710
raised	0.000029
speaker-dependent	0.000029
segment to	0.111111
Few	0.000029
kind ,	0.090909
, computational	0.000561
OS .	0.500000
F-score	0.000029
-LRB- counselling	0.002710
typical real-world	0.111111
-RRB- Current	0.002817
, flexibility	0.000561
article accuracy	0.034483
non-trivial techniques	0.500000
many years	0.019231
Latin alphabet	0.250000
<verb>	0.000029
not able	0.008929
currently using	0.142857
can form	0.005525
automating abstractive	1.000000
characters using	0.062500
lexicon with	0.111111
formed by	0.200000
`` pseudo-pilot	0.005291
multiscript texts	1.000000
Digitized	0.000029
relay	0.000029
most authoritative	0.017241
the lexical	0.000692
Flickinger D.	1.000000
`` Intelligent	0.005291
's input	0.019608
text by	0.006289
analyzing it	0.200000
appropriate perspective	0.250000
Charles	0.000029
because while	0.033333
2006 ,	0.333333
<s> Trained	0.000769
and rich	0.001445
human in	0.021739
8000 samples	1.000000
Realtime	0.000029
communication radios	0.200000
John Heritage	0.125000
sufficient include	0.200000
LexisNexis was	1.000000
DA began	0.333333
extrinsic -RRB-	0.166667
various constructions	0.055556
Stef Slembrouck	1.000000
the naval	0.000692
meaningful portions	0.125000
vertices should	0.111111
Gender =	1.000000
or shifted	0.004505
treat them	0.500000
a tag	0.001227
recognizing and	0.200000
Recognize	0.000029
empirical solutions	1.000000
Stubbs ,	1.000000
, English-like	0.000561
IR relies	0.333333
being used	0.055556
except some	1.000000
are extractive	0.004149
with edit	0.005464
Francis	0.000029
textbook of	0.500000
a huge	0.001227
1970 -RRB-	0.333333
is unclear	0.002033
consistently achieve	0.333333
case ''	0.058824
, relatively	0.000561
reliably --	1.000000
example shows	0.012346
than 150	0.022222
languages semantics	0.020000
and here	0.001445
LexRank simply	0.083333
voices	0.000029
, pronunciation	0.000561
<s> svg	0.000769
semantic schemes	0.047619
, during	0.000561
organization ,	0.200000
have direct	0.009615
-RRB- This	0.002817
understanding approximates	0.030303
help in	0.111111
other purposes	0.014286
`` My	0.005291
sublanguage of	0.333333
costly training	1.000000
language other	0.006757
this product	0.010989
including probabilistic	0.071429
unveiled	0.000029
Canada ?	0.166667
Lexical choice	0.500000
Tagging Guidelines	1.000000
with collecting	0.005464
optimize some	1.000000
to construct	0.001328
optimal	0.000029
: whereas	0.009804
He decided	0.125000
linguist working	0.500000
tagging techniques	0.040000
Development Activity	1.000000
corpora ''	0.090909
Xuedong	0.000029
improving	0.000029
Peru ,	0.500000
biographical	0.000029
critical or	0.250000
opinionated	0.000029
<s> Components	0.000769
broken in	0.200000
extraction task	0.032258
reasoning to	0.142857
constructions occur	1.000000
includes transfer-based	0.142857
issues Disambiguation	0.200000
popular in	0.111111
a valid	0.001227
about this	0.025000
and final	0.001445
an associated	0.007576
rate crossed	0.090909
as smart	0.003484
thereby	0.000029
not determine	0.008929
consonants ,	0.333333
SHRDLU for	0.166667
actually playing	0.333333
and consonants	0.001445
as phoneme	0.003484
validated and	1.000000
two waves	0.034483
way they	0.041667
gaming	0.000029
The sub-committee	0.005208
dividing a	0.333333
about social	0.025000
rewrite it	1.000000
review of	0.333333
classifying the	0.200000
investigation	0.000029
likely a	0.062500
, you	0.000561
means the	0.166667
numbers represent	0.142857
Head-driven phrase	1.000000
the requirements	0.000692
is red	0.002033
accompanying HTK	1.000000
the factors	0.000692
right ''	0.100000
Brazil	0.000029
released ``	0.500000
a form	0.001227
development has	0.083333
city	0.000029
efficient however	0.333333
have error	0.009615
He taught	0.125000
following manner	0.066667
create edges	0.058824
, conjunction	0.000561
whole phrases	0.111111
shifting to	1.000000
look to	0.200000
Parliament of	0.500000
<s> Progress	0.000769
subfields	0.000029
usually a	0.031250
factors affect	0.333333
the Apollo	0.000692
would recognize	0.018868
instructed	0.000029
spoken -RRB-	0.071429
as artificial	0.003484
question marks	0.023810
in fact	0.001873
questioner might	0.250000
roughly proportional	0.333333
distorted by	0.500000
itself to	0.200000
l'assignation des	1.000000
Topic segmentation	1.000000
the CCD	0.000692
successfully adapted	0.333333
be needed	0.004219
Conferences in	0.500000
dynamic background	0.200000
laws	0.000029
Genres	0.000029
shallowest ,	1.000000
, stutering	0.000561
examples for	0.041667
memory of	0.500000
these techniques	0.023810
bought the	1.000000
of linguistics	0.000891
semi -	1.000000
ASR ''	0.166667
, articulation	0.000561
assistant	0.000029
linear-time versions	1.000000
discourse structure	0.027778
Paul W.	0.200000
approximately 200	0.500000
from naive	0.009615
by simple	0.005714
a unified	0.001227
are variously	0.004149
labor intensive	0.500000
software tools	0.037037
ostensibly	0.000029
complex NLG	0.041667
intelligence technologies	0.125000
Symbian	0.000029
processing The	0.018519
expression which	0.100000
screen	0.000029
about basic	0.025000
understand ''	0.142857
Whether NLP	0.500000
last night	0.200000
The Duchess	0.005208
left-recursion	0.000029
<s> LexisNexis	0.000769
On-line systems	0.333333
FST	0.000029
, Nuance	0.000561
allow blind	0.200000
storing ,	1.000000
suitable department	0.250000
damping	0.000029
as latent	0.003484
to right	0.001328
+4 -RRB-	1.000000
relationship between	0.166667
Turney with	0.111111
E. ,	0.250000
thus avoiding	0.100000
parsing systems	0.035714
measure summary	0.090909
psychotherapy	0.000029
Adda G.	0.500000
methods and	0.022727
Several research	0.333333
morphemes .	0.333333
<s> Unfortunately	0.000769
used speech	0.008850
and Web	0.001445
boundary '	0.166667
applications such	0.040000
sales data	0.333333
problems for	0.058824
of to	0.000891
wrote that	0.166667
a short-time	0.001227
without confusions	0.076923
relevant text	0.142857
The technology	0.005208
methods achieved	0.022727
new cross-discipline	0.041667
convey intended	0.333333
Harris et	0.111111
, volume	0.000561
Page\/Lex\/TextRank	0.000029
format .	0.500000
reviews to	0.166667
different related	0.020408
corporation does	1.000000
and searching	0.001445
compensate for	1.000000
data-to-text systems	1.000000
efficiently .	1.000000
interested in	1.000000
were written	0.024390
, installed	0.000561
includes both	0.142857
mechanism for	1.000000
`` mentions	0.005291
name -LRB-	0.200000
avoiding some	0.500000
to machine-learning	0.001328
the interim	0.000692
sub-sounds	0.000029
all view	0.023256
founder of	1.000000
large ;	0.043478
reference that	0.125000
Penicillin ''	1.000000
summary used	0.023810
and achieves	0.001445
consistently use	0.333333
that removing	0.003546
decorrelating	0.000029
text-understanding system	1.000000
- NC	0.062500
unsupervised approach	0.125000
set to	0.025641
experience is	0.500000
action should	0.200000
is easily	0.002033
parsers can	0.076923
common ones	0.040000
the important	0.000692
will seem	0.028571
Dijk ,	1.000000
a five-star	0.001227
George Lakoff	1.000000
can get	0.005525
`` Army	0.005291
analysis is	0.015385
the textual	0.000692
it formed	0.008547
often involve	0.022727
map to	0.500000
provide additional	0.166667
Anaphor resolution	1.000000
an equivalent	0.007576
desktop OCR	1.000000
, unless	0.000561
raised in	1.000000
first agree	0.030303
% in	0.025641
away unlikely	0.500000
is typical	0.002033
reasons .	0.500000
Front-End	0.000029
theory Functional	0.076923
of years	0.000891
Computing Machinery	0.500000
, communication	0.000561
, Eurospeech\/ICSLP	0.000561
recursive productions	1.000000
other related	0.014286
<s> Digitized	0.000769
been attained	0.014706
disambiguate the	0.333333
automatic machine	0.043478
-LRB- rather	0.002710
do predict	0.038462
Direct	0.000029
examples can	0.041667
Gene Ontology	1.000000
, Oklahoma	0.000561
extent -RRB-	0.250000
computer-aided translation	0.333333
epidemic which	1.000000
nodes in	0.142857
a fancy	0.001227
usually has	0.031250
to assess	0.001328
' stability	0.052632
it helps	0.008547
summarization have	0.020000
between IR	0.025641
handwritten ,	0.500000
to serve	0.001328
to two	0.001328
in computer-aided	0.001873
CSR have	0.333333
been produced	0.014706
account context	0.333333
scientists	0.000029
Rhetoric	0.000029
a model	0.001227
influence in	1.000000
al. 1989	1.000000
at processing	0.014706
PageRank\/TextRank	0.000029
article quoting	0.034483
and required	0.001445
Information retrieval	0.200000
him or	0.500000
compiler or	0.333333
Agency -LRB-	0.500000
many examples	0.019231
; This	0.021277
meaning -LRB-	0.043478
is adaptive	0.002033
example Mr.	0.012346
reads it	0.500000
orally speaking	1.000000
to robots	0.001328
using photocells	0.016949
pauses in	0.250000
reporter -LRB-	1.000000
: Word	0.009804
qualitative manner	0.500000
<s> ROUGE-1	0.000769
technology are	0.045455
tasks that	0.031250
Nelson Francis	1.000000
final letter	0.111111
glossary words	0.500000
It had	0.026316
register	0.000029
topics .	0.142857
format called	0.500000
grammar because	0.027027
distortion	0.000029
another verb	0.076923
partly statistical	1.000000
of comprehensive	0.000891
method can	0.062500
of glass-box	0.000891
reranking	0.000029
Wetherell ,	1.000000
computed with	0.500000
user interface	0.071429
reported -LRB-	0.200000
of scanned	0.000891
Grammar	0.000029
Mobile devices	0.333333
1980s the	0.111111
2006 hurricane	0.333333
summarization It	0.020000
, T	0.000561
Graesser	0.000029
as length	0.003484
extraction removes	0.032258
letters blend	0.100000
, Deirdre	0.000561
of scholars	0.000891
Progress mainly	1.000000
Rose	0.000029
main verb	0.125000
reduce	0.000029
Rosa	0.000029
, EMNLP	0.000561
Reading ''	0.500000
degraded-images ,	1.000000
To address	0.111111
University 's	0.111111
itself while	0.200000
Defense	0.000029
In corpus	0.009524
were walking	0.024390
and curves	0.001445
same type	0.040000
POST	0.000029
to locate	0.001328
Halliday	0.000029
Behind this	1.000000
distances for	0.500000
's instructions	0.019608
recursively .	0.500000
<s> might	0.000769
is precision	0.002033
wingmen with	1.000000
jet	0.000029
introduction	0.000029
, Edmund	0.000561
Lemke ,	1.000000
long research	0.500000
elaboration	0.000029
application has	0.071429
nodes to	0.142857
readable human	0.333333
as gold	0.003484
algorithm optimizes	0.035714
not sufficient	0.008929
producing natural	0.333333
beforehand	0.000029
: Emergent	0.009804
MEAD -RRB-	1.000000
generalizes	0.000029
reliance	0.000029
generalized	0.000029
of Chomskyan	0.000891
horizontal mark	1.000000
, too	0.000561
only automate	0.026316
machine-aided human	1.000000
of diagonal	0.000891
rare or	0.250000
Cloud	0.000029
went on	0.200000
coarticulation ,	1.000000
restaurant ,	0.500000
author of	0.333333
uses continuous	0.071429
Chantal	0.000029
writer	0.000029
despite being	0.333333
its history	0.028571
fragments that	1.000000
and business	0.001445
Thai and	0.500000
systems favor	0.008929
methods can	0.022727
vs. Spontaneous	0.083333
the Information	0.000692
groups within	0.200000
calculates n-gram	1.000000
banking	0.000029
most can	0.017241
social interaction	0.071429
and speaker	0.001445
using edges	0.016949
beyond which	0.166667
the built	0.000692
medium levels	0.333333
multiple source	0.076923
permuted	0.000029
an expression	0.007576
OCR-A	0.000029
, Paroubek	0.000561
several ambiguous	0.045455
the largest	0.000692
war camp	1.000000
typical sentence	0.111111
the interactions	0.000692
-LRB- 3rd	0.002710
the chosen	0.000692
linguistics concerned	0.050000
Stilstudien	0.000029
potential parses	0.142857
computer input	0.022727
Tags	0.000029
Mariani	0.000029
system by	0.010753
that adjectives	0.003546
Effective natural	1.000000
but BLEU	0.014706
obstacles to	1.000000
The nodes	0.005208
representative	0.000029
1989 ?	0.500000
isolation of	0.500000
out -LRB-	0.071429
while an	0.050000
of classifying	0.000891
grouped into	0.500000
reliably	0.000029
and human-generated	0.001445
provided a	0.200000
read characters	0.142857
parsing In	0.035714
the ARCHILES	0.000692
capture speech	0.500000
Since OCR	0.200000
general principles	0.045455
-RRB- NASA	0.002817
provides additional	0.500000
Anaphor	0.000029
action .	0.200000
Army Avionics	0.250000
used that	0.008850
, their	0.000561
Labov	0.000029
editing the	0.500000
conclusions	0.000029
first order	0.030303
compared German	0.142857
the sample	0.000692
and search	0.001445
the metrics	0.000692
controllers .	0.333333
only want	0.026316
went past	0.200000
sorting	0.000029
human speech	0.021739
reasoning .	0.142857
various NLP	0.055556
which we	0.007246
language can	0.006757
hand coding	0.071429
kick '	1.000000
genres of	1.000000
plus some	1.000000
` caught	0.062500
7 %	0.142857
phonetic-based	0.000029
facemask ,	1.000000
Santorini	0.000029
or keep	0.004505
<s> Despite	0.000769
, web	0.000561
digitized	0.000029
, Words	0.000561
very optimistic	0.024390
broadcast news	1.000000
question types	0.023810
UPV	0.000029
relating	0.000029
` summary	0.062500
automated online	0.142857
strategies to	0.500000
unlike brain	1.000000
the technique	0.000692
NER	0.000029
Perspectives The	1.000000
annotation and	0.250000
most linguists	0.017241
other than	0.014286
alignment method	0.500000
infinitive	0.000029
model all	0.033333
the entire	0.000692
are fields	0.004149
um	0.000029
-LRB- normalized	0.002710
uh	0.000029
quotations ,	1.000000
storing	0.000029
automated ,	0.142857
by context-free	0.005714
University included	0.111111
visible under	0.333333
'' the	0.005376
the coherence	0.000692
both be	0.032258
times throughout	0.200000
holes	0.000029
equivalent set	0.200000
to blind	0.001328
the segment	0.000692
grammatical parts	0.090909
most positive	0.017241
inference --	0.250000
complex images	0.041667
Progress	0.000029
on sentences	0.004717
, leads	0.000561
built a	0.333333
those running	0.045455
exigencies of	1.000000
machine-encoded	0.000029
handover system	1.000000
to backup	0.001328
prove impossible	1.000000
an objective	0.007576
matching and	0.200000
texts written	0.058824
recall-based measure	0.500000
Schroeder ,	1.000000
functional grammar	0.500000
commercial .	0.090909
Words and	0.250000
summary tackles	0.023810
nuances and	1.000000
nuggets of	1.000000
licensed	0.000029
NLP An	0.021277
of science	0.000891
HTML	0.000029
were performed	0.024390
Prior	0.000029
explicit models	0.200000
-- i.e.	0.040000
F.	0.000029
a long-time	0.001227
can exploit	0.005525
retrieved .	1.000000
effect the	0.500000
Leading	0.000029
judge ,	0.250000
which many	0.007246
small text	0.111111
different possible	0.020408
promoting diversity	1.000000
, shop	0.000561
Engineers ''	0.500000
e.g. elaboration	0.017857
a sense	0.001227
background knowledge	0.333333
category registry	0.500000
for understanding	0.003610
campaign compared	0.200000
sound creates	0.050000
for approximating	0.003610
Regardless	0.000029
challenge	0.000029
publications	0.000029
perspective so	0.250000
's results	0.019608
compared a	0.142857
translation methodologies	0.013514
entropy-based summarization	1.000000
Stilstudien -LRB-	1.000000
noun ''	0.071429
distinction ,	0.200000
the bridging	0.000692
compared -	0.142857
a reliance	0.001227
entities -LRB-	0.142857
custom speech	0.500000
systems typically	0.008929
using natural	0.016949
that perform	0.003546
counter	0.000029
a camera	0.001227
element	0.000029
color images	1.000000
Semantic Orientation	0.333333
to deal	0.001328
, Hafiz	0.000561
move	0.000029
`` Japanese	0.005291
would identify	0.018868
their routing	0.029412
Recall can	0.333333
even larger	0.037037
continue to	1.000000
The phenomenon	0.005208
2012	0.000029
by receivers	0.005714
tune the	1.000000
both use	0.032258
games ,	1.000000
continued more	0.111111
Noise	0.000029
Early versions	0.500000
questions or	0.038462
the dictator	0.000692
approaches emphasize	0.035714
this right	0.010989
word processing	0.016667
adjectives ,	0.333333
often under	0.022727
highly-specialized natural	1.000000
to How	0.001328
and recognition	0.001445
bills returned	1.000000
concepts between	0.200000
for personal	0.003610
HLDA -RRB-	1.000000
like syntax	0.035714
If ``	0.100000
Summarizers -LRB-	1.000000
speakers were	0.250000
have already	0.009615
rules ATNs	0.023256
and mapping	0.001445
vocabulary sizes	0.125000
as conveniently	0.003484
Labov ,	1.000000
speech designed	0.006579
in medical	0.001873
linear combination	0.142857
-RRB- Interactional	0.002817
issued to	1.000000
To upgrade	0.111111
a rapidly	0.001227
linear algebra	0.142857
scanning applications	0.500000
<s> You	0.000769
Scansoft	0.000029
Understanding Conferences	0.500000
collecting	0.000029
tokens -LRB-	0.142857
manner rather	0.250000
would consist	0.018868
grammar-based	0.000029
applications Robotics	0.040000
the acoustic	0.000692
abbreviations that	0.200000
book on	0.125000
delayed	0.000029
is speaking	0.002033
It stands	0.026316
target-language-independent representation	1.000000
, Type	0.000561
published at	0.142857
mechanical	0.000029
grammars that	0.071429
dataset -RRB-	1.000000
President Biden	0.250000
semantic interpretation	0.047619
and placement	0.001445
similarity of	0.100000
predicted pollen	0.500000
representations are	0.250000
, improving	0.000561
same words	0.040000
scanned images	0.333333
the hypothesis	0.000692
which structured	0.007246
as Maximal	0.003484
emotional effect	0.250000
pointed out	1.000000
the eigenvector	0.000692
speech caused	0.006579
weapon release	0.500000
Spitzer	0.000029
not rare	0.008929
using all	0.016949
parse computationally	0.111111
project ongoing	0.076923
Jay Lemke	1.000000
The final	0.005208
better translations	0.111111
expect ;	0.333333
extremes ,	1.000000
Vauquois	0.000029
in USA	0.001873
and print	0.001445
, Klavans	0.000561
Note also	0.111111
'' aimed	0.005376
million word	0.333333
launched the	1.000000
individual unigrams	0.083333
denote an	0.500000
step is	0.066667
everyday life	1.000000
Intelligent ''	0.333333
retrieval module	0.142857
more like	0.010526
: task-based	0.009804
JAS-39	0.000029
by decomposing	0.005714
summarization exactly	0.020000
parser are	0.062500
still used	0.066667
Text Segmentation	0.166667
other applications	0.014286
<s> ...	0.000769
similar ``	0.037037
recognizers into	0.500000
keyword matching	1.000000
theory it	0.076923
theory in	0.076923
<s> Formal	0.000769
the CKY	0.000692
scale -RRB-	0.166667
generate some	0.055556
When used	0.142857
Wordnet lexicon	1.000000
A possible	0.020000
Typical stages	0.500000
displayed on-line	0.500000
Research and	0.125000
from its	0.009615
letter that	0.166667
Carmen	0.000029
the speech-enabled	0.000692
sentiment based	0.040000
images environment	0.166667
A. van	0.200000
rooms	0.000029
Dictionary-based Main	0.500000
Rabiner can	1.000000
produce ,	0.045455
Content determination	1.000000
Hollenbach 1970	1.000000
corpus to	0.032258
Rose ,	1.000000
checking	0.000029
could do	0.062500
conjunction ,	0.333333
and stochastic	0.001445
Extraction Algorithm	0.333333
learned model	0.200000
summarization approaches	0.020000
as words	0.003484
to consult	0.001328
Eugene	0.000029
summaries qualitatively	0.023256
grammatical gender	0.090909
as voicemail	0.003484
English :	0.027027
segment and	0.111111
'' occurs	0.005376
production and	0.333333
Because progress	0.500000
is relevant	0.002033
also that	0.014493
information databases	0.021739
Ray Kurzweil	1.000000
for verification	0.003610
became an	0.200000
reporting on	0.333333
Martin presents	0.500000
has interest	0.011905
do all	0.038462
objective evaluation	0.200000
-LRB- arguably	0.002710
inter-annotator	0.000029
has improved	0.011905
signed language	1.000000
notable early	1.000000
Search to	0.500000
the vocabulary	0.000692
and copying	0.001445
Unsupervised taggers	0.166667
agree on	0.333333
the letters	0.000692
contribute	0.000029
<s> human	0.000769
converting the	0.500000
be checked	0.004219
ink	0.000029
as often	0.003484
biographical questions	1.000000
lookup	0.000029
schemes frequently	0.500000
are summaries	0.004149
specific objects	0.047619
To find	0.111111
spaces or	0.200000
lessons learned	1.000000
spaces of	0.200000
with Nuance	0.005464
voice applications	0.076923
humans to	0.083333
simply by	0.083333
most significant	0.017241
produce numeric	0.045455
controversial	0.000029
is accomplished	0.002033
controllers Training	0.333333
evaluation programs	0.018519
various boolean	0.055556
use heteroscedastic	0.013889
which usually	0.007246
Morpheme Analysis	1.000000
especially useful	0.066667
<s> Ensemble	0.000769
of faster	0.000891
by silence	0.005714
been automatic	0.014706
source and	0.041667
Claude	0.000029
floods ''	1.000000
Most of	0.500000
threshold to	0.250000
B ,	1.000000
thus reducing	0.100000
the DUC	0.000692
well a	0.035714
continuous similarity	0.166667
memorandum ``	1.000000
accepts some	0.500000
alone --	0.250000
advantage that	0.200000
components -RRB-	0.200000
of integration	0.000891
, modern	0.000561
Machinery	0.000029
did Joe	0.200000
whether ``	0.076923
well ,	0.035714
eyes-busy environment	1.000000
and Roger	0.001445
browsing	0.000029
Penicillin	0.000029
at an	0.014706
disappear .	1.000000
tagger proceeds	0.111111
with reference	0.005464
recognition As	0.008264
is commercially	0.002033
taggers The	0.142857
that handles	0.003546
foster	0.000029
, addressed	0.000561
and early	0.001445
Australia .	1.000000
the preceding	0.000692
generate weather	0.055556
feasibility demonstration	0.500000
and derive	0.001445
European group	0.333333
<s> Psycholinguists	0.000769
HMM parameter	0.333333
Brill tagger	0.333333
validated	0.000029
explicit by	0.200000
verify	0.000029
coined the	1.000000
BASEBALL answered	0.500000
when necessary	0.028571
beach	0.000029
coined	0.000029
of researchers	0.000891
services ,	0.333333
or match	0.004505
processed ,	0.166667
transform -RRB-	0.200000
accommodate left	0.200000
Koine Greek	1.000000
Judith M.	1.000000
quality can	0.100000
differences in	0.333333
clues are	0.333333
at Stanford	0.014706
diverse set	0.500000
recognition-related project	1.000000
key theorists	0.166667
nets	0.000029
adjacent instances	0.166667
versus	0.000029
of product	0.000891
pertaining to	1.000000
generators of	0.500000
ambiguous English	0.083333
, Strzalkowski	0.000561
patent for	0.250000
likely source	0.062500
standard can	0.071429
bank	0.000029
rocks	0.000029
Adriana Bolivar	1.000000
using online	0.016949
to school-age	0.001328
Cuzco area	1.000000
in healthcare	0.001873
of life	0.000891
coefficients and	0.250000
+ R	0.166667
so phonemes	0.033333
but has	0.014706
medicine	0.000029
lies a	0.500000
to rewrite	0.001328
Deaf or	1.000000
where semantics	0.028571
sentences when	0.013158
Chomskyan theories	1.000000
, PangeaMT	0.000561
difference is	0.250000
the choices	0.000692
BORIS	0.000029
boundaries in	0.090909
builds a	0.500000
+5	0.000029
+4	0.000029
of aircraft	0.000891
between `	0.025641
a purely	0.001227
and discuss	0.001445
reduction ,	0.500000
trained automatically	0.333333
is positive	0.002033
template-matching OCR	1.000000
into machine-encoded	0.012821
generalizes as	1.000000
limited type	0.100000
perception of	0.500000
trivial due	0.250000
van Leeuwen	0.500000
on bilingual	0.004717
document gives	0.027778
trees using	0.166667
and parsing	0.001445
sold his	0.333333
Gene	0.000029
possibilities but	0.200000
Text-proofing Natural	1.000000
many others	0.019231
embedded system	0.250000
reverse -RRB-	0.500000
now absorbing	0.076923
normalization and	0.166667
of our	0.000891
phenomenon is	0.200000
the machine	0.000692
a criterion	0.001227
realm	0.000029
Vietnamese ,	1.000000
latter	0.000029
reported was	0.200000
easily copied	0.111111
corresponded to	1.000000
or knowledge	0.004505
Computers	0.000029
wave from	0.111111
exercises	0.000029
and previously-written	0.001445
Haton -LRB-	1.000000
six numbers	0.500000
more -RRB-	0.010526
, intelligent	0.000561
use directly	0.013889
calculates	0.000029
shallow approaches	0.166667
most fonts	0.017241
tagging will	0.040000
about as	0.025000
HMM based	0.333333
However even	0.027027
representations of	0.250000
positions as	1.000000
Dec.	0.000029
are clearly	0.004149
which items	0.007246
properties and	0.250000
is some	0.002033
others have	0.083333
polynomial-size	0.000029
in evaluation	0.001873
`` eat	0.005291
two ways	0.034483
writing style	0.111111
many are	0.019231
carried on	0.500000
C. ,	1.000000
deep systems	0.142857
a knowledge	0.001227
by part	0.005714
of navigation	0.000891
equivalent to	0.200000
slow and	0.500000
person may	0.052632
draft is	0.500000
already discussed	0.200000
Chinese have	0.142857
ARRA -RRB-	1.000000
simple English	0.038462
to automated	0.001328
vs. preposition	0.083333
words as	0.009174
strong correlation	0.250000
journal article	0.333333
Unfortunately ,	1.000000
dialogues	0.000029
are further	0.004149
been opinionated	0.014706
the JAS-39	0.000692
of guessing	0.000891
Mouffe ,	1.000000
uttered ;	0.333333
Patent 2,026,329	0.333333
Harris The	0.111111
1993 .	0.333333
researchers need	0.100000
trigrams ,	0.500000
classes :	0.200000
Often used	0.333333
as :	0.003484
an NLG	0.007576
keyphrases and	0.028571
corpus such	0.032258
publicly	0.000029
-LRB- orange	0.002710
forecasts .	0.200000
Invoice	0.000029
a preposition	0.001227
launched	0.000029
produce keyphrases	0.045455
gap between	1.000000
Virtually	0.000029
a person\/persons	0.001227
analysis depends	0.015385
readers processed	0.500000
are pulled	0.004149
and for	0.001445
incorrectly	0.000029
of personalised	0.000891
statistical distribution	0.030303
form the	0.050000
methods based	0.022727
Institute	0.000029
in spite	0.001873
e.g. who	0.017857
the course	0.000692
closely associate	0.200000
model information	0.033333
the exception	0.000692
measure for	0.090909
were based	0.024390
unified	0.000029
intervals like	1.000000
Science Research	0.500000
closed-domain might	1.000000
Recognize if	1.000000
constraint ,	1.000000
for test	0.003610
things .	0.333333
for translation	0.003610
overall speech	0.166667
results over	0.047619
belongs	0.000029
new scientific	0.041667
progressed	0.000029
the phrases	0.000692
recent book	0.125000
distinct ideas	0.142857
clear .	0.250000
of analysis	0.000891
parametric values	1.000000
three basic	0.333333
Cohesion and	1.000000
me the	1.000000
news-gathering ,	1.000000
entities often	0.142857
web may	0.125000
Task description	0.333333
allows a	0.125000
WebOCR also	0.250000
worked out	0.200000
1946 by	1.000000
ambiguity of	0.125000
and algorithms	0.001445
summarization faces	0.020000
or left-to-right	0.004505
post	0.000029
-LRB- correct	0.002710
essentially two	0.125000
reported accuracy	0.200000
local '	0.333333
graph -RRB-	0.076923
: Many	0.009804
the values	0.000692
stemming -RRB-	0.500000
are surprisingly	0.004149
Hard of	0.500000
associating a	1.000000
equivalent information	0.200000
be declared	0.004219
or five	0.004505
was influenced	0.012987
class they	0.250000
not its	0.008929
war	0.000029
something	0.000029
becoming	0.000029
converse	0.000029
Customized	0.000029
meaning ``	0.043478
high-quality	0.000029
between dynamically	0.025641
inferior results	1.000000
the opinions	0.000692
on-line ,	0.333333
projection followed	1.000000
Edmund Fournier	1.000000
`` good	0.005291
Multimodal interaction	1.000000
Margaret Wetherell	1.000000
labeled data	0.333333
extensive lexicons	0.333333
Jonathan Potter	1.000000
network -LRB-	0.166667
standard table	0.071429
with Fourier	0.005464
Winograd finished	0.333333
usually involves	0.031250
common to	0.040000
that making	0.003546
tried .	0.333333
tried ,	0.333333
trivial -RRB-	0.250000
VRX and	1.000000
Sept.	0.000029
contains all	0.100000
Importance	0.000029
for specific	0.003610
an embedded	0.007576
compensate	0.000029
by any	0.005714
rarely have	0.333333
individual phones	0.083333
'' set	0.005376
smoothly with	0.500000
Just	0.000029
were published	0.024390
<s> Application-Oriented	0.000769
paraphrases -LRB-	1.000000
Duchess	0.000029
generated texts	0.066667
phrases with	0.062500
possible on	0.041667
: setting	0.009804
when reading	0.028571
in system	0.001873
indiscriminate .	1.000000
task remains	0.023810
: statistical	0.009804
simplified form	0.500000
machine-learning systems	0.250000
terms that	0.076923
multimedia documents	0.500000
based recognition	0.018519
sequential	0.000029
D.S.	0.000029
Imagine	0.000029
<s> Prominent	0.000769
especially interested	0.066667
account how	0.333333
great deal	0.333333
been written	0.014706
application to	0.071429
Morphological segmentation	1.000000
apparent from	1.000000
prove	0.000029
, along	0.000561
least one	0.200000
produce consonants	0.045455
measure one	0.090909
became part	0.200000
first ,	0.030303
entity about	0.200000
first .	0.030303
case that	0.058824
F	0.000029
automated technologies	0.142857
electronic conversion	0.500000
Automated essay	0.500000
organizations	0.000029
graphic	0.000029
extraction or	0.032258
, MySpace	0.000561
in part	0.001873
, understanding	0.000561
War II	1.000000
Rosa Caldas-Coulthard	1.000000
heard	0.000029
thanks to	1.000000
to converse	0.001328
sounds it	0.066667
uses cosine	0.071429
Gail	0.000029
construct an	0.333333
dominance	0.000029
understanding involves	0.030303
normalization -LRB-	0.166667
Black E.	0.500000
representations .	0.250000
Widdowson	0.000029
Wodak ,	1.000000
Langues	0.000029
, Digital	0.000561
Grammatical dependency	1.000000
-RRB- at	0.002817
from ,	0.009615
usually be	0.031250
and VOLSUNGA	0.001445
the Advanced	0.000692
-RRB- an	0.002817
accordingly .	1.000000
rates on	0.125000
machine-translation approaches	0.500000
different speaker	0.020408
sentences at	0.013158
Willig ,	1.000000
: extraction	0.009804
of DA	0.000891
fields such	0.166667
Although Harris	0.125000
is Shift-Reduce	0.002033
earliest such	0.500000
gives less	0.500000
the industry	0.000692
these good	0.023810
elements from	0.250000
from IBM	0.009615
1957	0.000029
1956	0.000029
1953	0.000029
P +	0.500000
P ,	0.500000
statement ,	1.000000
introducing models	1.000000
full-text	0.000029
analyses to	0.200000
visible Markov	0.333333
house through	0.500000
happen	0.000029
on neat	0.004717
internal semantic	0.200000
advances in	1.000000
suffix ''	1.000000
to HMMs	0.001328
including ,	0.071429
on both	0.004717
the methods	0.000692
inputting	0.000029
throughout a	1.000000
Duchess was	1.000000
important example	0.062500
form filling	0.050000
has thousands	0.011905
way is	0.041667
capitalized .	0.333333
also concluded	0.014493
the mechanism	0.000692
himself translated	0.500000
Speaker Dependence	0.166667
including mobile	0.071429
Human Summarization	0.200000
a damping	0.001227
practical dimensions	0.500000
150 separate	0.500000
Starting in	1.000000
Handbook chapter	1.000000
of meaningful	0.000891
Pointwise	0.000029
Auto plant	1.000000
could understand	0.062500
surprising popularity	1.000000
rank ``	0.166667
require rapid	0.045455
and\/or producing	0.333333
row ,	1.000000
to focus	0.001328
would never	0.018868
Microsoft Voice	0.500000
book Language	0.125000
may dismiss	0.019231
tested the	0.500000
, decimal	0.000561
recognition algorithms	0.008264
fancy statistics	1.000000
of case-based	0.000891
concatenated	0.000029
researchers found	0.100000
convey meaning	0.333333
words involved	0.009174
, Svenka	0.000561
As with	0.055556
such template-matching	0.008130
skew ,	1.000000
, Aletta	0.000561
crossed below	1.000000
of key	0.000891
curves ,	1.000000
on pilot	0.004717
upgrade	0.000029
Inuit	0.000029
many more	0.019231
to contain	0.001328
texts and	0.058824
considerable commercial	0.200000
card imprints	0.250000
-LRB- orally	0.002710
the key	0.000692
between automatically	0.025641
computer-understandable	0.000029
about a	0.025000
Beaugrande ,	1.000000
or fade	0.004505
: complicated	0.009804
Arbor	0.000029
necessarily portable	0.500000
: Manual	0.009804
as individual	0.003484
microphone .	1.000000
evaluation campaign	0.018519
evaluate an	0.250000
languages tend	0.020000
as keyphrases	0.003484
an interactive	0.007576
perceptions	0.000029
pertain	0.000029
, candidacies	0.000561
of using	0.000891
enabling	0.000029
therefore help	0.200000
and achieved	0.001445
were similar	0.024390
into standard	0.012821
<s> Modern	0.000769
and form	0.001445
tagging :	0.040000
essentially perfectly	0.125000
Schools	0.000029
a subtopic	0.001227
some but	0.012048
but instead	0.014706
be trained	0.004219
information and	0.021739
Kenneth Lee	1.000000
e.g. Known	0.017857
listens for	1.000000
as corresponding	0.003484
utterance can	0.333333
above all	0.076923
last example	0.200000
too similar	0.166667
remains the	0.250000
= masculine	0.111111
formalization .	0.500000
Envelopes	0.000029
Speech ''	0.032258
Noun ,	1.000000
standards are	0.200000
keyboard a	0.333333
larger text	0.062500
's dissertation	0.019608
or structures	0.004505
MEAD	0.000029
breaks exist	0.500000
n-dimensional	0.000029
Kurzweil Applied	0.142857
of over	0.000891
template-matching	0.000029
depending what	0.250000
keyboard .	0.333333
terminology ,	1.000000
optimizes parameters	1.000000
or custom	0.004505
inspired the	1.000000
severe	0.000029
<s> Every	0.000769
transmitting	0.000029
A direct	0.020000
of Latin-script	0.000891
give a	0.250000
`` Computational	0.005291
of units	0.000891
; Speech	0.021277
Compute features	1.000000
-RRB- Acoustical	0.002817
, psycholinguistics	0.000561
are useful	0.004149
quoted in	1.000000
favor accuracy	0.500000
complicated because	0.333333
ambitious	0.000029
the inter-word	0.000692
, current	0.000561
large corpus	0.043478
Project	0.000029
unveiled during	1.000000
listening	0.000029
on lower	0.004717
us to	0.500000
have higher	0.009615
Science ,	0.500000
Marc	0.000029
criteria and	0.250000
hand it	0.071429
e.g. Syntactic	0.017857
Military High-performance	1.000000
and linear	0.001445
a feasibility	0.001227
Tokens	0.000029
project -LRB-	0.076923
It refers	0.026316
limited application	0.100000
tool .	0.500000
news conference	0.076923
of assembling	0.000891
use vocal	0.013889
inclusion	0.000029
open problem	0.250000
ambiguities one	0.250000
electronically searched	1.000000
MMI -RRB-	1.000000
Goldberg continued	0.500000
generic summaries	0.333333
also considerable	0.014493
-LRB- greater	0.002710
asking why	0.500000
input feature	0.024390
with payments	0.005464
and Unsupervised	0.001445
<s> Isolated	0.000769
quantitatively	0.000029
by Piron	0.005714
In these	0.009524
that act	0.003546
star ratings	0.500000
History Some	0.500000
keyphrase extractor	0.052632
sound on	0.050000
deploy machine	1.000000
processed incorrectly	0.166667
e.g. WordNet	0.017857
open-ended	0.000029
OnStar ,	1.000000
peak	0.000029
distinguishes two	0.500000
is provided	0.002033
corpus for	0.032258
Loriot	0.000029
1930s	0.000029
the Wordnet	0.000692
boundaries and	0.090909
proper syntax	0.142857
a pre-structured	0.001227
task requires	0.023810
with little	0.005464
When punctuation	0.142857
case with	0.058824
-5	0.000029
any pauses	0.032258
The Unicode	0.005208
; Amplitude	0.021277
even so	0.037037
learner .	0.500000
a psychologist	0.001227
mobile processor	0.500000
typewritten or	0.200000
and very	0.001445
the delta	0.000692
widely-reported	0.000029
Animate =	1.000000
at SRI	0.014706
of nouns	0.000891
are arranged	0.004149
printed documents	0.083333
interpretation capabilities	0.500000
effort has	0.250000
diversity ''	0.250000
or future	0.004505
large portion	0.043478
usage is	1.000000
, -RRB-	0.000561
transform of	0.200000
'' of	0.005376
or English	0.004505
3 +4	0.200000
machine-translation research	0.500000
specified in	1.000000
metrics .	0.111111
metrics ,	0.111111
scoring Truecasing	0.500000
metrics :	0.111111
following issues	0.066667
`` sad	0.005291
30 %	0.333333
the meeting	0.000692
` conceptual	0.062500
An extrinsic	0.062500
= Human	0.111111
entropy -LRB-	0.200000
detailed discussions	0.500000
The sailor	0.005208
, false	0.000561
Federation	0.000029
thereof -RRB-	1.000000
different output	0.020408
and Jabberwacky	0.001445
given an	0.041667
is available	0.002033
orange in	1.000000
which simply	0.007246
<s> Are	0.000769
has continued	0.011905
Another possible	0.076923
negligibly	0.000029
ISO\/TC37 and	1.000000
likelihood for	0.333333
explicit formalization	0.200000
held	0.000029
, within	0.000561
With continuous	0.142857
still translates	0.066667
speaker recognition	0.055556
they still	0.025000
from our	0.009615
a window	0.001227
are beginning	0.004149
develop dedicated	0.200000
questioned the	1.000000
even with	0.037037
Hopper ,	1.000000
are widely	0.004149
numbers that	0.142857
For other	0.016393
Recognition is	0.125000
the NLP	0.000692
is importance	0.002033
, impressive	0.000561
created based	0.142857
publish	0.000029
for terms	0.003610
plain text	1.000000
useful summary	0.071429
learner ,	0.500000
, rarity	0.000561
and gets	0.001445
by DARPA	0.005714
Junqua	0.000029
trigrams without	0.500000
subtypes of	1.000000
User Interface	0.500000
Marginal Relevance	1.000000
technology would	0.045455
seem to	0.500000
followed .	0.250000
we may	0.022222
answer the	0.033333
pour le	1.000000
selling	0.000029
, split	0.000561
merely assigning	0.500000
Tannen ,	1.000000
like ca	0.035714
have assessed	0.009615
Because ROUGE	0.500000
is substantial	0.002033
major design	0.083333
in trying	0.001873
lexical analysis	0.076923
wife of	1.000000
not initially	0.008929
hybrid approach	0.500000
, comprising	0.000561
français .	1.000000
The progress	0.005208
forward-backward	0.000029
-LRB- free	0.002710
from spelling	0.009615
the random	0.000692
constructions	0.000029
Lehrberger 1982	1.000000
In 1983	0.009524
In 1987	0.009524
letters or	0.100000
application domain	0.071429
the platform	0.000692
direction .	0.333333
stories on	1.000000
popularity	0.000029
USAF ,	1.000000
Asian language	1.000000
new utterance	0.041667
accuracies	0.000029
an enormous	0.007576
labeled as	0.333333
of just	0.000891
author when	0.333333
into sentences	0.012821
assertion	0.000029
his famous	0.083333
, degraded-images	0.000561
otherwise achieves	0.500000
& lines	0.125000
same general	0.040000
QA More	0.047619
from single	0.009615
<s> Open-domain	0.000769
One such	0.076923
With sufficient	0.142857
particularly the	0.200000
Phillips .	1.000000
considered good	0.111111
Biden visit	0.333333
, sentence	0.000561
Code ,	1.000000
tagger on	0.111111
their suitability	0.029412
measures try	0.166667
addressed the	0.500000
have difficulty	0.009615
closely tied	0.200000
lexical units	0.076923
these databases	0.023810
toward	0.000029
even more	0.037037
<s> Unsourced	0.000769
to HMM	0.001328
`` right	0.005291
model temporal	0.033333
is prone	0.002033
companies -LRB-	0.500000
describe developments	0.166667
Turkish	0.000029
or aspect	0.004505
recognition refers	0.008264
Consortium	0.000029
well their	0.035714
Was	0.000029
War	0.000029
or verify	0.004505
, topics	0.000561
for summarization	0.003610
ontology are	0.500000
-RRB- Some	0.002817
disruptive	0.000029
words that	0.009174
Statistical models	0.111111
assigning	0.000029
dialing	0.000029
by applying	0.005714
the possibilities	0.000692
ISO\/TC37\/SC4 .	1.000000
answered about	0.200000
explicitly present	0.250000
get some	0.142857
the foreign	0.000692
as Turkish	0.003484
EARS	0.000029
demonstration was	0.200000
and strength	0.001445
syntactic parser	0.076923
entropy ,	0.200000
tried to	0.333333
major database	0.083333
emoticons	0.000029
redundant sentences	1.000000
their estimated	0.029412
A machine	0.020000
system which	0.010753
`` prestige	0.005291
formulation The	1.000000
counts are	1.000000
as each	0.003484
e-communities through	0.500000
context can	0.030303
, notably	0.000561
other types	0.014286
to run	0.001328
as there	0.003484
of Ethnomethodology	0.000891
Sound waves	0.333333
Speech-to-text reporter	1.000000
be analyzed	0.004219
still disagree	0.066667
one more	0.015385
assumption ,	0.500000
Anthology .	1.000000
a professional	0.001227
annual Loebner	0.500000
but weaker	0.014706
phonemes with	0.166667
<s> Short	0.000769
man ''	1.000000
people would	0.062500
simple parsing	0.038462
Advanced Research	0.200000
article verb	0.034483
to detect	0.001328
you '	0.076923
release or	0.333333
Annex on	1.000000
<s> Informally	0.000769
Named entity	1.000000
in solving	0.001873
subfields of	1.000000
judge is	0.250000
how useful	0.034483
99 %	1.000000
a relic	0.001227
more times	0.010526
naturally spoken	0.500000
ten years	1.000000
his work	0.083333
of efforts	0.000891
they also	0.025000
constituents such	0.500000
Specifically ,	1.000000
language by	0.006757
is largely	0.002033
D ,	1.000000
select whole	0.166667
approaches and	0.035714
classes are	0.200000
of errors	0.000891
Ruth	0.000029
characters from	0.062500
.5	0.000029
has included	0.011905
fulfill expectations	0.500000
algebra word	0.500000
-LRB- grammatical	0.002710
Online software	0.500000
answering have	0.083333
for various	0.003610
linguists decided	0.333333
intuitive	0.000029
model taggers	0.033333
Error Rates	0.500000
similar contexts	0.037037
availability of	1.000000
data table	0.012987
100 million	0.333333
we construct	0.022222
polarity on	0.125000
The AT&T	0.005208
commonly researched	0.125000
one year	0.015385
removal of	1.000000
- -RRB-	0.062500
theory Conversation	0.076923
developed RSI	0.038462
Voice Input	0.200000
into general	0.012821
Supervised text	1.000000
-RRB- involved	0.002817
Automatically	0.000029
improve .	0.076923
independently	0.000029
one place	0.015385
adverbs ,	1.000000
did cause	0.200000
and signing	0.001445
After training	0.333333
a bilingual	0.001227
is closer	0.002033
vertices\/unigrams	0.000029
doing as	0.500000
<s> Intra-texual	0.000769
function of	0.125000
Example-based Main	0.333333
Around the	1.000000
are ranked	0.004149
any supervised	0.032258
modeling ,	0.142857
<s> Similarly	0.000769
characters rather	0.062500
LUNAR was	0.333333
complex endeavors	0.041667
geospatial	0.000029
summarization -RRB-	0.020000
beach ,	1.000000
the burden	0.000692
of Hearing	0.000891
be studied	0.004219
measured can	0.166667
- A	0.062500
current text	0.142857
in operational	0.001873
perform as	0.090909
<s> Adda	0.000769
knowledge comes	0.037037
perform an	0.090909
Japanese camp	0.125000
categorical .	1.000000
database tables	0.100000
serving a	1.000000
, modules	0.000561
since one	0.100000
utilize an	0.500000
example Wireless	0.012346
Speech Technology	0.032258
which involves	0.007246
statistical approach	0.030303
JSF	0.000029
Confusable Words	1.000000
after going	0.083333
analysis ''	0.015385
long-time translator	1.000000
and computer	0.001445
necessary .	0.100000
time on	0.030303
studies and	0.250000
crossed	0.000029
2 descriptions	0.200000
time or	0.030303
successful systems	0.111111
consistent terminology	1.000000
It essentially	0.026316
large-scale content-analysis	1.000000
might ask	0.038462
'' which	0.005376
-LRB- -LRB-	0.002710
AI than	0.333333
also refer	0.014493
MySpace	0.000029
usually termed	0.031250
Politics	0.000029
quotations	0.000029
group at	0.250000
-LRB- ,	0.002710
on simple	0.004717
common feature	0.040000
league over	1.000000
program is	0.045455
of Michigan	0.000891
Consultant -LRB-	1.000000
-LRB- k	0.002710
hands	0.000029
-LRB- c	0.002710
-LRB- b	0.002710
showing evidence	0.500000
the presentation	0.000692
titles and	0.500000
devices for	0.250000
warnings from	1.000000
Marginal	0.000029
Speereo Software	0.500000
-LRB- P	0.002710
IR and	0.333333
lines ,	0.333333
-LRB- F	0.002710
front-end	0.000029
it could	0.008547
semiotics ,	1.000000
and decorrelating	0.001445
then characterized	0.028571
various combinations	0.055556
examples are	0.041667
to :	0.001328
etc. ''	0.045455
Patent 1,915,993	0.333333
facts about	1.000000
Sensory ,	1.000000
represent analog	0.111111
covers tasks	0.250000
incorrect ones	0.333333
and address	0.001445
limit to	0.250000
and noise	0.001445
recommendations	0.000029
, Bobrow	0.000561
completely	0.000029
legends	0.000029
' language	0.052632
1981	0.000029
to turn	0.001328
the large	0.000692
camp ''	0.250000
unsupervised keyphrase	0.125000
<s> Perspectives	0.000769
and extrinsic	0.001445
and determining	0.001445
Some attempts	0.047619
spelled `	1.000000
compiled newswire	1.000000
such formal	0.008130
, voice-activation	0.000561
and 1970s	0.001445
was attempted	0.012987
precisely	0.000029
using random	0.016949
to English	0.001328
perfectly	0.000029
and example	0.001445
conveniently as	1.000000
neural approaches	0.066667
the algorithm	0.000692
on hand-crafted	0.004717
-RRB- languages	0.002817
its application	0.028571
e.g. echoes	0.017857
Recognition -LRB-	0.125000
Guzman	0.000029
parsed efficiently	0.250000
translating speech	0.250000
manual annotation	0.500000
POST -RRB-	1.000000
statistically-based	0.000029
depth ''	0.333333
broken English	0.200000
Jaworski	0.000029
query-biased summaries	1.000000
has meant	0.011905
harder 75	0.142857
though other	0.100000
non-textual	0.000029
lectures	0.000029
deploy	0.000029
-RRB- it	0.002817
- keyphrases	0.062500
Processor	0.000029
utterance ``	0.333333
derived meaning	0.166667
acoustics -RRB-	1.000000
precision because	0.200000
Christmas fall	1.000000
Medical Records	0.500000
tagging system	0.040000
accommodate various	0.200000
employs a	0.500000
Turing test	0.500000
cultural factors	1.000000
bases	0.000029
data-to-text	0.000029
l'assignation	0.000029
testing for	0.200000
and Re-encoding	0.001445
Popular	0.000029
internal organization	0.200000
Narrow	0.000029
low-resolution ,	1.000000
topic or	0.125000
under construction	0.200000
topic of	0.125000
considerable interest	0.200000
screen of	1.000000
models can	0.038462
be challenged	0.004219
rescoring	0.000029
comparable	0.000029
context have	0.030303
difference between	0.250000
this centroid	0.010989
minimal complexity	1.000000
transformed into	1.000000
dedicated OCR	0.333333
Woods	0.000029
as could	0.003484
statistical natural	0.030303
The program	0.005208
pasted ,	1.000000
space character	0.200000
`` political	0.005291
those surrounding	0.045455
be approached	0.004219
with fixed	0.005464
of corpus	0.000891
seem completely	0.500000
article deal	0.034483
legal and	0.333333
cache language	1.000000
of interaction	0.000891
earlier term	0.250000
magazine 's	1.000000
on post-processing	0.004717
Ann	0.000029
recent developments	0.125000
air is	0.200000
can learn	0.005525
of retail	0.000891
was done	0.012987
phenomenon may	0.200000
descriptive and	0.333333
included analyses	0.125000
World ,	0.142857
been encouraging	0.014706
segments at	0.200000
Summarizers	0.000029
strength score	0.200000
, NLG	0.000561
with recognition	0.005464
APEXC	0.000029
way as	0.041667
human would	0.021739
that alone	0.003546
of optical	0.000891
verify the	1.000000
vertices ,	0.111111
SpeechTEK and	0.500000
uttered before	0.333333
vertices ?	0.111111
evaluation systems	0.018519
male-female	0.000029
software -LRB-	0.037037
Despite	0.000029
and bought	0.001445
NNS	0.000029
human-language	0.000029
formulaic	0.000029
immediately	0.000029
immunology	0.000029
these represent	0.023810
dictionaries	0.000029
initial sounds	0.333333
overt morphological	1.000000
'' implicate	0.005376
Svenka	0.000029
, showing	0.000561
such features	0.008130
largest speech	1.000000
to humans	0.001328
less standardised	0.083333
Extract subjective	1.000000
them with	0.052632
a relaxed	0.001227
ends a	0.500000
received considerable	0.500000
are highly	0.004149
inaccurate	0.000029
Other areas	0.142857
movie review	0.333333
multi-way	0.000029
OCR vendors	0.020408
their chosen	0.029412
a sensible	0.001227
qualities of	0.500000
Many machine	0.083333
<s> LR	0.000769
represented using	0.166667
been data-to-text	0.014706
synthesizer	0.000029
A feature	0.020000
in picture	0.001873
Jelinek F.	0.500000
Workshop Hirschman	1.000000
i.e. requiring	0.052632
nodes for	0.142857
late 70s	0.111111
goals	0.000029
eat	0.000029
spaces used	0.200000
it must	0.008547
on pattern	0.004717
phrase ``	0.100000
decisions probabilistically	0.100000
The problems	0.005208
main ''	0.125000
stories	0.000029
converted them	0.333333
shallow-transfer machine	1.000000
to aid	0.001328
probability is	0.142857
transcription of	0.500000
by Kurzweil	0.005714
Norval ,	1.000000
Santorini gives	1.000000
Besides	0.000029
The FAA	0.005208
of candidates	0.000891
IBM and	0.333333
alternative courses	0.333333
of databases	0.000891
a co-occurrence	0.001227
voice recognition	0.076923
Due to	1.000000
evaluators .	1.000000
form words	0.050000
on speech	0.004717
is technology	0.002033
cross-discipline of	1.000000
ensure verifiability	1.000000
from Latin	0.009615
1,000,000 words	1.000000
techniques similar	0.043478
show the	1.000000
-LRB- at	0.002710
fine-grained	0.000029
receipts ,	1.000000
to analyze	0.001328
abbreviations .	0.200000
1976 the	0.500000
Generation Challenges	0.500000
do we	0.038462
be his	0.004219
and length	0.001445
an in-depth	0.007576
wreck	0.000029
text as	0.006289
huge handmade	1.000000
Last level	1.000000
grammar -LRB-	0.027027
images .	0.166667
telephony is	0.333333
desired answers	0.200000
Greene	0.000029
adjective 40	0.142857
of planning	0.000891
had mentioned	0.071429
determining whether	0.166667
dry	0.000029
He received	0.125000
same in	0.040000
the Puma	0.000692
Each level	0.166667
-- between	0.040000
special fonts	0.200000
G. Lehnart	0.500000
human thought	0.021739
investigation performed	1.000000
describing a	0.250000
with each	0.005464
capture the	0.500000
logic oriented	0.250000
of mouse	0.000891
Gismo ''	0.500000
extracted summaries	1.000000
Algorithms which	0.500000
V	0.000029
paste relevant	1.000000
is probably	0.002033
goals of	1.000000
it that	0.008547
processing Objectives	0.018519
, June	0.000561
ontology requires	0.500000
operations .	1.000000
, relative	0.000561
only into	0.026316
depended on	1.000000
are harder	0.004149
commonplace and	1.000000
transform -LRB-	0.200000
blogs and	0.500000
75 %	1.000000
most sentiment	0.017241
domains ASR	0.125000
various aspects	0.055556
Monroe	0.000029
term voice	0.055556
An automated	0.062500
formalisms are	0.500000
some training	0.012048
results may	0.047619
annotated -LRB-	0.500000
' is	0.052632
Recall this	0.333333
maximal	0.000029
is digital	0.002033
light -RRB-	0.333333
the assistance	0.000692
products '	0.250000
therapy	0.000029
products .	0.250000
products ,	0.250000
to travel	0.001328
hearings -RRB-	1.000000
, Facebook	0.000561
quantities .	0.333333
their device	0.029412
side	0.000029
probability to	0.142857
help prevent	0.111111
a bill	0.001227
typology	0.000029
Poncini	0.000029
interim year	1.000000
crucial	0.000029
software and	0.037037
; a	0.021277
, D.	0.000561
who maintains	0.100000
overlap metrics	0.250000
which focused	0.007246
sentence structure	0.020833
; A	0.021277
100000	0.000029
which focuses	0.007246
to treat	0.001328
article ``	0.034483
likely following	0.062500
`` angry	0.005291
effectiveness of	0.333333
thereof	0.000029
very hard	0.024390
hand-produced	0.000029
sentiment .	0.040000
conditions ;	0.200000
more common	0.010526
example text	0.012346
Press	0.000029
HMM-based part	0.333333
and retrieving	0.001445
the initial	0.000692
all where	0.023256
preparation	0.000029
enables	0.000029
even lower	0.037037
perhaps surprisingly	0.166667
mine	0.000029
Designing	0.000029
seek	0.000029
virtually any	0.500000
read not	0.142857
automatically focus	0.047619
synopsis	0.000029
SpeechTEK Europe	0.500000
delayed until	1.000000
shared-task	0.000029
US Veterans	0.142857
a novel	0.001227
regular	0.000029
categories -LRB-	0.111111
goal .	0.142857
must produce	0.071429
or dimensions	0.004505
pick the	1.000000
Unlike PageRank	1.000000
principle	0.000029
` hitcha	0.062500
consumer	0.000029
History The	0.500000
to medical	0.001328
modules ,	0.500000
post-process	0.000029
, vehicle	0.000561
QA is	0.047619
exploits	0.000029
Shift-Reduce parsing	1.000000
you want	0.076923
see Tablet	0.050000
separate parts	0.100000
Searches	0.000029
States Air	0.142857
and replicated	0.001445
documents might	0.026316
guided by	1.000000
Dogged	0.000029
in parametric	0.001873
us with	0.500000
nautical term	0.500000
in e-communities	0.001873
other fields	0.014286
edges between	0.142857
assignment .	0.500000
last year	0.200000
distances represented	0.500000
`` hub	0.005291
issues relating	0.200000
methods require	0.022727
Vocabulary is	0.333333
simplest	0.000029
glossary or	0.500000
another -RRB-	0.076923
on top	0.004717
the shift-reduce	0.000692
greater accuracy	0.333333
candidacies and	1.000000
compared phrase-structure	0.142857
disseminate	0.000029
fairly non-trivial	0.250000
very much	0.024390
Cognitive psychology	0.333333
built that	0.333333
parsing aims	0.035714
users sent	0.111111
21 taggers	1.000000
PDF to	1.000000
Robert Wilensky	0.250000
by different	0.005714
by multiplying	0.005714
mainly from	0.166667
Giro ,	1.000000
persuasion ,	1.000000
from Turney	0.009615
e.g. containing	0.017857
software vendors	0.037037
Language Input	0.083333
integrated part	0.333333
feasibility study	0.500000
`` President	0.005291
Martin ,	0.500000
, Perceptron	0.000561
duplicate or	0.500000
state -LRB-	0.071429
after Fourier	0.083333
Sacks ,	1.000000
Context-free	0.000029
power ,	0.250000
mouse	0.000029
often requires	0.022727
Journal -RRB-	0.333333
others can	0.083333
confusability Speaker	1.000000
enterprise customers	1.000000
vibrates	0.000029
vocabulary of	0.125000
MMR -RRB-	1.000000
1970s ,	0.333333
Englund	0.000029
how the	0.034483
Results have	1.000000
as paraphrase	0.003484
questions under	0.038462
pulled directly	1.000000
not before	0.008929
complex matter	0.041667
importance .	0.166667
-LRB- HLDA	0.002710
's tagger	0.019608
Rates Increase	1.000000
and similar	0.001445
not Afghanistan	0.008929
reuse	0.000029
structure rules	0.083333
had an	0.071429
opportunity to	0.500000
were the	0.024390
Based on	1.000000
computer ,	0.022727
now called	0.076923
NC ''	1.000000
pragmatics of	0.333333
prisoners or	0.500000
in differing	0.001873
a situation	0.001227
learn such	0.076923
<s> Profile	0.000769
extensive research	0.333333
-RRB- represents	0.002817
making more	0.142857
separate lexical	0.100000
accumulation of	1.000000
known labeled	0.038462
encode in	1.000000
The Associated	0.005208
critics claim	1.000000
to read	0.001328
terminology	0.000029
français	0.000029
general use	0.045455
to accomplish	0.001328
technology that	0.045455
lectures ,	1.000000
do .	0.038462
tokens like	0.142857
possibilities must	0.200000
any safety	0.032258
any condition	0.032258
task-based -LRB-	0.250000
teletype	0.000029
of FoG	0.000891
automatically ,	0.047619
Keyphrases have	1.000000
step -RRB-	0.066667
increased and	0.200000
the meantime	0.000692
disassembling	0.000029
based representation	0.018519
include contractions	0.037037
of surrounding	0.000891
span several	1.000000
apply statistical	0.200000
In 1629	0.009524
between an	0.025641
more forms	0.010526
Bayes risk	0.333333
the Turney	0.000692
are content	0.004149
Bolivar ,	1.000000
hoping to	1.000000
Gustav Tauschek	1.000000
application requirements	0.071429
authoritative	0.000029
it enumerated	0.008547
first occurrence	0.030303
but such	0.014706
probabilistic division	0.142857
Sager ,	0.500000
automation Interactive	1.000000
text illustrates	0.006289
standards require	0.200000
help speakers	0.111111
school-age children	1.000000
<s> Tokens	0.000769
in massive	0.001873
interest Topics	0.090909
involves several	0.100000
of January	0.000891
sounds ''	0.066667
segments -LRB-	0.200000
Sensory	0.000029
for voice	0.003610
continues to	1.000000
of charge	0.000891
, closed-domain	0.000561
a vocabulary	0.001227
High-order n-gram	1.000000
Japanese .	0.125000
further commercializing	0.125000
photographing data	1.000000
therefore to	0.200000
Japanese ,	0.125000
processing and	0.018519
by one	0.005714
its context	0.028571
a final	0.001227
93-95 %	1.000000
item	0.000029
minimal	0.000029
to bootstrap	0.001328
patterns rather	0.200000
Scotland with	0.200000
their framework	0.029412
Heritage	0.000029
an Australian	0.007576
the can	0.000692
Wilson ,	1.000000
during machine	0.100000
or she	0.004505
features ''	0.038462
a substantial	0.001227
passages to	0.500000
and atmosphere	0.001445
reader to	0.100000
Perceptron ,	1.000000
shift	0.000029
many NLP	0.019231
of similarity	0.000891
results of	0.047619
and Nelson	0.001445
conveniently	0.000029
emotional communication	0.250000
in principle	0.001873
and encouraged	0.001445
action is	0.200000
understanding also	0.030303
` global	0.062500
with Japanese	0.005464
associated with	0.250000
-RRB- one	0.002817
finding non-existent	0.200000
compactly	0.000029
Critical Genre	0.500000
lessened	0.000029
previously prepared	0.500000
: Produce	0.009804
Givón	0.000029
On a	0.166667
purposes -LRB-	0.250000
document\/text summarization	0.500000
Lehrberger	0.000029
course ,	0.333333
in performance	0.001873
William Labov	0.500000
be obtained	0.004219
is obtained	0.002033
not require	0.008929
learn to	0.076923
various algorithms	0.055556
an extractive	0.007576
social psychology	0.071429
evaluating the	0.200000
significant semiotic	0.111111
combination and	0.200000
hand printing	0.071429
sentence such	0.020833
script will	0.250000
, special	0.000561
man	0.000029
display format	0.500000
follows that	0.500000
silence	0.000029
-RRB- measure	0.002817
talk	0.000029
to NLP	0.001328
Cook ,	1.000000
pitch	0.000029
of disambiguation	0.000891
con sentiment	1.000000
Savic	0.000029
system operators	0.010753
relationships in	0.166667
one can	0.015385
creates new	0.500000
See machine	0.166667
Nearest-neighbor	0.000029
Arbor ,	1.000000
related words	0.066667
`` corpora	0.005291
Substantial test	0.500000
machine-aided	0.000029
mainly the	0.166667
My head	1.000000
SWER -RRB-	1.000000
vectors ,	0.333333
Interactional	0.000029
recognizer ,	1.000000
automatic analysis	0.043478
were ambiguous	0.024390
funding of	0.125000
centroid sentence	0.500000
2500	0.000029
3rd	0.000029
the one	0.000692
emerged	0.000029
metamodel	0.000029
sentence there	0.020833
than procedural	0.022222
thus beyond	0.100000
small local	0.111111
subject -RRB-	0.125000
recursion in	1.000000
organizations such	1.000000
For keyphrase	0.016393
supervised machine	0.062500
painstakingly ``	1.000000
semantics without	0.071429
Referring	0.000029
Before a	0.500000
-LRB- Wilensky	0.002710
is exactly	0.002033
approximation was	0.166667
common term	0.040000
prize .	1.000000
typically include	0.055556
especially because	0.066667
systems do	0.008929
Tagging	0.000029
direct comparison	0.166667
position of	0.250000
broadcast	0.000029
Unsupervised tagging	0.166667
; nor	0.021277
11	0.000029
Are there	1.000000
17	0.000029
gives examples	0.500000
though we	0.100000
LexRank uses	0.083333
example the	0.012346
noise but	0.125000
an evaluation	0.007576
exceeded	0.000029
where POS	0.028571
future developments	0.333333
the subjectivity	0.000692
having considerable	0.200000
by Frost	0.005714
cases are	0.055556
appears that	0.200000
multiple parts	0.076923
learn tag	0.076923
Features might	1.000000
To mine	0.111111
and laughter	0.001445
ask him	0.250000
currency for	1.000000
attractive recognition	0.333333
an OCR	0.007576
leads ,	1.000000
shop	0.000029
previously-written	0.000029
show	0.000029
after removing	0.083333
section titles	0.166667
be reached	0.004219
complicating the	1.000000
human judge	0.021739
2008 -RRB-	1.000000
original sound	0.076923
discourses and	0.500000
method -LRB-	0.062500
1979 -RRB-	1.000000
are numerous	0.004149
promise to	1.000000
been displaced	0.014706
1996 ,	1.000000
best guesses	0.055556
Bayes ,	0.333333
mild repetitive	1.000000
-LRB- Asia	0.002710
development cost	0.083333
<s> Finally	0.000769
documents as	0.026316
MT companies	0.200000
F =	1.000000
and techniques	0.001445
prepared ,	1.000000
uses several	0.071429
processing plain	0.018519
developed CLAWS	0.038462
sensible	0.000029
For sentiment	0.016393
a robot	0.001227
culminating in	1.000000
word to	0.016667
call ''	0.333333
translation paradigms	0.013514
top-down parsers	0.250000
is hard	0.002033
Fairclough	0.000029
RCA Drum	0.200000
'' non-linearly	0.005376
<s> Large-scale	0.000769
Psycholinguists	0.000029
photocells	0.000029
Edward	0.000029
-RRB- vs.	0.002817
transducers with	1.000000
weighted finite	0.333333
conferences	0.000029
-RRB- recognize	0.002817
devised to	0.500000
known key	0.038462
paper used	0.090909
based engine	0.018519
approaches differ	0.035714
the British	0.000692
others were	0.083333
Mention must	1.000000
sentences '	0.013158
FAA document	0.500000
works It	0.500000
LMF -RRB-	1.000000
Initial results	1.000000
Digest ,	0.333333
degrees depending	0.500000
Booth and	1.000000
Hirschman 1998	0.500000
bi-directional	0.000029
be presented	0.004219
: syntax	0.009804
or con	0.004505
right kind	0.100000
interactive translation	0.250000
broad ,	0.250000
grid	0.000029
materials to	0.500000
and large	0.001445
sentence and	0.020833
LexRank deals	0.083333
-- to	0.040000
from section	0.009615
ATIS .	1.000000
suitability for	0.500000
facing	0.000029
those which	0.045455
words emerge	0.009174
into battle	0.012821
British General	0.333333
its main	0.028571
Dr.	0.000029
Statistics guided	0.333333
, sets	0.000561
devoted in	0.200000
pilots flying	0.500000
extensively	0.000029
-LRB- Journal	0.002710
to resort	0.001328
Environmental noise	1.000000
with deep	0.005464
T.	0.000029
sound blocks	0.050000
over hand-produced	0.083333
and Lifeline	0.001445
referenced	0.000029
moon missions	1.000000
, Margaret	0.000561
produces Grass	0.250000
is capitalized	0.002033
http:\/\/arxiv.org\/abs\/1104.2086 -RRB-	1.000000
typically grouped	0.055556
methods did	0.022727
possible forms	0.041667
, large	0.000561
those meanings	0.045455
to analyzing	0.001328
: how	0.009804
; or	0.021277
name must	0.200000
represent natural	0.111111
<s> LUNAR	0.000769
following words	0.066667
extraction process	0.032258
Warren Weaver	1.000000
Society	0.000029
a necessary	0.001227
was Pollen	0.012987
Leo Spitzer	1.000000
risk -LRB-	0.500000
USA	0.000029
sentiment -LRB-	0.040000
world 's	0.066667
, adjective	0.000561
1-July-2005	0.000029
genres	0.000029
As this	0.055556
and when	0.001445
personnel	0.000029
to +5	0.001328
like supervised	0.035714
98.5	0.000029
vibrates per	1.000000
SBD -RRB-	1.000000
enumerated all	1.000000
was connected	0.012987
computer-generated	0.000029
was of	0.012987
world ''	0.066667
these environments	0.023810
Speaking ''	1.000000
observe	0.000029
Piron ,	0.333333
possible word	0.041667
pollen count	0.076923
oral	0.000029
Was he	1.000000
how people	0.034483
aids	0.000029
speech feature	0.006579
Marcus M.	1.000000
Greene and	1.000000
determine both	0.043478
looking wave	0.200000
aids for	1.000000
trainer .	1.000000
news documents	0.076923
referring expression	0.500000
environment where	0.166667
characters to	0.062500
are names	0.004149
human-generated summaries	0.500000
cohesion ''	1.000000
, adjectives	0.000561
minimize the	1.000000
of theories	0.000891
terms ,	0.076923
to progress	0.001328
same in-depth	0.040000
, domotic	0.000561
the founder	0.000692
public	0.000029
<s> Starting	0.000769
of analyzing	0.000891
approached keyphrase	0.500000
harder it	0.142857
rich information	0.200000
segments each	0.200000
any speaker	0.032258
million books	0.333333
was all	0.012987
expression generation	0.100000
at varying	0.014706
their own	0.029412
an input-stream	0.007576
, instead	0.000561
, negative	0.000561
might expect	0.038462
like writing	0.035714
, dimensionality	0.000561
assign positive	0.200000
first customers	0.030303
enormous amount	1.000000
unit ,	0.333333
Zacharov -RRB-	1.000000
Web 2.0	0.111111
or sentiments	0.004505
issue ,	0.125000
Relationship extraction	1.000000
in domains	0.001873
about 1965	0.025000
priorities	0.000029
!	0.000029
smoothly or	0.500000
computer database	0.022727
which even	0.007246
of modern	0.000891
This way	0.015873
attitude of	0.500000
amenable to	1.000000
This was	0.015873
walk to	0.200000
Standard Annex	0.500000
submit their	0.500000
Produce a	1.000000
technique chosen	0.142857
among others	0.125000
to computer	0.001328
sound really	0.050000
`` STT	0.005291
playing	0.000029
if a	0.035714
smaller dictionary	0.142857
connected directly	0.200000
summary might	0.023810
25	0.000029
26	0.000029
20	0.000029
21	0.000029
this constraint	0.010989
23	0.000029
years in	0.047619
sponsored by	0.500000
database ,	0.100000
for billing	0.003610
and Development	0.001445
decade in	0.333333
accelerations and	1.000000
which describe	0.007246
for programming	0.003610
unit block	0.333333
deteriorated	0.000029
computer interaction	0.022727
eliminate the	0.500000
chose different	1.000000
feature dependencies	0.076923
logical assertions	0.166667
and Vietnamese	0.001445
other levels	0.014286
algorithm known	0.035714
print	0.000029
was extensively	0.012987
categories themselves	0.111111
modeling has	0.142857
pattern has	0.166667
machine -RRB-	0.012658
the Levenshtein	0.000692
prior work	0.333333
technique which	0.142857
increasing the	0.333333
component .	0.200000
previous training	0.333333
generators .	0.500000
read musical	0.142857
Brenton	0.000029
sentence-level syntax	1.000000
language constraints	0.006757
accordance with	1.000000
Kurzweil started	0.142857
devoted exclusively	0.200000
, outputting	0.000561
Precision	0.000029
Clancy	0.000029
of User	0.000891
combination hidden	0.200000
popularity as	1.000000
related questions	0.066667
to clean	0.001328
pars	0.000029
Rogerian psychotherapist	1.000000
`` On	0.005291
speech recognizers	0.006579
recording	0.000029
Ohio Bell	1.000000
accent ,	1.000000
was tested	0.012987
trillion-word	0.000029
SPHINX	0.000029
on it	0.004717
proved far	0.333333
majority	0.000029
not pre	0.008929
the subsequent	0.000692
likely related	0.062500
individuals that	1.000000
correct answer	0.066667
<s> Individuals	0.000769
can simplify	0.005525
podcast where	1.000000
weapons release	1.000000
UK RAF	0.250000
photos against	1.000000
, similarities	0.000561
' at	0.052632
sentence-level	0.000029
a purpose	0.001227
community ,	1.000000
8	0.000029
constraints ;	0.250000
to five	0.001328
is considerable	0.002033
constraints .	0.250000
<s> Behind	0.000769
token ,	0.250000
be an	0.004219
clues in	0.333333
senses .	0.500000
semitied	0.000029
part-of-speech markers	0.066667
segments and	0.200000
discover these	1.000000
Canadian Hansard	0.500000
right-hand-sides	0.000029
'' corpora	0.005376
Senseval	0.000029
ELIZA might	0.111111
's methodology	0.019608
Postal	0.000029
agreement about	0.333333
<s> Bottom-up	0.000769
that funding	0.003546
, our	0.000561
semantics .	0.071429
generated -LRB-	0.066667
models were	0.038462
representing successive	0.500000
also classify	0.014493
introduction of	1.000000
manage their	1.000000
opens ,	1.000000
are then	0.004149
45 %	1.000000
together in	0.125000
, \*	0.000561
of building	0.000891
gap	0.000029
estate advertisements	1.000000
sentence to	0.020833
some set	0.012048
Shepard went	0.333333
Performing grammatical	1.000000
a recent	0.001227
length normalization	0.125000
search .	0.090909
Fairclough ,	1.000000
tagging work	0.040000
of fusion	0.000891
structures ,	0.200000
-LRB- extrinsic	0.002710
Symantec changed	0.500000
Weizenbaum at	0.333333
, DeRose	0.000561
Activity	0.000029
specific summarization	0.047619
vectors would	0.333333
be moderate	0.004219
hand -RRB-	0.071429
metrics like	0.111111
the ROUGE	0.000692
usually the	0.031250
less accurate	0.083333
sponsored evaluations	0.500000
ICR .	0.333333
approach in	0.028571
deliberately	0.000029
what they	0.031250
was considered	0.012987
Future research	0.500000
smoothing to	1.000000
semi	0.000029
moderate with	0.200000
-RRB- Hands-free	0.002817
CyberEmotions	0.000029
accelerations	0.000029
, cursive	0.000561
1971 -LRB-	0.333333
ending at	1.000000
although there	0.166667
Commissioned by	1.000000
Some text	0.047619
T ,	0.166667
So an	0.333333
301	0.000029
synthesis techniques	1.000000
addressed in	0.500000
vol-2	0.000029
air -LRB-	0.200000
readability	0.000029
in artificial	0.001873
constraint	0.000029
processing tasks	0.018519
because NLP	0.033333
or movies	0.004505
networks allow	0.071429
segment the	0.111111
of segmentation	0.000891
getting into	0.250000
be referenced	0.004219
extracting answers	0.200000
top-down expansion	0.250000
on developing	0.004717
LDA-based	0.000029
contrastive analysis	1.000000
method used	0.062500
seconds ,	1.000000
theory to	0.076923
simplify the	1.000000
Ruth Wodak	1.000000
decided that	0.333333
kind appears	0.090909
acoustic and	0.166667
input which	0.024390
achieves its	0.500000
, ASR	0.000561
-- indeed	0.040000
Books	0.000029
exploration	0.000029
using algorithms	0.016949
words coming	0.009174
decided without	0.333333
textual representation	0.200000
Perhaps	0.000029
big a	0.500000
<s> Due	0.000769
H. Shepard	0.500000
within Tipster	0.055556
Case	0.000029
works These	0.500000
prepared	0.000029
much harder	0.045455
most other	0.017241
to encourage	0.001328
the desktop	0.000692
2,000 or	0.500000
express sentiment	0.200000
Asian	0.000029
articulated theory	1.000000
historically -RRB-	0.500000
general approaches	0.045455
'' ``	0.005376
and Grass	0.001445
the dBase	0.000692
-LRB- parsed	0.002710
mid-1960s .	1.000000
1914 ,	1.000000
entry has	0.250000
University by	0.111111
, Vito	0.000561
automotive	0.000029
in full	0.001873
DTW .	0.333333
be decided	0.004219
helped improve	0.333333
help to	0.111111
EMR -LRB-	0.333333
judgments .	1.000000
gather information	1.000000
on programer	0.004717
such rules	0.008130
paper-to-computer text	1.000000
the norm	0.000692
<s> Commanders	0.000769
exchange	0.000029
Evaluation -LRB-	0.111111
for acquiring	0.003610
implicit	0.000029
32	0.000029
, Nikolas	0.000561
programs often	0.090909
their input	0.029412
Acoustical distortions	0.500000
stochastic semantic	0.125000
authors found	0.200000
such input	0.008130
Subsequently a	1.000000
improvements .	0.500000
our alphabetic	0.200000
basic and	0.076923
phrase `	0.100000
large probabilities	0.043478
unsupervised ''	0.125000
, Ruth	0.000561
similar ideas	0.037037
determining sentiment	0.166667
NLP that	0.021277
keyphrases available	0.028571
direct translation	0.166667
Recognition or	0.125000
other native	0.014286
year later	0.166667
phrase ,	0.100000
normalized	0.000029
Yet ELIZA	1.000000
speech from	0.006579
on discourse	0.004717
focus is	0.142857
is semantic	0.002033
to arrive	0.001328
contained in	1.000000
obvious	0.000029
number on	0.023256
on machine-learning	0.004717
want not	0.166667
differ in	0.333333
Teun	0.000029
the editor	0.000692
Phonemes	0.000029
the personal	0.000692
democracy	0.000029
Sometimes it	1.000000
modeling of	0.142857
detail .	0.500000
nouns -LRB-	0.111111
out from	0.071429
Journal corpus	0.333333
useful NLG	0.071429
this step	0.010989
WER	0.000029
Approaches which	0.333333
of Quechua	0.000891
The umbrella	0.005208
, widely	0.000561
perhaps the	0.166667
has plateaued	0.011905
leverages the	1.000000
Chilton ,	1.000000
looks ,	0.250000
to post-process	0.001328
technology Sensory	0.045455
linguistics .	0.050000
views as	1.000000
graphic user	1.000000
a potentially	0.001227
entries ,	0.500000
is written	0.002033
proven useful	1.000000
Knowing this	1.000000
a growing	0.001227
fulfill the	0.500000
IBM Research	0.333333
tones that	1.000000
Michael Stubbs	0.250000
the disfluences	0.000692
-RRB- output	0.002817
versions of	0.333333
multi-document extractive	0.250000
In 1935	0.009524
conducted the	0.200000
to specify	0.001328
stub	0.000029
These standards	0.058824
is specifically	0.002033
Speaker Independent	0.166667
-RRB- Bhatia	0.002817
Unix Consultant	0.500000
and knowledge	0.001445
possible task	0.041667
conversations .	0.333333
with keyphrases	0.005464
conversations ,	0.333333
taken up	0.333333
words relate	0.009174
judges can	0.500000
Hence -LRB-	0.500000
speech tools	0.006579
performed through	0.100000
single verbal	0.071429
Annotate the	1.000000
have unambiguous	0.009615
were question	0.024390
command interpreters	0.500000
seen in	0.100000
been trained	0.014706
AVRADA tests	0.500000
at conclusions	0.014706
are broader	0.004149
content -LRB-	0.083333
system developed	0.010753
visited	0.000029
was .	0.012987
consideration of	0.333333
controller would	0.250000
papers by	0.333333
unlikely	0.000029
close	0.000029
Oil	0.000029
mid	0.000029
as models	0.003484
explicit word	0.200000
Carston	0.000029
every combination	0.333333
constraints Read	0.250000
graphs	0.000029
this ostensibly	0.010989
`` defective	0.005291
Bhatia	0.000029
is unusual	0.002033
, multi-document	0.000561
use text	0.013889
has now	0.011905
accommodate direct	0.200000
each template	0.022222
complicated backgrounds	0.333333
documents and	0.026316
speech-recognition machine	0.333333
inferior	0.000029
, possessive	0.000561
in 1989	0.001873
, anthropology	0.000561
<s> Described	0.000769
in 1982	0.001873
in 1984	0.001873
True\/False	0.000029
expressed by	0.166667
currently focus	0.142857
4 star	0.200000
Their algorithm	0.500000
using precision	0.016949
of 200	0.000891
the gradual	0.000692
The results	0.005208
no matter	0.076923
informal exchange	0.500000
, need	0.000561
segmentation will	0.030303
of intermediary	0.000891
generalized ATNs	1.000000
anomalies .	1.000000
set that	0.025641
time series	0.030303
Alessandro	0.000029
by searching	0.005714
validity and	1.000000
Products began	0.500000
resolved :	1.000000
usually separated	0.031250
inference algorithms	0.250000
January 13	0.250000
proposal	0.000029
during verbalization	0.100000
machines by	0.250000
these actions	0.023810
doctors ,	0.333333
an abstract	0.007576
by precision	0.005714
on understanding	0.004717
it belongs	0.008547
many sentences	0.019231
sometimes had	0.076923
inseparable part	1.000000
almost	0.000029
proper noun	0.142857
The vertices	0.005208
consideration neural	0.333333
the latter	0.000692
requires a	0.062500
The reader	0.005208
and recording	0.001445
to book	0.001328
the difficulty	0.000692
infer	0.000029
e.g. Noise	0.017857
a clarification	0.001227
abruptly at	1.000000
modern parsers	0.200000
approaches ,	0.035714
PAM -LRB-	1.000000
language of	0.006757
<s> Little	0.000769
as SVM	0.003484
, UMLS	0.000561
some labeled	0.012048
languages are	0.020000
constraints are	0.250000
made by	0.062500
nodes based	0.142857
speaking speeds	0.125000
DOE -RRB-	1.000000
been explored	0.014706
a date	0.001227
add	0.000029
a data	0.001227
confusions	0.000029
with machine	0.005464
tourism information	1.000000
part -LRB-	0.037037
we learn	0.022222
Ethnomethodology	0.000029
perceptions are	1.000000
Noise in	1.000000
likely another	0.062500
are already	0.004149
in taxonomies	0.001873
feature\/aspect-based sentiment	1.000000
1935 Tauschek	1.000000
is brought	0.002033
, several	0.000561
used OCR	0.008850
British English	0.333333
controversy is	1.000000
boards	0.000029
certainty	0.000029
of approaches	0.000891
basically a	1.000000
or paragraph	0.004505
of international	0.000891
the outside	0.000692
Computing +	0.500000
, task-based	0.000561
blind ,	0.250000
are under	0.004149
of phonetic	0.000891
researchers wrote	0.100000
segmentation may	0.030303
phases .	1.000000
second aim	0.100000
other pieces	0.014286
26 letters	1.000000
disambiguate sentence	0.333333
Significant advances	1.000000
a difficult	0.001227
vastly less	1.000000
theoretical perspectives	0.333333
discussions in	0.333333
objective sentences	0.200000
proceeds	0.000029
47	0.000029
ambiguity by	0.125000
45	0.000029
that identify	0.003546
impossibility	0.000029
Context and	1.000000
occurrence of	0.500000
of accent	0.000891
requires six	0.062500
no. .	1.000000
highly structured	0.111111
5 consecutive	0.500000
coding of	1.000000
of answer	0.000891
definitional questions	1.000000
questions asking	0.038462
of physics	0.000891
Described	0.000029
Extractive methods	1.000000
a universal	0.001227
well be	0.035714
Naive	0.000029
font at	0.333333
Air controller	0.333333
<s> Artificial	0.000769
proposed as	0.111111
level is	0.050000
people ,	0.062500
<s> English	0.000769
with initial	0.005464
learned from	0.200000
dynamically create	0.500000
unified mathematical	1.000000
look-up	0.000029
simply based	0.083333
Management command	1.000000
An explicit	0.062500
consistent	0.000029
English POS-taggers	0.027027
the keyboard	0.000692
words commonly	0.009174
effectively learning	0.333333
whole workday	0.111111
Huang	0.000029
Harold Garfinkel	1.000000
learning model	0.023256
70s	0.000029
Savic Naomi	1.000000
metrics in	0.111111
the search	0.000692
Subsumption	0.000029
unigram matching	0.200000
target-language-independent	0.000029
language are	0.006757
June	0.000029
people from	0.062500
noting	0.000029
see appraisal	0.050000
assessment	0.000029
translation or	0.013514
task -LRB-	0.023810
in garden	0.001873
extensively used	1.000000
including images	0.071429
the judge	0.000692
distinguish reliably	0.200000
possible semantics	0.041667
being able	0.055556
, Stephen	0.000561
, Why	0.000561
similarity to	0.100000
segmentation depends	0.030303
many as	0.019231
by these	0.005714
of elementary	0.000891
appears to	0.200000
express all	0.200000
warping -LRB-	0.250000
walk ,	0.200000
Most modern	0.500000
there 's	0.025000
methods Some	0.022727
generated out	0.066667
Page\/Lex\/TextRank that	1.000000
simply verbs	0.083333
German taggers	0.250000
linguistic formalism	0.062500
Essentially ,	1.000000
the effectiveness	0.000692
challenges -RRB-	0.500000
Hendrix formed	1.000000
bore similarities	1.000000
the prolific	0.000692
than T	0.022222
recognize equivalent	0.111111
trivial ,	0.250000
aloud	0.000029
<s> Realisation	0.000769
-- often	0.040000
currently used	0.142857
routing -LRB-	0.333333
Ford Sync	1.000000
for up-to-date	0.003610
automating	0.000029
principled way	1.000000
test document	0.100000
Pang who	0.333333
1971 Terry	0.333333
, who	0.000561
U.S. program	0.142857
into its	0.012821
defines the	0.500000
Act of	1.000000
tourism	0.000029
especially if	0.066667
Granada Pallet	0.500000
best one	0.055556
selecting examples	0.200000
modern statistically-based	0.200000
Objectives	0.000029
the models	0.000692
and multitude	0.001445
<s> Warren	0.000769
<s> Aggregation	0.000769
time-consuming and	0.333333
-RRB- by	0.002817
collaborated	0.000029
'' from	0.005376
were accelerations	0.024390
relatively simple	1.000000
while logic	0.050000
Studies	0.000029
vol-2 Black	1.000000
The performance	0.005208
messages into	0.500000
and informativeness	0.001445
of phrases	0.000891
onto	0.000029
, document	0.000561
Stanford University	0.500000
20th-century	0.000029
Nielsen	0.000029
must take	0.071429
popular is	0.111111
Creating referring	0.500000
clues not	0.333333
concurrently with	1.000000
artificial languages	0.090909
subsequent application	0.500000
stopwords .	1.000000
maximal probability	1.000000
ends up	0.500000
appliance control	1.000000
summaries formed	0.023256
in pattern	0.001873
commercializing	0.000029
overriding issue	1.000000
converse on	1.000000
report -LRB-	0.250000
1964	0.000029
has 4	0.011905
has 2	0.011905
Gina Poncini	1.000000
to separate	0.001328
at lower	0.014706
punched cards	1.000000
items in	0.500000
an LDA-based	0.007576
grammatical relationships	0.090909
machine and	0.012658
High-performance fighter	1.000000
can function	0.005525
should predict	0.052632
tools usually	0.166667
Records	0.000029
decoding is	1.000000
include versions	0.037037
algorithm exploits	0.035714
Web -RRB-	0.111111
recognized or	0.166667
scale .	0.166667
are complicated	0.004149
that adaptation	0.003546
which led	0.007246
2,026,329 -RRB-	1.000000
Spanish do	0.500000
appears in	0.200000
roadmap	0.000029
the comprehension	0.000692
cost of	0.500000
M-346	0.000029
discriminate because	0.333333
recognizing entire	0.200000
these apply	0.023810
alone usually	0.250000
weak	0.000029
-LRB- QA	0.002710
taken place	0.333333
have developed	0.009615
wear	0.000029
relationships can	0.166667
find left-most	0.076923
for word	0.003610
corpus and	0.032258
Computed	0.000029
For the	0.016393
Bobrow	0.000029
as EAGLi	0.003484
after testing	0.083333
games	0.000029
simpler questions	0.333333
variance	0.000029
a specialised	0.001227
convinced many	1.000000
custom software	0.500000
successes occurred	1.000000
requires significant	0.062500
for generating	0.003610
each ambiguity	0.022222
the differences	0.000692
<s> Part-of-speech	0.000769
simplification	0.000029
quickly	0.000029
one detail	0.015385
speech choice	0.006579
hence reducing	0.500000
Pennsylvania	0.000029
a communicative	0.001227
sources or	0.166667
pitch ,	1.000000
non-Western	0.000029
; otherwise	0.021277
pyramid	0.000029
value ,	0.333333
undercarriage	0.000029
value .	0.333333
resolve some	0.250000
experts	0.000029
much about	0.045455
n't end	0.250000
advances	0.000029
Part-of-Speech	0.000029
was applied	0.012987
minimum phone	0.500000
are consumed	0.004149
contain enough	0.083333
pick	0.000029
hard task	0.166667
token generation	0.250000
positives	0.000029
the culture	0.000692
some nice	0.012048
SHRDLU could	0.166667
Internet and	0.500000
broad tags	0.250000
between closely	0.025641
another linguistic	0.076923
MAHS =	1.000000
NLG researchers	0.047619
<s> Attribute	0.000769
F35	0.000029
Nunan	0.000029
official languages	1.000000
paper documents	0.090909
exceptions -RRB-	1.000000
, reliability	0.000561
linguistic cues	0.062500
advent of	1.000000
learning applications	0.023256
the Baum-Welch	0.000692
vibration	0.000029
should figure	0.052632
transcription .	0.500000
cultural	0.000029
this aim	0.010989
's 1990	0.019608
MLLT -RRB-	1.000000
translation Transfer-based	0.013514
a scaling	0.001227
<s> Tags	0.000769
errors or	0.200000
a smaller	0.001227
tackles each	1.000000
interact with	1.000000
tagging by	0.040000
extended in	1.000000
germane to	1.000000
areas ,	0.166667
answer 90	0.033333
control when	0.200000
the state-of-the-art	0.000692
again statistically	1.000000
mechanized	0.000029
chapter	0.000029
be based	0.004219
grammars can	0.071429
forward-backward algorithm	1.000000
naturally occurring	0.500000
plus	0.000029
cursive handwriting	0.200000
human review	0.021739
calling for	1.000000
, Cleave	0.000561
need is	0.047619
= Noun	0.111111
attempted	0.000029
portions	0.000029
Microphone on	1.000000
Nuance Voice	0.333333
the inherent	0.000692
in each	0.001873
, ICASSP	0.000561
constrained ,	1.000000
discontinuous ,	0.333333
naive semantics	0.500000
applied ,	0.066667
= no.	0.111111
been devised	0.014706
to enable	0.001328
Archaeology of	1.000000
this paper	0.010989
Effective	0.000029
lies the	0.500000
return a	0.500000
using either	0.016949
recognition because	0.008264
an opportunity	0.007576
suggest a	0.333333
US Navy	0.142857
recognized normal	0.166667
`` patient	0.005291
data be	0.012987
analysis which	0.015385
charge	0.000029
promoting	0.000029
techniques merely	0.043478
Tagger ,	1.000000
management system	0.142857
individual morphemes	0.083333
UPV -RRB-	1.000000
ca n't	1.000000
improve results	0.076923
up-to-date research	1.000000
, Wayne	0.000561
vulnerable to	1.000000
They simply	0.333333
producing the	0.333333
only one	0.026316
dried	0.000029
size N	0.166667
improve robustness	0.076923
Known word	1.000000
since they	0.100000
is challenging	0.002033
with low	0.005464
favor a	0.500000
'' exceeded	0.005376
mention how	0.333333
Aermacchi M-346	1.000000
dissertation -LRB-	0.333333
size ,	0.166667
emerge	0.000029
successively more	1.000000
in Scotland	0.001873
Collection of	1.000000
Telematics -LRB-	1.000000
covariance transform	0.500000
formalisms\/languages	0.000029
a fluent	0.001227
handles	0.000029
the implied	0.000692
inference within	0.250000
major algorithms	0.083333
enhance accessibility	1.000000
speech that	0.006579
nearly anything	0.500000
new application	0.041667
that converts	0.003546
lexical similarity	0.076923
recognition within	0.008264
Please improve	0.333333
repeatedly reviewed	1.000000
converted the	0.333333
differences It	0.333333
and computationally	0.001445
are analytical	0.004149
extracting sentences	0.200000
Edmund	0.000029
counting	0.000029
sentences weighted	0.013158
DeRose and	0.200000
online expression	0.125000
evaluate summaries	0.250000
of subjectivity	0.000891
for air	0.003610
to texts	0.001328
emails -RRB-	0.500000
used is	0.008850
be unrealistically	0.004219
<s> Typically	0.000769
context-free ,	0.090909
in reverse	0.001873
-RRB- while	0.002817
human intervention	0.021739
of Speaker	0.000891
'' text	0.005376
Machines	0.000029
disease ,	1.000000
led by	0.333333
far is	0.125000
and placed	0.001445
representative of	1.000000
text more	0.006289
levels even	0.045455
depth understanding	0.333333
sources are	0.166667
to TextRank	0.001328
usefulness of	1.000000
, sufficiently	0.000561
continue	0.000029
between posts	0.025641
ongoing issue	0.500000
anthropology ,	1.000000
the narrowest	0.000692
describe informal	0.166667
out a	0.071429
Nearest-neighbor have	1.000000
acquiring coarse-grained	1.000000
paradigm includes	0.333333
pyramid showing	1.000000
Knowledge of	0.500000
uttered one	0.333333
closed-captioning	0.000029
Knowledge on	0.500000
up or	0.045455
rank ,	0.166667
rank .	0.166667
a stream	0.001227
coherence .	0.333333
up of	0.045455
<s> Leading	0.000769
parsing for	0.035714
systems indicate	0.008929
and Weizenbaum	0.001445
a conversation	0.001227
Record	0.000029
Security	0.000029
library are	0.500000
abstraction Broadly	0.250000
the years	0.000692
-RRB- securely	0.002817
PC +	0.250000
those patterns	0.045455
our everyday	0.200000
array	0.000029
might refer	0.038462
returns	0.000029
we could	0.022222
mental representations	0.333333
examples ?	0.041667
implicitly determines	1.000000
specify	0.000029
RSI	0.000029
fade away	1.000000
unfortunately	0.000029
synopsis like	1.000000
explore critical	0.250000
very distant	0.024390
verbalization	0.000029
from other	0.009615
they helped	0.025000
themselves sometimes	0.250000
English grammars	0.027027
some statistical	0.012048
selling a	1.000000
ideal	0.000029
Ethnography	0.000029
one summary	0.015385
tasks include	0.031250
humans in	0.083333
a superset	0.001227
, phrases	0.000561
<s> Reading	0.000769
automatically tuned	0.047619
erroneous input	1.000000
document can	0.027778
missions .	1.000000
the blind	0.000692
the CoNLL	0.000692
occur on	0.200000
bridging relationship	1.000000
`` do	0.005291
sentence -LRB-	0.020833
evidence for	0.500000
Spitzer 's	1.000000
machine-generated summaries	1.000000
rocks returned	1.000000
All the	1.000000
ways .	0.125000
paragraphs in	0.250000
review .	0.333333
evident that	0.500000
on summarization	0.004717
to remain	0.001328
Apollo moon	1.000000
formats like	1.000000
closed world	1.000000
reveal	0.000029
hierarchically in	1.000000
it 's	0.008547
did Christmas	0.200000
Ge'ez	0.000029
same objects	0.040000
vertices\/unigrams are	1.000000
as nouns	0.003484
that difference	0.003546
following years	0.066667
May 2009	0.500000
: Extract	0.009804
, culminating	0.000561
field is	0.037037
-RRB- -	0.002817
represent only	0.111111
turns -RRB-	0.333333
from false	0.009615
be also	0.004219
Apple Newton	1.000000
a row	0.001227
recognized with	0.166667
in following	0.001873
corpus has	0.032258
adjective -LRB-	0.142857
Treebank -RRB-	0.166667
also lead	0.014493
different profile	0.020408
sold to	0.333333
`` centroid	0.005291
entirely and	0.500000
under a	0.200000
, probabilities	0.000561
centrality .	0.500000
disparate fields	1.000000
abstractive method	0.166667
summarization hopes	0.020000
Thus the	0.083333
simple substitution	0.038462
Lemke	0.000029
the higher	0.000692
now the	0.076923
which recognized	0.007246
tagged as	0.333333
operational settings	1.000000
basic task	0.076923
determine what	0.043478
ten-year-long research	1.000000
to require	0.001328
improving output	1.000000
cartoon	0.000029
-LRB- SBD	0.002710
but robustness	0.014706
it runs	0.008547
reasoning mechanisms	0.142857
accuracy substantially	0.032258
<s> Hybrid	0.000769
-LRB- not	0.002710
domain is	0.050000
of descriptive	0.000891
reason why	0.250000
point scale	0.333333
and creation	0.001445
for Computational	0.003610
cause much	0.500000
name of	0.200000
at revealing	0.014706
include automatic	0.037037
accepted	0.000029
be for	0.004219
With IT	0.142857
... About	0.500000
G-loads .	1.000000
Bobrow 's	1.000000
has more	0.011905
three or	0.333333
bi-directional inference	1.000000
DARPA -LRB-	0.250000
Much of	0.333333
underpinnings discouraged	1.000000
2001 -RRB-	0.500000
Hansard	0.000029
would still	0.018868
first solid	0.030303
Web or	0.111111
A post	0.020000
media has	0.166667
Control -RRB-	1.000000
reading machine	0.125000
, meaning	0.000561
play in	1.000000
English speaking	0.027027
cosine values	0.333333
, medicine	0.000561
rescore	0.000029
short-time stationary	0.500000
corrected by	1.000000
nodes should	0.142857
Slembrouck ,	1.000000
predict what	0.166667
within computer	0.055556
up pronouns	0.045455
amongst	0.000029
program and	0.045455
security process	1.000000
part because	0.037037
decide to	0.250000
vocal tract	1.000000
change focus	1.000000
The user	0.005208
before it	0.166667
, complicating	0.000561
objective or	0.200000
assumptions .	0.200000
a speaker-dependent	0.001227
automatic is	0.043478
Sacks	0.000029
Parsers may	0.500000
Project ,	1.000000
current commercial	0.142857
backward	0.000029
was due	0.012987
systems to	0.008929
unsupervised ,	0.125000
humor -RRB-	1.000000
unweighted	0.000029
spacecraft	0.000029
meets two	0.500000
So far	0.333333
who utilize	0.100000
Das ,	1.000000
generate polynomial-size	0.055556
ARCHILES	0.000029
CANDIDE from	1.000000
other punctuation	0.014286
features ,	0.038462
statistical translation	0.030303
for Larry	0.003610
al.	0.000029
mentioned the	0.166667
combining those	0.250000
Fowler	0.000029
Afghanistan or	1.000000
the history	0.000692
hand .	0.071429
or content	0.004505
a nautical	0.001227
an extrinsic	0.007576
Force and	0.500000
learn it	0.076923
available to	0.058824
overload	0.000029
but a	0.014706
model and	0.033333
simple conditions	0.038462
-RRB- Marc	0.002817
multitude	0.000029
express this	0.200000
1965 based	0.250000
steps of	0.500000
Another reason	0.076923
complexity .	0.083333
1984 .	1.000000
these T	0.023810
digital texts	0.142857
the derived	0.000692
fair gold-standard	1.000000
, means	0.000561
extremes	0.000029
may pick	0.019231
POS-taggers	0.000029
learning automatically	0.023256
the characters	0.000692
classification :	0.058824
Tom	0.000029
of restaurant	0.000891
Human-machine interaction	1.000000
cost related	0.500000
Overall	0.000029
as multiple	0.003484
the Artificial	0.000692
is for	0.002033
, Sept.	0.000561
superset of	1.000000
Das	0.000029
basically	0.000029
The recently	0.005208
Dyer	0.000029
Yale which	0.500000
printed in	0.083333
Systems with	0.083333
discussions .	0.333333
highest level	0.333333
Snyder performed	0.500000
uses spontaneous	0.071429
, speeches	0.000561
, simulated	0.000561
closest the	0.500000
, contain	0.000561
automatically answering	0.047619
of coherent	0.000891
replace the	1.000000
how phrases	0.034483
recognition applications	0.008264
each with	0.022222
that statistical	0.003546
commercial interest	0.090909
multiple times	0.076923
judgement or	0.333333
campaigns within	0.500000
much smaller	0.045455
and Dale	0.001445
without having	0.076923
weaknesses	0.000029
difficult and	0.035714
scripts ,	0.333333
are commonly	0.004149
to millions	0.001328
Hearing ,	1.000000
Machine Learning	0.111111
text databases	0.006289
binary classifier	0.250000
then applies	0.028571
natural-language	0.000029
journal abstracts	0.333333
metric such	0.333333
be understood	0.004219
Full	0.000029
misspelled	0.000029
affine	0.000029
machine-learning paradigm	0.250000
resort	0.000029
of valuable	0.000891
are ``	0.004149
sometimes be	0.076923
machine digitized	0.012658
elements ,	0.250000
characterizes	0.000029
computer-aided language	0.333333
, 1975	0.000561
, 1977	0.000561
, 1979	0.000561
techniques use	0.043478
experimented	0.000029
organised	0.000029
degree to	0.166667
the HMM	0.000692
Such inflection	0.125000
and generate	0.001445
shipment	0.000029
simplification Text-to-speech	1.000000
Penpoint	0.000029
often make	0.022727
other places	0.014286
's many	0.019608
Malcolm Coulthard	1.000000
meet Wikipedia	0.250000
as named	0.003484
new approaches	0.041667
NLP is	0.021277
the sizes	0.000692
well-known	0.000029
says	0.000029
allow a	0.200000
, Ford	0.000561
analysis Applied	0.015385
right-to-left ,	1.000000
2000 -RRB-	0.333333
expensive to	0.142857
involved the	0.166667
the KEA	0.000692
photographing	0.000029
understand that	0.142857
are put	0.004149
break hyphenated	0.500000
a canonical	0.001227
an urgent	0.007576
characters that	0.062500
of inflected	0.000891
as people	0.003484
ratings for	0.111111
to sort	0.001328
common -LRB-	0.040000
for document	0.003610
computer programming	0.022727
he proposed	0.142857
raters typically	1.000000
75	0.000029
classifier so	0.142857
prestige	0.000029
from knowledge	0.009615
to 150	0.001328
largely because	0.200000
paper ,	0.090909
paper .	0.090909
Facebook -RRB-	1.000000
more human-generated	0.010526
chapter ,	1.000000
that builds	0.003546
inflection	0.000029
, Verbyx	0.000561
Ann Arbor	1.000000
, analyze	0.000561
right ,	0.100000
compiled	0.000029
to protect	0.001328
distortions -LRB-	1.000000
sentiment of	0.040000
BASEBALL and	0.500000
English in	0.027027
English is	0.027027
discourse -RRB-	0.027778
approaches assume	0.035714
many in	0.019231
Case =	1.000000
probabilistic modeling	0.142857
signal or	0.166667
comparison of	0.333333
2.0 was	0.500000
candidates can	0.200000
University researchers	0.111111
unigrams placed	0.083333
numerous	0.000029
positive sentiment	0.142857
profiling	0.000029
Document summarization	0.250000
the occurrence	0.000692
instance some	0.071429
's quality	0.019608
relying	0.000029
of major	0.000891
1971 and	0.333333
the machine-learning	0.000692
in Northern	0.001873
: Neural	0.009804
text fragments	0.006289
misspelled words	1.000000
assertions in	0.500000
Pragmatics	0.000029
displays .	1.000000
SVOX .	1.000000
LexRank paper	0.083333
quite expensive	0.125000
various natural	0.055556
concentrates	0.000029
5000 or	1.000000
simple sentence	0.038462
gained surprising	0.500000
Communication .	1.000000
and geospatial	0.001445
impersonate	0.000029
and\/or aural	0.333333
grammar :	0.027027
non-linear transformations	1.000000
analysis --	0.015385
literature	0.000029
boundary identification	0.166667
big green	0.500000
Leeuwen ,	1.000000
the answers	0.000692
tonal language	1.000000
is described	0.002033
specific domains	0.047619
inference algorithm	0.250000
Dogged ''	1.000000
methods build	0.022727
stating	0.000029
computer -LRB-	0.022727
D. Booth	0.200000
make the	0.050000
with n	0.005464
Since then	0.200000
programmed with	0.500000
however empirical	0.076923
KEA -LRB-	1.000000
the majority	0.000692
English text	0.027027
governmental	0.000029
two senses	0.034483
Last	0.000029
writing -RRB-	0.111111
with -LRB-	0.005464
with .	0.005464
with ,	0.005464
groups submit	0.200000
and SVOX	0.001445
are instructed	0.004149
regular expressions	1.000000
scanner and	0.333333
digitalized	0.000029
-RRB- words	0.002817
an excellent	0.007576
essential	0.000029
we use	0.022222
<s> Langues	0.000769
recall-based to	0.500000
the EHR	0.000692
been built	0.014706
the partial	0.000692
extracting and	0.200000
-LRB- IR	0.002710
patterns ,	0.200000
because analyzing	0.033333
researched tasks	1.000000
informatics	0.000029
However some	0.027027
that integrated	0.003546
Evaluation The	0.111111
<s> Effective	0.000769
Statistical techniques	0.111111
that generate	0.003546
This rubric	0.015873
ELIZA .	0.111111
relief is	1.000000
classifier for	0.142857
The objects	0.005208
process include	0.027778
degrees of	0.500000
form letters	0.050000
right information	0.100000
noun 40	0.071429
that simultaneously	0.003546
The European	0.005208
about which	0.025000
humans possess	0.083333
field which	0.037037
consist	0.000029
Bell	0.000029
coverage of	0.333333
Yale University	0.500000
very large	0.024390
controller tasks	0.250000
discrete characters	0.333333
-RRB- hours	0.002817
specialist textbook	1.000000
core database	0.500000
similarity .	0.100000
phonemes .	0.166667
helping	0.000029
word with	0.016667
grow without	1.000000
Cullingford ,	1.000000
both in	0.032258
into computer-understandable	0.012821
vice	0.000029
Malcolm	0.000029
-RRB- Around	0.002817
demonstrates	0.000029
once	0.000029
and lexical	0.001445
features -LRB-	0.038462
N in	0.333333
N is	0.333333
English-like command	0.333333
its lexicon	0.028571
dramatically	0.000029
sentiment about	0.040000
work from	0.041667
context or	0.030303
This term	0.015873
systems ''	0.008929
be distinguished	0.004219
as HMM	0.003484
documents more	0.026316
facemask	0.000029
various optimization	0.055556
<s> Rules	0.000769
ambiguous there	0.083333
query these	0.333333
modified	0.000029
have corpus	0.009615
appear consecutively	0.062500
made up	0.062500
and inspired	0.001445
voice file	0.076923
EUROPARL ,	1.000000
hypothesis	0.000029
produce models	0.045455
arguably function	0.500000
human-written texts	0.500000
: Automatically	0.009804
of estimating	0.000891
The technique	0.005208
hardly any	1.000000
<s> Of	0.000769
the LexRank	0.000692
, Screenshot	0.000561
people for	0.062500
Statistical Main	0.111111
most summarization	0.017241
performance improvements	0.055556
need as	0.047619
need at	0.047619
derivation or	0.250000
of discrete	0.000891
succeeding on	1.000000
of Lichtenstein	0.000891
computational humor	0.100000
summarise conditions	0.333333
consumption	0.000029
the conversations	0.000692
Prolog	0.000029
trade offs	0.500000
periods or	0.333333
adjacent and	0.166667
filtered by	0.333333
on recognition	0.004717
journals -LRB-	0.500000
Disambiguation Main	1.000000
by relying	0.005714
little any	0.333333
impressive .	0.500000
mentioned above	0.166667
comprehensive survey	0.200000
anywhere	0.000029
identify .	0.083333
publish a	1.000000
all natural	0.023256
, recognizing	0.000561
stress and	0.500000
and English	0.001445
nice '	0.250000
parser for	0.062500
certain region	0.142857
typical machine-learning-based	0.111111
Caldas-Coulthard	0.000029
handover	0.000029
meaning ;	0.043478
target -LRB-	0.090909
appraisal theory	1.000000
pursued after	1.000000
of rule-based	0.000891
Document reader	0.250000
famous early	0.333333
would somehow	0.018868
traditionally written	0.500000
dividing speech	0.333333
multiply .	1.000000
revealing socio-psychological	1.000000
sufficient iteration	0.200000
quantity .	0.333333
the ''	0.000692
only cares	0.026316
But also	0.166667
unique and	1.000000
mine the	1.000000
ways to	0.125000
a user-provided	0.001227
not represent	0.008929
, training	0.000561
of handwritten	0.000891
can occur	0.005525
Janet Kolodner	0.500000
have become	0.009615
it led	0.008547
then be	0.028571
contains a	0.100000
documents where	0.026316
To decode	0.111111
<s> Vocabulary	0.000769
clusters	0.000029
and relevant	0.001445
tasks from	0.031250
articles rarely	0.125000
organized notations	1.000000
Applications include	0.500000
input characters	0.024390
they observe	0.025000
Graph This	1.000000
breathing was	1.000000
, syllables	0.000561
sense and	0.125000
bills	0.000029
substantially .	1.000000
the 2011	0.000692
tasks defined	0.031250
Wendy	0.000029
80	0.000029
a global	0.001227
other aspects	0.014286
human-readable	0.000029
above --	0.076923
autopilot	0.000029
simple morphology	0.038462
real time	0.111111
maintains	0.000029
post-processing by	0.333333
fields .	0.166667
of 19th	0.000891
character -RRB-	0.045455
or evaluation	0.004505
search -LRB-	0.090909
, after	0.000561
five pages	0.200000
3 ,	0.200000
co-founded	0.000029
corpora ,	0.090909
3 %	0.200000
parse tree	0.111111
highly .	0.111111
a slide	0.001227
of named	0.000891
<s> Importance	0.000769
word -LRB-	0.016667
Success	0.000029
, Thai	0.000561
of sentence-level	0.000891
peak ,	1.000000
Ethnomethodology .	1.000000
logical representation	0.166667
its definition	0.028571
method in	0.062500
stock market	0.333333
rarity	0.000029
of pragmatics	0.000891
method is	0.062500
known cases	0.038462
their solutions	0.029412
two illustrates	0.034483
caused problems	1.000000
forecasts to	0.200000
certain assumptions	0.142857
features involve	0.038462
angle	0.000029
together into	0.125000
as if	0.003484
; Compute	0.021277
i.e. so	0.052632
for NLP	0.003610
part-of-speech ,	0.066667
Lichtenstein	0.000029
Kintsch	0.000029
principles which	1.000000
accessibility ,	1.000000
corpus is	0.032258
encouraged researchers	1.000000
is clear	0.002033
used an	0.008850
and methodologies	0.001445
RCA engineers	0.200000
Before getting	0.500000
, spoken	0.000561
at TWA	0.014706
co-occur at	0.500000
first and	0.030303
state computers	0.071429
wrote a	0.166667
for customisation	0.003610
affect OCR	0.333333
and Latin	0.001445
primary output	0.500000
simple terms	0.038462
sentence of	0.020833
'' for	0.005376
titled Natural	1.000000
Ken Church	1.000000
, ID	0.000561
this procedure	0.010989
limited applications	0.100000
The difference	0.005208
has dried	0.011905
on increasingly	0.004717
levels is	0.045455
levels in	0.045455
variability	0.000029
recognize speech	0.111111
studied more	1.000000
crucial to	1.000000
and align	0.001445
Server	0.000029
in Norman	0.001873
Important journals	1.000000
discourses ,	0.500000
discourse begin	0.027778
-LRB- EBMT	0.002710
immediately to	1.000000
increasing number	0.333333
databases into	0.125000
-LRB- Loriot	0.002710
Finally	0.000029
Pang and	0.333333
table lookup	0.142857
automotive maintenance	1.000000
From these	1.000000
image consisting	0.333333
recommending ''	1.000000
quite distinct	0.125000
small integer	0.111111
different speaking	0.020408
negative emotions	0.125000
analysis has	0.015385
systems applications	0.008929
processing problems	0.018519
to train	0.001328
unlike	0.000029
parse reranking	0.111111
English into	0.027027
tag-sets	0.000029
Organization ,	1.000000
the average	0.000692
MPE -RRB-	1.000000
benefits to	0.500000
semantic or	0.047619
presume a	1.000000
2002 a	0.500000
visual and\/or	0.500000
are maximum	0.004149
assigns large	1.000000
humans as	0.083333
The ideal	0.005208
gained by	0.500000
to densely	0.001328
reconfiguring	0.000029
an easier	0.007576
which should	0.007246
Translations are	1.000000
automation	0.000029
by Zellig	0.005714
seminal paper	1.000000
they rephrase	0.025000
rules generated	0.023256
Speaker independent	0.166667
information theory	0.021739
greatly reduced	0.142857
Using the	0.500000
are probably	0.004149
interlingua	0.000029
ranking sentences	0.142857
other academic	0.014286
rapidly growing	0.500000
`` un-supervised	0.005291
answer questions	0.033333
good search	0.076923
information that	0.021739
Brenton D.	1.000000
grammar parsing	0.027027
, Liberman	0.000561
in multiple	0.001873
larger summarization	0.062500
, domain	0.000561
States ,	0.142857
Scope and	1.000000
trillion-word corpus	1.000000
States ?	0.142857
summarization technology	0.020000
<s> Recently	0.000769
entertaining can	0.500000
lot of	0.333333
the record	0.000692
arbitrarily long	1.000000
statistical language	0.030303
but evaluation	0.014706
, distinct	0.000561
different problem	0.020408
FAA as	0.500000
usually faster	0.031250
methods already	0.022727
answering The	0.083333
OCR Since	0.020408
difficulty is	0.142857
For some	0.016393
artifacts	0.000029
8000	0.000029
and Snyder	0.001445
whose theoretical	0.333333
found no	0.071429
follows a	0.500000
IE additionally	0.333333
PCFGs -LRB-	1.000000
where particular	0.028571
important topics	0.062500
accuracy above	0.032258
, room	0.000561
, coreference	0.000561
suggest valuable	0.333333
`` ASR	0.005291
valid summary	1.000000
approximated	0.000029
mutual	0.000029
is less	0.002033
documents per	0.026316
segment .	0.111111
task-effectiveness well	0.500000
prisoners ?	0.500000
NAACL ,	1.000000
or turns-at-talk	0.004505
programs that	0.090909
may or	0.019231
but sometimes	0.014706
But then	0.166667
thought-to-paper	0.000029
users after	0.111111
builds up	0.500000
paper Shipibo	0.090909
, Computer	0.000561
so meaningless	0.033333
implicate ``	1.000000
with images	0.005464
ParaEval	0.000029
SourceForge	0.000029
`` Speech	0.005291
dictionary can	0.142857
or EHR	0.004505
morphological analysis	0.333333
Word-sense disambiguation	1.000000
good results	0.076923
exactly how	0.333333
online databases	0.125000
Chafe	0.000029
specialist	0.000029
, location	0.000561
reporter	0.000029
read 23	0.142857
chosen .	0.200000
conversational	0.000029
the geological	0.000692
became one	0.200000
Japanese prisoners	0.125000
HLT	0.000029
capabilities were	0.200000
task often	0.023810
Recovery and	1.000000
to other	0.001328
in similar	0.001873
processes of	0.200000
brought	0.000029
each lexical	0.022222
member of	1.000000
Basic	0.000029
experience ,	0.500000
and ask	0.001445
; total	0.021277
extractive -LRB-	0.142857
of whether	0.000891
carried out	0.500000
taxonomies .	1.000000
usable output	1.000000
the mean	0.000692
sub-categories .	1.000000
above 95	0.076923
using shallow	0.016949
processors or	1.000000
99	0.000029
Language Workshop	0.083333
detection of	0.500000
achieved translating	0.100000
capabilities by	0.200000
natural-language processing	1.000000
Perspectives	0.000029
all nouns	0.023256
classification-related	0.000029
-RRB- break	0.002817
word use	0.016667
all alternative	0.023256
analysis on	0.015385
MorphoChallenge	0.000029
Formal	0.000029
, stochastic	0.000561
specifically concerned	0.500000
Each article	0.166667
Schober	0.000029
`` computer	0.005291
usually operate	0.031250
which accommodate	0.007246
test how	0.100000
providing a	0.500000
findings were	1.000000
the evaluators	0.000692
voice dialing	0.076923
James Paul	0.250000
matching -RRB-	0.200000
fidelity	0.000029
systems now	0.008929
The shapes	0.005208
text corpora	0.006289
programer	0.000029
Red is	1.000000
orthography .	0.500000
understanding machine	0.030303
, clean	0.000561
quite weak	0.125000
as vertices	0.003484
fonts ,	0.333333
Plot	0.000029
caps -RRB-	1.000000
resources and	0.166667
<s> Telephony	0.000769
: Example-based	0.009804
Gustav	0.000029
detection and	0.500000
disfluences -LRB-	1.000000
complex setting	0.041667
Functional grammar	1.000000
sometimes preferred	0.076923
heavy-noise ,	1.000000
years -LRB-	0.047619
and makes	0.001445
being followed	0.055556
capitalize names	1.000000
has published	0.011905
's OCR	0.019608
see that	0.050000
Sonic	0.000029
similarly	0.000029
will tend	0.028571
quantity -LRB-	0.333333
be NP-complete	0.004219
language characters	0.006757
a -5	0.001227
Code	0.000029
and many	0.001445
also many	0.014493
tractability .	1.000000
by finding	0.005714
to structured	0.001328
approach involves	0.028571
\/ F-16	0.333333
-RRB- leverages	0.002817
distinction of	0.200000
solved in	0.200000
billion words	1.000000
A corpus	0.020000
easier part	0.125000
use\/mention distinction	1.000000
hub	0.000029
Current difficulties	0.200000
might want	0.038462
an untagged	0.007576
of morphologically	0.000891
using ,	0.016949
in 1933	0.001873
above to	0.076923
metric -LRB-	0.333333
funding to	0.125000
resource such	0.200000
though much	0.100000
incomplete	0.000029
to databases	0.001328
Union	0.000029
early as	0.100000
SIGGEN portion	1.000000
example type	0.012346
design of	0.250000
of count	0.000891
Translator	0.000029
that speech	0.003546
adviser for	1.000000
newspaper articles	0.333333
, headlines	0.000561
started trying	0.250000
decisions only	0.100000
in-principle	0.000029
is able	0.002033
, GRASSHOPPER	0.000561
adjectives .	0.333333
context --	0.030303
issue of	0.125000
issue on	0.125000
naturalness	0.000029
Other systems	0.142857
, any	0.000561
controllers -LRB-	0.333333
and decelerations	0.001445
and writing	0.001445
A more	0.020000
language data	0.006757
this point	0.010989
patented	0.000029
Text-proofing	0.000029
contribute to	1.000000
, Constraint	0.000561
the mental	0.000692
stochastic purposes	0.125000
Method	0.000029
billing	0.000029
meaning but	0.043478
Dependent	0.000029
extractive approach	0.142857
-LRB- digital	0.002710
risk of	0.500000
do something	0.038462
already placed	0.200000
year despite	0.166667
algorithm -LRB-	0.035714
SRI	0.000029
Holmes	0.000029
, Jelinek	0.000561
user about	0.071429
can perform	0.005525
e.g. SCU	0.017857
remembering	0.000029
weaknesses .	1.000000
employs rule-based	0.500000
co-occur with	0.500000
importantly ,	1.000000
's first	0.019608
translated as	0.250000
and smaller	0.001445
decorrelating the	1.000000
templates	0.000029
may result	0.019231
vary with	0.166667
that ROUGE	0.003546
tune	0.000029
usability .	1.000000
Structure ,	1.000000
, meanings	0.000561
focus to	0.142857
a multileveled	0.001227
defined ,	0.166667
think of	0.333333
morphological distinctions	0.333333
rushing	0.000029
succeeding	0.000029
of 80	0.000891
ease	0.000029
For individuals	0.016393
successful HMM-based	0.111111
should soon	0.052632
answer -LRB-	0.033333
of keywords	0.000891
speaker dependent	0.055556
corpus -LRB-	0.032258
Pallet 1998	0.500000
seen -RRB-	0.100000
occurring	0.000029
paraphrase	0.000029
in classifying	0.001873
to pre-process	0.001328
<s> Just	0.000769
languages with	0.020000
the 93-95	0.000692
, archiving	0.000561
Warren	0.000029
appears multiple	0.200000
publicly available	1.000000
System	0.000029
Frederick Jelinek	1.000000
<s> Canada	0.000769
are different	0.004149
on text	0.004717
Pollen counts	1.000000
forward than	1.000000
decide when	0.250000
de Beaugrande	0.500000
First	0.000029
challenges .	0.500000
word delimiter	0.016667
the notable	0.000692
scholars -LRB-	0.500000
the fidelity	0.000692
offer	0.000029
extraction Task	0.032258
the part-of-speech	0.000692
Liberman M.	1.000000
location ,	1.000000
and interjection	0.001445
UK dealing	0.250000
coherent discourse	0.200000
steer-point coordinates	1.000000
new data	0.041667
and treat	0.001445
inclusion in	1.000000
verifiability	0.000029
contain rules	0.083333
Intelligence ''	0.333333
large text	0.043478
levels ,	0.045455
levels .	0.045455
a similar	0.001227
human-readable address	1.000000
articles on	0.125000
or Continuous	0.004505
100000 may	1.000000
steps ,	0.500000
present special	0.166667
patient ''	1.000000
Inc. in	0.500000
Lee Pike	1.000000
pars -LRB-	1.000000
see what	0.050000
interlingual ,	0.250000
Desktop	0.000029
It approaches	0.026316
machine-learning algorithms	0.250000
analysts not	0.500000
've just	0.500000
task because	0.023810
1960s and	0.333333
tools starts	0.166667
Stanford ,	0.500000
Discursive	0.000029
mainly evaluation	0.166667
to Recognize	0.001328
data was	0.012987
of NLG	0.000891
base of	0.250000
various fine	0.055556
find that	0.076923
base or	0.250000
word-forms are	1.000000
a full-text	0.001227
and end	0.001445
issues are	0.200000
findings	0.000029
what class	0.031250
meteorologist -RRB-	1.000000
1965 it	0.250000
harmonic mean	1.000000
learning is	0.023256
processes implemented	0.200000
source software	0.041667
basic knowledge	0.076923
deterministic problem	0.250000
was higher	0.012987
Associated	0.000029
corpora of	0.090909
flight ''	0.500000
corpora on	0.090909
life ?	0.250000
they disagree	0.025000
Finally ,	1.000000
life .	0.250000
the entity	0.000692
resolution remains	0.250000
processing group	0.018519
be detected	0.004219
not functioning	0.008929
training on	0.035714
on SourceForge	0.004717
'' tagging	0.005376
by creating	0.005714
answer candidate	0.033333
less -RRB-	0.083333
, Abney	0.000561
validity	0.000029
passage web	1.000000
tends to	1.000000
end abruptly	0.125000
printing	0.000029
Text grammar	0.166667
domotic	0.000029
the Sparkle	0.000692
effort should	0.250000
Single Word	1.000000
The goal	0.005208
High-order	0.000029
lines segments	0.333333
divider	0.000029
results for	0.047619
qualitatively The	1.000000
making decisions	0.142857
essay scoring	1.000000
and weaknesses	0.001445
truck	0.000029
you say	0.076923
Typhoon currently	1.000000
the highest	0.000692
, sociology	0.000561
assume no	0.500000
produce both	0.045455
Telephony and	1.000000
it proved	0.008547
additional features	0.166667
sentence-ending	0.000029
include papers	0.037037
errata ,	1.000000
means Category	0.166667
from multimedia	0.009615
linguists can	0.333333
many keyphrases	0.019231
copy the	1.000000
can both	0.005525
those using	0.045455
predefined	0.000029
-RRB- provides	0.002817
1,000 words	0.500000
example through	0.012346
sentences or	0.013158
written for	0.038462
by Joseph	0.005714
besides	0.000029
words --	0.009174
's annual	0.019608
The essential	0.005208
massive	0.000029
ATN	0.000029
thus require	0.100000
heuristics with	0.500000
of newspaper	0.000891
might also	0.038462
EAGLi	0.000029
is becoming	0.002033
simulators	0.000029
two categories	0.034483
This device	0.015873
inventor	0.000029
some linguistic	0.012048
standardised	0.000029
with human-made	0.005464
segments besides	0.200000
often required	0.022727
sad	0.000029
records is	0.250000
testing is	0.200000
called grammatical	0.055556
Pointwise Mutual	1.000000
saw	0.000029
12 ,	0.200000
in Italy	0.001873
may depend	0.019231
note	0.000029
Important	0.000029
spending limit	1.000000
Writing	0.000029
, called	0.000561
and phonemes	0.001445
-LRB- AFTI	0.002710
be processed	0.004219
multilingual corpus	0.333333
in more	0.001873
known summaries	0.038462
or by	0.004505
features making	0.038462
help understand	0.111111
thirty years	1.000000
coverage ,	0.333333
coverage .	0.333333
tract length	1.000000
for database	0.003610
describe a	0.166667
within documents	0.055556
latent semantic	1.000000
A popular	0.020000
slot	0.000029
weapons	0.000029
Other tasks	0.142857
intrinsic and	0.250000
Weaver wrote	1.000000
Yes\/No vs.	1.000000
<s> Multilingual	0.000769
digitize	0.000029
computers to	0.111111
-- discourse	0.040000
score if	0.166667
settings	0.000029
have taken	0.009615
syntactic features	0.076923
when inter-annotator	0.028571
for without	0.003610
their translation	0.029412
from Fully	0.009615
relevance theory	0.333333
expended to	1.000000
consecutive years	0.500000
new wave	0.041667
example The	0.012346
smaller lexical	0.142857
rule-based and	0.142857
QA It	0.047619
Bush 's	0.500000
created rules	0.142857
segmentation that	0.030303
<s> Schools	0.000769
be selected	0.004219
gets about	0.500000
Pang showed	0.333333
One approach	0.076923
personal digital	0.250000
Bush ''	0.500000
specialised document	0.500000
The management	0.005208
large amount	0.043478
process Main	0.027778
measure than	0.090909
world with	0.066667
generation techniques	0.111111
Comparing	0.000029
measure that	0.090909
transformations .	0.500000
NLP comprises	0.021277
graph using	0.076923
still ''	0.066667
observe patterns	1.000000
limited amounts	0.100000
evaluation might	0.018519
meeting summarization	1.000000
G-loads	0.000029
, LexRank	0.000561
context-free approximation	0.090909
coughing	0.000029
Additional aspects	1.000000
Coreference resolution	1.000000
lexicon reached	0.111111
approach has	0.028571
called ISO\/TC37\/SC4	0.055556
relic	0.000029
highest ROUGE-1	0.333333
hurts ''	0.500000
.5 decision	1.000000
learn from	0.076923
by looking	0.005714
formalism	0.000029
corpus as	0.032258
considered .	0.111111
, Adam	0.000561
is seen	0.002033
Although it	0.125000
Naive Bayes	1.000000
stage using	0.200000
`` random	0.005291
of Generation	0.000891
identities of	1.000000
the distinctive	0.000692
considered a	0.111111
recognizers have	0.500000
milliseconds .	0.500000
new ,	0.041667
the special	0.000692
option .	1.000000
distinct vowels	0.142857
Pennsylvania in	1.000000
geological	0.000029
particularly difficult	0.200000
publications .	1.000000
1977 -RRB-	1.000000
the broken	0.000692
to direct	0.001328
by which	0.005714
equal to	1.000000
marker vs.	1.000000
transcended	0.000029
sampling	0.000029
from 10,000	0.009615
occur together	0.200000
parsing accuracy	0.035714
and simulation	0.001445
primarily by	0.500000
levels as	0.045455
speaking computer	0.125000
so forth	0.033333
is copied	0.002033
entered the	0.500000
such accuracy	0.008130
objectives of	0.500000
Ratliff	0.000029
each dictionary	0.022222
Rajman M.	1.000000
read aloud	0.142857
yet been	0.500000
<s> Last	0.000769
This includes	0.015873
gradually reduced	1.000000
`` features	0.005291
sub-field of	1.000000
been undertaken	0.014706
Message	0.000029
patterns would	0.200000
reflect a	1.000000
off-line	0.000029
not lead	0.008929
have shown	0.009615
ways in	0.125000
Collection	0.000029
tagset	0.000029
a classifier	0.001227
for Speech	0.003610
case-based	0.000029
complete	0.000029
SHRDLU ,	0.166667
Full of	1.000000
Research Institute	0.125000
capitalization may	0.333333
reasoned	0.000029
phrases that	0.062500
rules by	0.023256
expansion of	0.333333
also an	0.014493
linear-time	0.000029
word recognition	0.016667
in itself	0.001873
algorithm like	0.035714
noting that	1.000000
Howarth	0.000029
method and	0.062500
unigrams appear	0.083333
Systems corp.	0.083333
noun -LRB-	0.071429
Nunan ,	1.000000
that match	0.003546
graphs and	1.000000
or Auto	0.004505
to existing	0.001328
Once examples	0.200000
a team	0.001227
cases and	0.055556
intervention :	1.000000
splicing	0.000029
- not	0.062500
expensive task	0.142857
postal code	1.000000
by paying	0.005714
edges after	0.142857
Wodak	0.000029
the EARS	0.000692
undercarriage ,	1.000000
subjectivity\/objectivity	0.000029
commercial system	0.090909
1,500	0.000029
a Computer	0.001227
and composing	0.001445
computationally feasible	0.500000
the Sociologist	0.000692
points out	0.500000
Shallow parsing	0.500000
in supervised	0.001873
approach ;	0.028571
psychologist .	1.000000
dictionary-based machine	1.000000
`` entities	0.005291
developments of	0.333333
counselling -RRB-	1.000000
text map	0.006289
text may	0.006289
German and	0.250000
revealing	0.000029
complexity while	0.083333
be labeled	0.004219
results demonstrate	0.047619
, Ingria	0.000561
annual Document	0.500000
significant complexity	0.111111
first layer	0.030303
via	0.000029
5 %	0.500000
one that	0.015385
that attempt	0.003546
engines to	0.333333
containing several	0.125000
the peak	0.000692
: Natural	0.009804
that characterize	0.003546
adjust\/correct	0.000029
Content	0.000029
by standard	0.005714
be resolved	0.004219
late Claude	0.111111
and methods	0.001445
available and	0.058824
sent	0.000029
converts	0.000029
sailor !	0.200000
ACL Anthology	0.500000
vendors began	0.250000
from non	0.009615
generating too	0.200000
way --	0.041667
approach applies	0.028571
text used	0.006289
page count	0.142857
than has	0.022222
transducer ,	0.500000
, opens	0.000561
plant	0.000029
, science	0.000561
an action	0.007576
Teun A.	1.000000
12 categories	0.200000
checked each	0.500000
shop or	1.000000
out .	0.071429
is parsing	0.002033
includes mainly	0.142857
one according	0.015385
toolkit -RRB-	0.500000
, reading	0.000561
repetitive .	0.500000
currently require	0.142857
momentum for	1.000000
One might	0.076923
broad agreement	0.250000
database look-up	0.100000
helicopters is	0.500000
but those	0.014706
limiting the	1.000000
warped	0.000029
dynamic motion	0.200000
Convert chunks	0.500000
further speaker	0.125000
assumptions ,	0.200000
computer forecasts	0.022727
eigenvalue 1	1.000000
really	0.000029
features ?	0.038462
Ernesto Laclau	1.000000
to change	0.001328
accidentally omitted	1.000000
worked ,	0.200000
first approximation	0.030303
, engaging	0.000561
semiotic	0.000029
Some speech	0.047619
simple data	0.038462
represent as	0.111111
with boundary	0.005464
using unweighted	0.016949
a corporation	0.001227
Latin-script ,	1.000000
Charniak	0.000029
with having	0.005464
exhibited	0.000029
states that	0.250000
<s> Later	0.000769
should indicate	0.052632
human kind	0.021739
physicians who	1.000000
-LRB- Some	0.002710
approach described	0.028571
Street .	0.333333
College at	0.500000
natural -RRB-	0.013333
vocal	0.000029
hence need	0.500000
be put	0.004219
previous questions	0.333333
the bi-directional	0.000692
and dictionary-based	0.001445
is processed	0.002033
tasks implemented	0.031250
W. Handel	0.500000
mechanized sorting	1.000000
keyphrases will	0.028571
user has	0.071429
understood only	1.000000
In 1965	0.009524
selected as	0.500000
uses .	0.071429
JAS-39 Gripen	1.000000
speaker normalization	0.055556
Wikipedia 's	0.500000
out other	0.071429
Audio ,	0.500000
Jef Verschueren	1.000000
slow speech	0.500000
formalization of	0.500000
soon .	0.333333
total accuracy	0.500000
mentioned by	0.166667
creating systems	0.142857
lexical exigencies	0.076923
LexRank differences	0.083333
captures	0.000029
further condensation	0.125000
of ambitious	0.000891
a domain-specific	0.001227
many systems	0.019231
words to	0.009174
that deals	0.003546
makes intuitive	0.125000
systems existing	0.008929
-LRB- Nuance	0.002710
masculine ,	1.000000
Inter-rater	0.000029
`` open	0.005291
Liberman	0.000029
Examples include	0.333333
word sequences	0.016667
implemented ,	0.200000
Amplitude -LRB-	1.000000
underlie the	1.000000
Jan Blommaert	1.000000
basic level	0.076923
times in	0.200000
collections of	0.250000
`` training	0.005291
open-access	0.000029
superimpose	0.000029
linguistic competence	0.062500
<s> Scope	0.000769
These range	0.058824
are language-specific	0.004149
proved similarly	0.333333
, key	0.000561
useful review	0.071429
analyzing the	0.200000
as short	0.003484
Each word	0.166667
written without	0.038462
for using	0.003610
an automated	0.007576
publishing	0.000029
or electronic	0.004505
between successive	0.025641
an error	0.007576
it accepts	0.008547
Starting	0.000029
rescore lattices	1.000000
free as	0.250000
socio-psychological characteristics	1.000000
`` Dog	0.005291
optimization	0.000029
Brill 's	0.333333
forecasts from	0.200000
styles	0.000029
hoping	0.000029
producing more	0.333333
alphabetic heritage	1.000000
connected text	0.200000
triple	0.000029
Category :	0.500000
not context-free	0.008929
Category =	0.500000
place to	0.250000
while Carnegie	0.050000
computers for	0.111111
system using	0.010753
Hands-free	0.000029
has little	0.011905
types ,	0.071429
reporting -RRB-	0.333333
common ground	0.040000
unlabeled	0.000029
routing bar	0.333333
scientists ,	1.000000
Navigation Systems	1.000000
summers of	1.000000
randomly chosen	1.000000
choice between	0.125000
serve other	0.200000
engines such	0.333333
planning an	0.500000
Processes may	1.000000
somehow internalize	1.000000
to words	0.001328
garden path	1.000000
massive collections	1.000000
prune away	1.000000
extractor follows	0.500000
source .	0.041667
source -	0.041667
source ,	0.041667
constituents ,	0.500000
Coulthard	0.000029
linguistic research	0.062500
database available	0.100000
1933 -LRB-	1.000000
action applied	0.200000
WYSIWYM framework	1.000000
either positive	0.100000
trained on	0.333333
getting published	0.250000
, reasoning	0.000561
and Ken	0.001445
either an	0.100000
pertaining	0.000029
as Penn	0.003484
documents have	0.026316
Bar-Hillel	0.000029
volume and	0.250000
has gone	0.011905
broadband	0.000029
lexer would	1.000000
complex sounds	0.041667
Deirdre Wilson	1.000000
systems in	0.008929
performance only	0.055556
details the	0.500000
segmentation In	0.030303
2010 and	0.333333
technology also	0.045455
pre-process	0.000029
assertive -LRB-	1.000000
repeated as	0.500000
their similarity	0.029412
handheld scanner	1.000000
requires expansion	0.062500
called a	0.055556
spending	0.000029
-- in	0.040000
-RRB- work	0.002817
by question	0.005714
<s> Goldberg	0.000769
improved their	0.250000
temporal and	0.500000
Royal Aerospace	0.500000
Potentially ,	1.000000
pattern .	0.166667
that scans	0.003546
1960s were	0.333333
Office	0.000029
got about	1.000000
word of	0.016667
verification	0.000029
continuously	0.000029
Adda 1999	0.500000
Conference Evaluation	0.500000
frequently formalized	0.500000
translated in	0.250000
dependency theory	0.200000
translated it	0.250000
makes tagging	0.125000
relative probability	0.333333
, length	0.000561
invalid	0.000029
division of	0.500000
of translating	0.000891
Querying	0.000029
<s> Running	0.000769
select individual	0.166667
semantically constrained	1.000000
, Judith	0.000561
II -LRB-	0.500000
partial	0.000029
potentially unlimited	0.333333
most suitable	0.017241
now rely	0.076923
also Machine	0.014493
centers	0.000029
a startlingly	0.001227
Michael Schober	0.250000
reasonable chance	0.500000
reCAPTCHA	0.000029
checking that	1.000000
utterance and	0.333333
continues	0.000029
printed by	0.083333
, tag	0.000561
voice than	0.076923
negligibly rare	1.000000
two extremes	0.034483
Post has	0.500000
language with	0.006757
program with	0.045455
observation .	1.000000
be digitalized	0.004219
in simple	0.001873
look ''	0.200000
by Henry	0.005714
significant task	0.111111
ATC -RRB-	0.200000
proliferation	0.000029
any markup	0.032258
respectively	0.000029
for American	0.003610
, turns	0.000561
, explanation	0.000561
of 1928	0.000891
IR -RRB-	0.333333
<s> Imagine	0.000769
numbers which	0.142857
proposed by	0.111111
1999 L'action	0.500000
or desired	0.004505
topic by	0.125000
weaker	0.000029
candidates so	0.200000
to bridge	0.001328
practically available	1.000000
best path	0.055556
Lakoff	0.000029
-- is	0.040000
outputting language	0.500000
were printed	0.024390
svg This	1.000000
experiment in	0.200000
then use	0.028571
Wallace Chafe	1.000000
successive words	0.500000
Iraq in	0.500000
or Spanish	0.004505
recognition-related	0.000029
Therein	0.000029
prefer the	0.500000
pour	0.000029
entries for	0.500000
knowledge frequently	0.037037
you must	0.076923
can often	0.005525
pieces	0.000029
as semantic	0.003484
Christmas	0.000029
a character	0.001227
Extraction techniques	0.333333
art for	0.500000
characterised by	1.000000
tied	0.000029
separators -RRB-	1.000000
left ,	0.166667
processed documents	0.166667
on personal	0.004717
Apple	0.000029
<s> Beatrice	0.000769
earliest-used machine	0.500000
redundant	0.000029
substantial financial	0.200000
male-female normalization	1.000000
comprehension ,	0.142857
democracy .	1.000000
something similar	1.000000
, styles	0.000561
high as	0.055556
high at	0.055556
example-generation strategy	1.000000
a readable	0.001227
are unable	0.004149
In information	0.009524
<s> Was	0.000769
Speech When	0.032258
see references	0.050000
separators	0.000029
must appear	0.071429
parsing refers	0.035714
function words	0.125000
contrast -RRB-	0.125000
translating .	0.250000
parser attempts	0.062500
are focused	0.004149
achieving high	0.500000
Processing -RRB-	0.250000
static	0.000029
-LRB- Meehan	0.002710
consideration the	0.333333
problem was	0.022727
output -RRB-	0.038462
comprising context	0.500000
if and	0.035714
the accompanying	0.000692
and Callaghan	0.001445
an instance	0.007576
statistical ;	0.030303
East Asian	1.000000
lexer	0.000029
Jump	0.000029
phrase begin	0.100000
apparent	0.000029
even articles	0.037037
with his	0.005464
ATC situation	0.200000
digital camera	0.142857
bites man	0.333333
stems in	0.500000
2 ''	0.200000
phrases supported	0.062500
Use of	0.500000
famous article	0.333333
Workshop	0.000029
radiology	0.000029
Voice2Go	0.000029
capital letters	0.333333
with thought-to-paper	0.005464
language comprehension	0.006757
the impossibility	0.000692
showed how	0.250000
large amounts	0.043478
sentences instead	0.013158
more principled	0.010526
Penpoint OS	1.000000
Descartes	0.000029
Homayoon Beigi	1.000000
obtained .	0.142857
texts from	0.058824
fairly simple	0.250000
it in	0.008547
atmosphere	0.000029
this example	0.010989
terminate	0.000029
to clarify	0.001328
gaming and	1.000000
restrictions .	1.000000
The CyberEmotions	0.005208
difficult ,	0.035714
`` shallow	0.005291
domains where	0.125000
Terry Winograd	1.000000
e.g. stating	0.017857
emigre Leo	1.000000
transmitting by	1.000000
<s> Performing	0.000769
polynomial time	1.000000
to digitize	0.001328
the form	0.000692
Polar Lander	1.000000
currently .	0.142857
intervening	0.000029
of complexity	0.000891
The algorithm	0.005208
individual words	0.083333
ATN -RRB-	1.000000
untrained on	1.000000
standard method	0.071429
where phrases	0.028571
other modifying	0.014286
`` Translation	0.005291
closed-domain	0.000029
named Interspeech	0.142857
e.g. yes-no	0.017857
found by	0.071429
same person	0.040000
their underlying	0.029412
original source	0.076923
he talking	0.142857
equivalent ideas	0.200000
<s> Among	0.000769
edge between	0.333333
<s> Example-based	0.000769
and obtained	0.001445
and Semantic	0.001445
not 100	0.008929
: David	0.009804
causes a	1.000000
of phrase	0.000891
preliminary approach	0.333333
accuracy in	0.032258
offering WebOCR	1.000000
question classifier	0.023810
Verschueren ,	1.000000
modeling and	0.142857
's opinions	0.019608
start to	0.142857
article such	0.034483
cope	0.000029
by Xuedong	0.005714
and syntax	0.001445
phrases to	0.062500
conflicting	0.000029
upon	0.000029
formalized in	1.000000
Eurospeech\/ICSLP	0.000029
points of	0.500000
expand	0.000029
which he	0.007246
mark the	0.333333
Command Success	0.500000
Challenges	0.000029
costs -LRB-	1.000000
b -RRB-	1.000000
this book	0.010989
parsers were	0.076923
negligence	0.000029
it about	0.008547
separate field	0.100000
Callaghan	0.000029
lattice	0.000029
the 70	0.000692
coordinates and	1.000000
or quantities	0.004505
programs have	0.090909
human geography	0.021739
pioneered at	0.333333
supervised extractive	0.062500
his visit	0.083333
an era	0.007576
<s> Important	0.000769
quality and	0.100000
included as	0.125000
helps doctors	0.500000
only rely	0.026316
sufficiently	0.000029
and corrected	0.001445
democratizing data	0.500000
Harrison P.	1.000000
Cognitive Systems	0.333333
resources it	0.166667
of cepstral	0.000891
noun than	0.071429
metrics used	0.111111
and typical	0.001445
garden-path sentences	1.000000
often used	0.022727
articles ,	0.125000
often uses	0.022727
computerized language	0.500000
waves are	0.142857
from systems	0.009615
NLP and	0.021277
about 30	0.025000
Network	0.000029
speech commands	0.006579
paper -RRB-	0.090909
networks can	0.071429
The Army	0.005208
emails and	0.500000
potentially exponential	0.333333
roughness ,	1.000000
components .	0.200000
this level	0.010989
the food	0.000692
together ?	0.125000
together ,	0.125000
together .	0.125000
disagree that	0.333333
incorrect letters	0.333333
unstructured text	1.000000
is leading	0.002033
several quality	0.045455
very preliminary	0.024390
global '	0.333333
be either	0.004219
scholars have	0.500000
chance	0.000029
requires one	0.062500
Context	0.000029
<s> By	0.000769
above are	0.076923
shallow methods	0.166667
main ideas	0.125000
As the	0.055556
what original	0.031250
then compute	0.028571
global `	0.333333
Subsumption -LRB-	1.000000
star scale	0.500000
votes	0.000029
much less	0.045455
Independent ''	1.000000
relic of	1.000000
wave as	0.111111
enough for	0.200000
eliminate redundancy	0.500000
have human-made	0.009615
retrieval -LRB-	0.142857
used varies	0.008850
when annotating	0.028571
time question	0.030303
a rules	0.001227
and if	0.001445
Technology -LRB-	0.333333
often continues	0.022727
at hand	0.014706
Home	0.000029
Digitize the	1.000000
a degree	0.001227
NIST 's	0.500000
that aid	0.003546
PARRY	0.000029
review as	0.333333
garden-path	0.000029
as WordNet	0.003484
Star	0.000029
substitutions	0.000029
example is	0.012346
Meaningful Use	1.000000
training organizations	0.035714
`` words	0.005291
LexRank score	0.083333
Smartphones	0.000029
supported by	1.000000
of smoothing	0.000891
look -LRB-	0.200000
been developed	0.014706
input with	0.024390
1629	0.000029
style and	0.500000
copied despite	0.500000
an abbreviation	0.007576
neat ,	1.000000
LILOG ,	0.500000
a kind	0.001227
cited	0.000029
the generation	0.000692
groups at	0.200000
hyphenated	0.000029
simple demonstrations	0.038462
Digital	0.000029
Deese	0.000029
known word	0.038462
exponential number	0.500000
into readable	0.012821
disappear	0.000029
machine reading	0.012658
just robustness	0.111111
can start	0.005525
user-specified fraction	0.500000
Frost ,	1.000000
difficulties in	0.500000
1928 the	1.000000
data of	0.012987
Software -LRB-	0.500000
and both	0.001445
data on	0.012987
address of	0.250000
According to	1.000000
being developed	0.055556
accurately -LRB-	0.500000
parameter estimation	1.000000
linguistic typology	0.062500
theory of	0.076923
special image	0.200000
or speech	0.004505
an EMR	0.007576
terms in	0.076923
As access	0.055556
cursive text	0.200000
talking about	1.000000
mid-90s .	1.000000
eventually	0.000029
languages contain	0.020000
, generally	0.000561
chance of	1.000000
Control	0.000029
recognition but	0.008264
particularly speech	0.200000
The poor	0.005208
search corpus	0.090909
science convention	0.100000
structuring :	1.000000
prior attempts	0.333333
integrating speech	1.000000
items .	0.500000
for any	0.003610
static shape	1.000000
published his	0.142857
which accepts	0.007246
on lexicon	0.004717
evaluation approach	0.018519
Inuit virtually	1.000000
Naturally	0.000029
grammar can	0.027027
Loriot &	1.000000
Art Graesser	1.000000
<s> Beginning	0.000769
particular words	0.076923
parsing have	0.035714
businesses look	0.500000
done both	0.090909
a subsystem	0.001227
is because	0.002033
within their	0.055556
dimensionality reduction	1.000000
rated	0.000029
developing text	0.250000
and Nearest-neighbor	0.001445
predicted value	0.500000
the media	0.000692
sequences ,	0.111111
grammar that	0.027027
into methods	0.012821
tackles	0.000029
that underlies	0.003546
; Computed	0.021277
rewrite	0.000029
, plural	0.000561
Like the	0.500000
network to	0.166667
`` main	0.005291
Garfinkel	0.000029
to low	0.001328
Kittredge &	0.500000
both research	0.032258
concerns finding	0.500000
recognized essentially	0.166667
some summarization	0.012048
Error Rate	0.500000
, Winograd	0.000561
-LRB- semi	0.002710
effective and	0.166667
Statistical natural-language	0.111111
' could	0.052632
though this	0.100000
optimizes	0.000029
poorly defined	1.000000
William A.	0.500000
structured speech	0.166667
optimized	0.000029
phase	0.000029
stating that	1.000000
his wingmen	0.083333
than in	0.022222
evaluation process	0.018519
had to	0.071429
or generated	0.004505
automatizing the	1.000000
Helicopters	0.000029
Automatic translation	0.111111
two conflicting	0.034483
ParaEval -RRB-	1.000000
effectively launched	0.333333
CKY	0.000029
called Cross-Sentence	0.055556
and right-most	0.001445
universal ''	0.333333
preferred	0.000029
1993 there	0.333333
been parse	0.014706
the proliferation	0.000692
, highly-specialized	0.000561
classifier ,	0.142857
Trek .	1.000000
erroneous	0.000029
, Jay	0.000561
Apparatus	0.000029
technique used	0.142857
observed	0.000029
analytics	0.000029
, Jan	0.000561
technique uses	0.142857
repeated relations	0.500000
Auto	0.000029
includes a	0.142857
Technologies	0.000029
A precise	0.020000
-- makes	0.040000
manually created	0.250000
Segmentation ,	1.000000
charge services	1.000000
databases as	0.125000
produced like	0.111111
Handwriting recognition	1.000000
Maximal Marginal	1.000000
driving social	1.000000
topic -RRB-	0.125000
to cope	0.001328
Maximal	0.000029
But the	0.166667
markers ,	0.333333
markers .	0.333333
representation framework	0.052632
applying a	0.250000
concerning	0.000029
candidacies	0.000029
He then	0.125000
application where	0.071429
by periods	0.005714
Communication	0.000029
said with	1.000000
ambiguity ''	0.125000
eigenvector corresponding	0.500000
the jet	0.000692
interjection .	1.000000
successful for	0.111111
lacks pre-existing	1.000000
evaluating automatically	0.200000
Around	0.000029
, nasality	0.000561
avoids	0.000029
taxonomies	0.000029
well enough	0.035714
's polarity	0.019608
field within	0.037037
resource -LRB-	0.200000
and Romanseval	0.001445
`` an	0.005291
interaction ,	0.125000
linguistically meaningful	1.000000
its component	0.028571
centres	0.000029
are words	0.004149
pronouns with	0.500000
quoted	0.000029
generated is	0.066667
probabilities not	0.090909
a stochastic	0.001227
rules should	0.023256
recogniton by	0.500000
capturing data	1.000000
using machine	0.016949
is contrast	0.002033
approach was	0.028571
makes sense	0.125000
study language	0.250000
fusion	0.000029
accuracies in	1.000000
command centres	0.500000
sounds :	0.066667
Part-of-Speech Tagset	1.000000
a skilled	0.001227
sounds .	0.066667
consumed from	1.000000
He pointed	0.125000
frequency -LRB-	0.500000
Head-driven	0.000029
applications Aerospace	0.040000
humor	0.000029
rule-based methods	0.142857
a learner	0.001227
Imagine you	1.000000
, largely	0.000561
marketing	0.000029
customize OCR	0.500000
backup methods	1.000000
National Corpus	0.333333
: Stemming	0.009804
to apply	0.001328
them but	0.052632
with Optical	0.005464
of rocks	0.000891
POS -RRB-	0.076923
basic OCR	0.076923
theorists	0.000029
uses -LRB-	0.071429
Matches	0.000029
deaf	0.000029
wave which	0.111111
searching -LRB-	0.333333
contains only	0.100000
and hearings	0.001445
components operating	0.200000
easily as	0.111111
list ,	0.090909
boundaries of	0.090909
; By	0.021277
multileveled	0.000029
TWA	0.000029
to Australia	0.001328
be keyphrases	0.004219
abstract	0.000029
more effectively	0.010526
of how	0.000891
training systems	0.035714
general software	0.045455
A simplified	0.020000
research focus	0.023810
can discriminate	0.005525
very rare	0.024390
Windows	0.000029
Later	0.000029
The sentences	0.005208
an inseparable	0.007576
on absorbing	0.004717
will never	0.028571
steer-point	0.000029
parser can	0.062500
switched	0.000029
To avoid	0.111111
rise to	0.500000
a pre-existing	0.001227
requirements of	0.500000
and `	0.001445
This makes	0.015873
an isolated	0.007576
redundancy .	0.333333
<s> NLP	0.000769
select keyphrases	0.166667
involved in	0.166667
and 2	0.001445
different issue	0.020408
pre -	1.000000
Conversation analysis	1.000000
two levels	0.034483
CoNLL	0.000029
his PhD	0.083333
to market	0.001328
Current research	0.200000
Corporation and	0.250000
other terms	0.014286
George	0.000029
undertaken to	0.500000
SVM ,	1.000000
discover	0.000029
Given an	0.071429
also general	0.014493
only Wikipedia	0.026316
assistance	0.000029
debated	0.000029
corpus denote	0.032258
coarse-grained relations	1.000000
any feedback	0.032258
subdivided	0.000029
of sounds	0.000891
even allows	0.037037
to capture	0.001328
or phones	0.004505
machines or	0.250000
IMR during	0.500000
Deaf	0.000029
basic categories	0.076923
especially statistical	0.066667
process ``	0.027778
used together	0.008850
The Apple	0.005208
state automata	0.071429
Q&A systems	1.000000
Holmes ,	1.000000
marker	0.000029
assistance of	1.000000
and Intelligent	0.001445
be electronically	0.004219
from left	0.009615
usually are	0.031250
typically undirected	0.055556
ratings :	0.111111
travel .	1.000000
envelope	0.000029
data annotation	0.012987
ratings .	0.111111
ratings ,	0.111111
probable answer	1.000000
a plural	0.001227
software was	0.037037
, linear-time	0.000561
without much	0.076923
manipulate the	0.333333
SBD	0.000029
extractors are	1.000000
Walter	0.000029
voice-activation	0.000029
write	0.000029
modeling approach	0.142857
` kick	0.062500
, except	0.000561
a simple	0.001227
Health Record	0.500000
are parsed	0.004149
recognition problems	0.008264
phonetic segmentation	0.500000
, grounded	0.000561
into intrinsic	0.012821
: List	0.009804
individual trained	0.083333
process automatic	0.027778
was most	0.012987
ELIZA worked	0.111111
choice in	0.125000
breaks are	0.500000
way sentiment	0.041667
be produced	0.004219
retrieving information	1.000000
as researchers	0.003484
translation Machine	0.013514
disparate	0.000029
and practical	0.001445
scaling	0.000029
superset	0.000029
discuss	0.000029
movie together	0.333333
the attitude	0.000692
into several	0.012821
; Given	0.021277
four words	0.142857
tries to	1.000000
convention in	1.000000
than extraction	0.022222
: objective	0.009804
accomplish	0.000029
disabilities People	0.250000
rates .	0.125000
function is	0.125000
assistant providing	1.000000
work progressed	0.041667
Asia Online	1.000000
future .	0.333333
and graphics	0.001445
emotional state	0.250000
Laclau ,	1.000000
-LRB- 1954	0.002710
mean word	0.500000
apply increasingly	0.200000
flying	0.000029
Languages like	0.333333
variables	0.000029
for health	0.003610
were able	0.024390
-LRB- Carbonell	0.002710
not absolutely	0.008929
Walter Kintsch	1.000000
, rule-based	0.000561
trigram found	0.333333
Noun	0.000029
Standardization	0.000029
some writing	0.012048
1,500 documents	1.000000
the sense	0.000692
manual evaluation	0.500000
reputations .	1.000000
switched to	1.000000
categorical	0.000029
allow for	0.200000
characterize keyphrases	0.500000
accordance	0.000029
template ,	0.250000
a professor	0.001227
template .	0.250000
semantics is	0.071429
corpora specifically	0.090909
other work	0.014286
of adaptive	0.000891
Handbook	0.000029
other word	0.014286
programming algorithms	0.200000
societal problem	1.000000
restricted ``	0.250000
join different	1.000000
which undertook	0.007246
distinguishes these	0.500000
the opinion	0.000692
nuances	0.000029
country into	0.250000
mostly work	0.500000
Deese ,	1.000000
dried up	1.000000
uses stochastic	0.071429
doing extensive	0.500000
to foster	0.001328
within different	0.055556
k -RRB-	1.000000
professional	0.000029
high .	0.055556
high ,	0.055556
subject to	0.125000
typical features	0.111111
was LILOG	0.012987
disambiguation often	0.100000
about pronouns	0.025000
way and	0.041667
been much	0.014706
primary topics	0.500000
title	0.000029
Janet Holmes	0.500000
1981 -RRB-	1.000000
Vulcan program	0.500000
the simulation	0.000692
moved across	1.000000
with such	0.005464
EVALITA web	0.500000
active research	0.500000
better QA	0.111111
the potentially	0.000692
Aerospace Establishment	0.500000
not predict	0.008929
, pitch	0.000561
without it	0.076923
studying the	1.000000
the microphone	0.000692
However the	0.027027
or insufficient	0.004505
assigning the	1.000000
purpose at	0.200000
labeled keyphrases	0.333333
are provided	0.004149
highlighting candidate	1.000000
lexicon and	0.111111
summarization works	0.020000
and Subjectivity	0.001445
, biographical	0.000561
OCR Software	0.020408
highly by	0.111111
in political	0.001873
translation by	0.013514
gone into	1.000000
returns text	1.000000
databases and	0.125000
knowledge bases	0.037037
<s> Future	0.000769
over 95	0.083333
be learned	0.004219
pruned	0.000029
Few assumptions	1.000000
low precision	0.333333
cares	0.000029
skew	0.000029
-RRB- automatically	0.002817
VITO Voice2Go	1.000000
especially to	0.066667
done using	0.090909
phonetically different	1.000000
musical notations	1.000000
when deployed	0.028571
Kenneth	0.000029
to ensure	0.001328
analyzed using	0.200000
POS-taggers ,	1.000000
overload has	1.000000
sometimes provided	0.076923
rank individual	0.166667
by programs	0.005714
<s> increases	0.000769
adding citations	0.500000
English verbs	0.027027
investigates	0.000029
keyphrases your	0.028571
in processing	0.001873
abstraction can	0.250000
people or	0.062500
SATZ	0.000029
level we	0.050000
or millions	0.004505
varied from	1.000000
Parsers are	0.500000
competence ,	1.000000
latter as	1.000000
popular media	0.111111
level 7	0.050000
level 6	0.050000
level .	0.050000
each time	0.022222
this prior	0.010989
, Phrases	0.000561
ICR software	0.333333
David R.	0.250000
there would	0.025000
which draws	0.007246
those proved	0.045455
the tagset	0.000692
Vocalizations	0.000029
positive -RRB-	0.142857
teams to	0.500000
, business	0.000561
This has	0.015873
sound input	0.050000
The acoustic	0.005208
upper-case	0.000029
symbolic representation	1.000000
achieves 98.5	0.500000
Cross-Sentence	0.000029
still the	0.066667
be combined	0.004219
heuristics to	0.500000
1933	0.000029
1935	0.000029
final stage	0.111111
difficult process	0.035714
represent varies	0.111111
, V.J.	0.000561
constructs -LRB-	0.333333
processor	0.000029
content that	0.083333
harder tasks	0.142857
systems trade	0.008929
Brill Tagger	0.333333
larger source	0.062500
elementary	0.000029
-RRB- evaluation	0.002817
periods can	0.333333
an image	0.007576
assumed	0.000029
verbal unit	1.000000
challenge in	1.000000
or component	0.004505
faster computers	0.333333
, proper	0.000561
grammatical information	0.090909
to Iraq	0.001328
to build	0.001328
appliance	0.000029
and Rubin	0.001445
were conducted	0.024390
tones	0.000029
also marked	0.014493
found Intelligent	0.071429
A promising	0.020000
Bottom-up	0.000029
above text	0.076923
Training for	0.500000
the parse	0.000692
advanced -LRB-	0.200000
Coreference	0.000029
having the	0.200000
in our	0.001873
Lao	0.000029
from floods	0.009615
<s> Essentially	0.000769
delimited -LRB-	0.250000
about any	0.025000
documents containing	0.026316
valid	0.000029
Law	0.000029
software Current	0.037037
including morphemes	0.071429
, Harvey	0.000561
PangeaMT	0.000029
task should	0.023810
building	0.000029
condensation	0.000029
Sublanguage	0.000029
Spanish ,	0.500000
our learned	0.200000
many neighbors	0.019231
's intrinsic	0.019608
text categorization	0.006289
of freely	0.000891
workshops dedicated	0.500000
imprints for	1.000000
= common	0.111111
for triples	0.003610
training ;	0.035714
text based	0.006289
difficulties discussed	0.500000
and actioning	0.001445
can find	0.005525
Eight	0.000029
world applications	0.066667
objects -LRB-	0.200000
<s> Basic	0.000769
systems become	0.008929
grid &	1.000000
Amount	0.000029
-LRB- VITO	0.002710
securely	0.000029
integration with	1.000000
in of	0.001873
emotions in	1.000000
Norman ,	0.500000
is facing	0.002033
genre and	0.500000
in texts	0.001873
discourse Political	0.027778
units as	0.142857
processor speeds	1.000000
casual	0.000029
the pilot	0.000692
emotions	0.000029
ostensibly simple	1.000000
simple rules	0.038462
collaborated to	1.000000
analyzed for	0.200000
A similar	0.020000
problem can	0.022727
with implicit	0.005464
edited	0.000029
by Frederick	0.005714
1949 RCA	0.500000
questions -LRB-	0.038462
best ,	0.055556
a useful	0.001227
Chinese and	0.142857
been operated	0.014706
trainer	0.000029
important parts	0.062500
installed defective	0.333333
trainee	0.000029
and possibly	0.001445
intent .	1.000000
which arise	0.007246
and labor	0.001445
get this	0.142857
consumption -RRB-	1.000000
-LRB- subject	0.002710
Association for	1.000000
language output	0.006757
, opened	0.000561
A problem	0.020000
included in	0.125000
optimistic	0.000029
the harmonic	0.000692
Press ''	1.000000
computerized text	0.500000
program may	0.045455
Acoustical signals	0.500000
the behavior	0.000692
communication studies	0.200000
left-most derivations	0.500000
are presented	0.004149
, merging	0.000561
the linguistic	0.000692
tries	0.000029
syntax effectively	0.090909
the overriding	0.000692
voice-activation ,	1.000000
language system	0.006757
, annotation	0.000561
it -RRB-	0.008547
committed	0.000029
of man-hours	0.000891
simple tasks	0.038462
documents generally	0.026316
solving	0.000029
of reviews	0.000891
Putting	0.000029
learning problem	0.023256
-- thus	0.040000
since the	0.100000
4-gram matching	1.000000
to finding	0.001328
decimal	0.000029
Activity -LRB-	1.000000
relating to	1.000000
Master lead-in	1.000000
optimal match	1.000000
and Janet	0.001445
can deal	0.005525
steered	0.000029
counterparts in	1.000000
languages See	0.020000
deep ''	0.142857
classification indicates	0.058824
the suffix	0.000692
human assessments	0.021739
According	0.000029
notably successful	0.333333
; later	0.021277
with manually	0.005464
LexRank and	0.083333
domain posed	0.050000
interact	0.000029
inter-texual and	0.500000
hypothesis ``	1.000000
Lander used	0.500000
robotic	0.000029
descriptive tags	0.333333
where only	0.028571
provide summaries	0.166667
Improved	0.000029
accuracy can	0.032258
criterion depends	0.500000
started around	0.250000
ARNS	0.000029
150 examples	0.500000
shallowest	0.000029
singular proper	0.250000
translate spoken	0.166667
sentenced	0.000029
re-encode	0.000029
example where	0.012346
and Audio	0.001445
only of	0.026316
that operated	0.003546
, ratings	0.000561
Users	0.000029
NLP Main	0.021277
because punctuation	0.033333
proposed what	0.111111
`` understand	0.005291
parsing a	0.035714
phrase How	0.100000
changed direction	0.500000
degree -LRB-	0.166667
Arabic -RRB-	0.250000
-RRB- --	0.002817
dictation system	1.000000
not necessary	0.008929
critical new	0.250000
retrieval or	0.142857
declaration of	1.000000
classifiers make	0.500000
English sentences	0.027027
Language as	0.083333
did exactly	0.200000
Discontinuous or	1.000000
Trained linguists	1.000000
MT -LRB-	0.200000
very deep	0.024390
takes the	0.333333
previous Section	0.333333
and answered	0.001445
into subfields	0.012821
a factory	0.001227
specific to	0.047619
are starting	0.004149
not trivial	0.008929
linguistic way	0.062500
and conversations	0.001445
significant increase	0.111111
semantic from	0.047619
<s> Human-machine	0.000769
captioning ,	1.000000
rooms ,	1.000000
probable	0.000029
intelligence .	0.125000
intelligence ,	0.125000
-LRB- December	0.002710
has grown	0.011905
measure -LRB-	0.090909
The software	0.005208
natural summaries	0.013333
Hirschman L.	0.500000
You are	1.000000
structure The	0.083333
resolve .	0.250000
large-scale	0.000029
PC history	0.250000
2010 ?	0.333333
popular being	0.111111
as Scansoft	0.003484
, NN	0.000561
, NP	0.000561
Merging of	1.000000
speech there	0.006579
media .	0.166667
and characterizes	0.001445
others more	0.083333
and interactive	0.001445
determination	0.000029
since 1971	0.100000
Su ,	1.000000
popular evaluation	0.111111
because longer	0.033333
recognized words	0.166667
phoneme ,	0.500000
many artificial	0.019231
message boards	0.500000
The attitude	0.005208
informatics .	1.000000
FAS	0.000029
tell whether	0.333333
, Petrov	0.000561
group developed	0.250000
<s> Paul	0.000769
the introduction	0.000692
analysis systems	0.015385
learned .	0.200000
remains a	0.250000
text contains	0.006289
judgments	0.000029
classifying short-time	0.200000
Bernard	0.000029
complex recognition	0.041667
corpus contains	0.032258
CCD	0.000029
language from	0.006757
using database	0.016949
two distinctive	0.034483
wrote The	0.166667
common-sense reasoning	1.000000
undertaken ,	0.500000
Administration ,	1.000000
decode the	1.000000
Ochs ,	1.000000
M-346 Master	1.000000
translates	0.000029
Some unsupervised	0.047619
arbitrary new	0.333333
machines ,	0.250000
relations to	0.083333
improved .	0.250000
urgent	0.000029
evaluated ,	0.142857
evaluated .	0.142857
defined only	0.166667
warnings	0.000029
Several papers	0.333333
Apollo	0.000029
http:\/\/haydn.isi.edu\/ROUGE\/ -RRB-	1.000000
VTLN	0.000029
error analysis	0.083333
are Deaf	0.004149
and checked	0.001445
mid-1960s	0.000029
meanings ,	0.250000
summarization on	0.020000
than computers	0.022222
ASR .	0.166667
block	0.000029
Mutual	0.000029
problem setting	0.022727
using logical	0.016949
Google published	0.250000
could search	0.062500
was developed	0.012987
would expect	0.018868
Speech-to-text	0.000029
while ratings	0.050000
system such	0.010753
<s> About	0.000769
presence of	1.000000
properly .	0.500000
any kind	0.032258
computer process	0.022727
texts by	0.058824
standard expression	0.071429
intended semantic	0.200000
or disease	0.004505
'' about	0.005376
research devoted	0.023810
to current	0.001328
Intelligent Character	0.333333
alternative right-hand-sides	0.333333
ME -RRB-	0.500000
, Jim	0.000561
ontologies and	0.166667
a fast-evolving	0.001227
corpus -	0.032258
Polar	0.000029
use neural	0.013889
value is	0.333333
electrical	0.000029
word divider	0.016667
entities in	0.142857
not explicitly	0.008929
most commonly	0.017241
letters :	0.100000
Gender	0.000029
may blend	0.019231
ISRI	0.000029
discussed involve	0.142857
Romanseval campaigns	1.000000
practically	0.000029
passages .	0.500000
for reasons	0.003610
avoid	0.000029
that produce	0.003546
part-of-speech tag	0.066667
NLG summaries	0.047619
neural nets	0.066667
71 %	1.000000
the humanities	0.000692
cockpit ,	0.500000
unstructured	0.000029
umbrella term	1.000000
gender	0.000029
can prove	0.005525
focus and	0.142857
Information -LRB-	0.200000
computer-type	0.000029
is lessened	0.002033
Truecasing	0.000029
incorrect assignment	0.333333
are informative	0.004149
sentiment words	0.040000
term is	0.055556
them attractive	0.052632
translation simultaneously	0.013514
science and	0.100000
be thresholded	0.004219
best option	0.055556
use Machine	0.013889
an extension	0.007576
are written	0.004149
implicit assumptions	1.000000
all be	0.023256
cases -RRB-	0.055556
emigre	0.000029
boolean	0.000029
where one	0.028571
pioneered the	0.333333
: Content	0.009804
-LRB- Cullingford	0.002710
are by	0.004149
which used	0.007246
array .	1.000000
vehicle	0.000029
desired -RRB-	0.200000
is affected	0.002033
may use	0.019231
style ,	0.500000
grammar methods	0.027027
disabilities that	0.250000
verifying certain	1.000000
sent in	1.000000
between those	0.025641
2011 campaign	0.500000
Video	0.000029
keyphrase system	0.052632
expanded the	1.000000
dictation	0.000029
, neutral	0.000561
already published	0.200000
→ barmaid	0.333333
algorithms use	0.028571
of extracting	0.000891
onto its	1.000000
been characterized	0.014706
to tag	0.001328
on speaker	0.004717
<s> Turney	0.000769
<s> Translation	0.000769
finished writing	0.500000
disfluences	0.000029
it offered	0.008547
Wilson	0.000029
Phillips	0.000029
different relationships	0.020408
computer-understandable data	1.000000
Recently	0.000029
Wallace	0.000029
keep the	0.333333
optimized for	1.000000
an ''	0.007576
architecture uses	0.500000
ellipsis ,	1.000000
unseen data	1.000000
linked in	0.333333
hand-crafted rules	0.500000
solved .	0.200000
comparing the	0.500000
name and	0.200000
The combination	0.005208
more likely	0.010526
classification-related measure	1.000000
typology ,	1.000000
workload ,	1.000000
modules that	0.500000
on Reader	0.004717
absolutely necessary	1.000000
also referred	0.014493
ROUGE-1 is	0.200000
sense in	0.125000
dictator is	1.000000
strokes	0.000029
umbrella	0.000029
free speech	0.250000
linear transform	0.142857
-RRB- Speech	0.002817
and segment	0.001445
20,000	0.000029
Models are	0.333333
candidates ,	0.200000
eat ''	1.000000
solution can	1.000000
without significant	0.076923
mentioned in	0.166667
in universities	0.001873
, Marcus	0.000561
length cutoff	0.125000
level provides	0.050000
discards any	1.000000
spun it	1.000000
-RRB- ^	0.002817
- passage	0.062500
integrated into	0.333333
to computers	0.001328
with misspelled	0.005464
-LRB- essentially	0.002710
tools for	0.166667
limitation in	1.000000
be turned	0.004219
Richard	0.000029
marking up	0.500000
widely-reported news	1.000000
GPO -RRB-	1.000000
action of	0.200000
rule should	0.333333
<s> Results	0.000769
partially influenced	1.000000
Development	0.000029
microphone	0.000029
solely on	1.000000
pursued	0.000029
model avoids	0.033333
see context-free	0.050000
word problems	0.016667
-RRB- found	0.002817
different classes	0.020408
SATZ architecture	1.000000
a predefined	0.001227
government sponsored	0.333333
France installing	0.250000
spend much	1.000000
stems from	0.500000
machine that	0.012658
preceding token	1.000000
profiling for	1.000000
OnlineOCR practically	0.333333
to know	0.001328
lip-synch	0.000029
and shorter	0.001445
political negligence	0.333333
employed	0.000029
semantic parsing	0.047619
reading is	0.125000
dogs -RRB-	0.142857
same column	0.040000
final phase	0.111111
from has	0.009615
or formulaic	0.004505
human-ratings and	1.000000
and commercial	0.001445
a rule	0.001227
be -RRB-	0.004219
The choice	0.005208
function as	0.125000
use cepstral	0.013889
One could	0.076923
include stages	0.037037
short commands	0.125000
If web	0.100000
and minimum	0.001445
most NLP	0.017241
an infinitive	0.007576
that shift	0.003546
The earliest	0.005208
and etc.	0.001445
virtual currency	1.000000
feature is	0.076923
source materials	0.041667
been especially	0.014706
While LexRank	0.200000
in 1965	0.001873
in 1966	0.001873
: Dynamic	0.009804
knowledge sources	0.037037
harmonic	0.000029
NLP with	0.021277
advantages over	1.000000
was based	0.012987
assistants such	1.000000
translate five	0.166667
symbols or	0.333333
neutral .	0.500000
parse a	0.111111
then spoke	0.028571
evaluations such	0.166667
the 1970s	0.000692
This unreferenced	0.015873
improve document	0.076923
achieved only	0.100000
in word	0.001873
techniques can	0.043478
unsupervised and	0.125000
ASRU	0.000029
completion of	1.000000
any number	0.032258
algorithms fall	0.028571
discouraged	0.000029
precision .	0.200000
precision -	0.200000
is little	0.002033
as closed	0.003484
obstacles	0.000029
trade speed	0.500000
as 50	0.003484
social contexts	0.071429
attention ,	0.500000
automated semantic	0.142857
-RRB- refer	0.002817
will mention	0.028571
speech-to-text -RRB-	0.500000
language-specific	0.000029
`` Call	0.005291
used mostly	0.008850
burden	0.000029
, multilingual	0.000561
large quantity	0.043478
extracting meaningful	0.200000
B.	0.000029
the walk	0.000692
language sentences	0.006757
shed	0.000029
data which	0.012987
automated sentiment	0.142857
questioners	0.000029
taking a	0.200000
but triples	0.014706
SemEval	0.000029
for identifying	0.003610
that time	0.003546
implemented using	0.200000
LexRank was	0.083333
translator must	0.142857
camp is	0.250000
displaced by	1.000000
negative labels	0.125000
rule induction	0.333333
in ontologies	0.001873
the programs	0.000692
significant taggers	0.111111
computer user	0.022727
Company and	0.500000
Service has	1.000000
the filter	0.000692
R -RRB-	1.000000
vagueness of	1.000000
working out	0.142857
's informativeness	0.019608
to coherent	0.001328
input are	0.024390
Latin-script	0.000029
own ;	0.166667
duplicate typewritten	0.500000
signed	0.000029
and enterprise	0.001445
temporal dependencies	0.500000
majority of	1.000000
of document\/text	0.000891
the conversational	0.000692
spirit to	1.000000
Measuring	0.000029
Despite the	1.000000
heuristic post-processing	0.333333
distinguish from	0.200000
of effort	0.000891
Corpus of	0.062500
generally ,	0.090909
a pre-processing	0.001227
sharing one	1.000000
technology in	0.045455
required translation	0.142857
retrieval --	0.142857
They combine	0.333333
icon -RRB-	1.000000
developed transformational	0.038462
about 1,000,000	0.025000
attached ,	0.500000
`` polarity	0.005291
1,000 parts	0.500000
the reported	0.000692
preferable ,	1.000000
presents	0.000029
characterised	0.000029
updated	0.000029
connects	0.000029
text-to-speech technology	0.250000
the University	0.000692
structured databases	0.166667
only relief	0.026316
of telephony	0.000891
it generalizes	0.008547
a keyboard	0.001227
programs in	0.090909
with capitalization	0.005464
keyphrase to	0.052632
particular NLP	0.076923
states -RRB-	0.250000
of cursive	0.000891
discussing how	0.500000
qualitatively	0.000029
that describe	0.003546
are largely	0.004149
of developing	0.000891
warping Dynamic	0.250000
simplest -LRB-	1.000000
ever	0.000029
mechanical or	1.000000
and movie	0.001445
anthropology	0.000029
appear more	0.062500
Systran	0.000029
Ohio	0.000029
numeric scores	1.000000
certain patterns	0.142857
about NLP	0.025000
an attribute	0.007576
involves both	0.100000
components can	0.200000
sets -LRB-	0.090909
humans often	0.083333
electrical characteristics	1.000000
consistently available	0.333333
directly .	0.200000
most negative	0.017241
finished product	0.500000
other domains	0.014286
input character	0.024390
speech-enabled Symbian	1.000000
has received	0.011905
pro or	1.000000
any data	0.032258
area are	0.090909
human vocabularies	0.021739
or probabilities	0.004505
deemed the	0.500000
some detail	0.012048
classifier is	0.142857
Liu	0.000029
to minimize	0.001328
typewritten pages	0.200000
many languages	0.019231
, Gail	0.000561
page including	0.142857
with increasing	0.005464
a diverse	0.001227
Lancaster-Oslo-Bergen	0.000029
nodes that	0.142857
precise set	0.333333
All	0.000029
Civil	0.000029
surrounding consonants	0.200000
large corpora	0.043478
maintain	0.000029
single sentence	0.071429
ELIZA gained	0.111111
use the	0.013889
operations	0.000029
and common-sense	0.001445
considerable attention	0.200000
may fail	0.019231
Drew ,	1.000000
differently	0.000029
commercial systems	0.090909
Fighter Technology	1.000000
-LRB- ARRA	0.002710
have helped	0.009615
a past-tense	0.001227
we register	0.022222
a shortened	0.001227
, symbolic	0.000561
of traditional	0.000891
inserts	0.000029
successively	0.000029
technique referred	0.142857
hyphenated words	1.000000
principles	0.000029
Performance The	1.000000
principled	0.000029
she were	1.000000
Analysis Standardization	0.200000
by taking	0.005714
as subtasks	0.003484
`` advanced	0.005291
real-time character	0.500000
and naturalness	0.001445
denote abbreviations	0.500000
enumerate	0.000029
printed characters	0.083333
Both methods	0.333333
commonly tagged	0.125000
bootstrap using	1.000000
more corpus	0.010526
second edition	0.100000
phonemes -LRB-	0.166667
as within	0.003484
summarizing	0.000029
Klavans J.	1.000000
soon developed	0.333333
unlimited range	1.000000
generally refers	0.090909
same string	0.040000
for keyphrase	0.003610
on democratizing	0.004717
, emoticons	0.000561
question classification	0.023810
without a	0.076923
expect that	0.333333
overall system	0.166667
Paroubek P.	1.000000
and aircraft	0.001445
assign targets	0.200000
Frederick	0.000029
meaning from	0.043478
useful keyphrases	0.071429
: lexical	0.009804
difference was	0.250000
came into	0.500000
of 1,000	0.000891
graphics --	1.000000
there general	0.025000
Single	0.000029
search engine	0.090909
past decade	0.333333
walking slowly	0.333333
adding sentences	0.500000
perception that	0.500000
fixed schemata	0.500000
ending	0.000029
to examples	0.001328
a routing	0.001227
variously defined	1.000000
conference rooms	0.500000
are ambiguous	0.004149
Wendy Lehnert	1.000000
after 30	0.083333
can say	0.005525
compounded	0.000029
Nikolas Rose	1.000000
SYSTRAN	0.000029
specific letters	0.047619
and correctly-developed	0.001445
digits ``	1.000000
Amharic	0.000029
bag	0.000029
, employs	0.000561
requires citations	0.062500
way :	0.041667
correct according	0.066667
way ,	0.041667
Sydney	0.000029
identifiers .	1.000000
A series	0.020000
language model	0.006757
chain random	1.000000
further information	0.125000
C	0.000029
and morphology	0.001445
elaborate theories	1.000000
-RRB- vibration	0.002817
precise function	0.333333
human-ratings	0.000029
not map	0.008929
summarization program	0.020000
released speech	0.500000
, thanks	0.000561
The features	0.005208
<s> Unlike	0.000769
of tags	0.000891
it builds	0.008547
usually called	0.031250
C.	0.000029
Authorities in	1.000000
their answers	0.029412
find ways	0.076923
categories can	0.111111
that person	0.003546
C4	0.000029
-RRB- case	0.002817
although capitalization	0.166667
Meehan	0.000029
<s> Additional	0.000769
be -LRB-	0.004219
illustrates some	0.500000
what kinds	0.031250
ultraviolet light	1.000000
R. McDonald	0.166667
computer-generated weather	1.000000
, abstractive	0.000561
grown	0.000029
strategy gets	0.200000
overlap should	0.250000
McCarthy coined	1.000000
general ontologies	0.045455
fine-grained analysis	1.000000
that affective	0.003546
Users were	1.000000
`` Naturally	0.005291
algorithms differ	0.028571
this document	0.010989
The Archaeology	0.005208
overt	0.000029
1969 ,	0.500000
-LRB- transcription	0.002710
a roadmap	0.001227
-LRB- context-free	0.002710
parser that	0.062500
was first	0.012987
Analysis and	0.200000
in determining	0.001873
turn a	0.166667
is non-trivial	0.002033
Fully Automated	1.000000
not contain	0.008929
turn .	0.166667
turn ,	0.166667
while parsing	0.050000
What you	0.090909
human might	0.021739
, due	0.000561
Levenshtein	0.000029
Text Retrieval	0.166667
Corpus contains	0.062500
draws on	1.000000
Psycholinguists prefer	1.000000
changing information	1.000000
consult information	1.000000
integer ,	1.000000
multileveled pattern	1.000000
match between	0.166667
question-answering engines	0.500000
cognitive psychology	0.500000
Human-machine	0.000029
they superimpose	0.025000
also experimented	0.014493
complex expressions	0.041667
systems must	0.008929
, Ann	0.000561
qualitative automatic	0.500000
Shallow approaches	0.500000
Levinsohn	0.000029
also being	0.014493
2,000 words	0.500000
Hearing	0.000029
newspaper .	0.333333
reported there	0.200000
actual text	0.200000
indeed that	0.333333
speaker independent	0.055556
e.g. Chinese	0.017857
syntactic parsers	0.076923
with 12	0.005464
, distance	0.000561
centroid ''	0.500000
offering	0.000029
, Discontinuous	0.000561
matching the	0.200000
Z	0.000029
also needs	0.014493
-LRB- ISRI	0.002710
disabilities can	0.250000
II in	0.500000
6 over	0.250000
then with	0.028571
and funding	0.001445
the only	0.000692
stability in	1.000000
translation may	0.013514
appears several	0.200000
expansion Automated	0.333333
of sequential	0.000891
of patterns	0.000891
Unsupervised Morpheme	0.166667
, Robyn	0.000561
other forms	0.014286
are broken	0.004149
consider a	0.250000
With isolated	0.142857
mild	0.000029
, coughing	0.000561
preparation of	1.000000
Other taggers	0.142857
meaningful way	0.125000
Customized OCR	1.000000
variance on	1.000000
or sometimes	0.004505
applications discussed	0.040000
gold-standard	0.000029
the QA	0.000692
Force for	0.500000
about human	0.025000
die	0.000029
information overload	0.021739
the typical	0.000692
Efficient	0.000029
-LRB- sometimes	0.002710
, favor	0.000561
is reported	0.002033
the finite	0.000692
decelerations during	1.000000
than text	0.022222
assessed mainly	1.000000
achieve accuracy	0.500000
data to	0.012987
data records	0.012987
Rabinow .	1.000000
More complex	0.111111
avoiding linguistic	0.500000
hits than	1.000000
: Hidden	0.009804
history .	0.250000
Analysis of	0.200000
evaluation data	0.018519
flexibility	0.000029
calls instead	1.000000
ultimately want	1.000000
learn explicit	0.076923
rules defining	0.023256
the BLEU	0.000692
condition that	1.000000
Annual Test	1.000000
sharing	0.000029
Dependence	0.000029
form an	0.050000
Another term	0.076923
fly	0.000029
Pyramid	0.000029
data source	0.012987
Large-scale	0.000029
e.g. marking	0.017857
were repeatedly	0.024390
arrive	0.000029
claim	0.000029
`` create	0.005291
`` Computer	0.005291
at short	0.014706
went in	0.200000
, automates	0.000561
measured with	0.166667
in psycholinguistics	0.001873
critics	0.000029
Performing	0.000029
system selects	0.010753
sociolinguistics ,	0.500000
is expected	0.002033
this method	0.010989
for tense	0.003610
can aid	0.005525
other features	0.014286
gradual	0.000029
typically involve	0.055556
video ,	0.200000
argued	0.000029
digitize the	1.000000
hidden parts	0.125000
English like	0.027027
views	0.000029
<s> Encouraging	0.000769
current QA	0.142857
semiotics	0.000029
possess	0.000029
, education	0.000561
each document	0.022222
Business-card	0.000029
was delayed	0.012987
, selecting	0.000561
those it	0.045455
clear why	0.250000
Results	0.000029
field with	0.037037
-RRB- Video	0.002817
overlaps to	0.500000
FoG ,	0.500000
involve various	0.166667
use software	0.013889
and rule-based	0.001445
which associate	0.007246
undertook recognition	1.000000
second important	0.100000
taught to	0.333333
Microsoft Corporation	0.500000
and current	0.001445
Phrases ,	1.000000
paradigms .	1.000000
<s> because	0.000769
These results	0.058824
Pronunciation	0.000029
question-answering abilities	0.500000
un-supervised	0.000029
are grouped	0.004149
with adjacent	0.005464
the Ge'ez	0.000692
n Computer	0.500000
solve a	0.250000
nascent online	1.000000
character for	0.045455
user-provided	0.000029
word -RRB-	0.016667
input features	0.024390
questions have	0.038462
easily when	0.111111
, could	0.000561
word accuracies	0.016667
acquire basic	1.000000
Issues In	0.500000
demonstrates the	1.000000
backgrounds ,	1.000000
extraction algorithm	0.032258
right-hand-sides of	1.000000
green	0.000029
Du	0.000029
Weizenbaum between	0.333333
data has	0.012987
strengths of	0.500000
we think	0.022222
-LRB- this	0.002710
paper explored	0.090909
We apply	0.142857
tract	0.000029
surprising	0.000029
interest ,	0.090909
that read	0.003546
interest .	0.090909
gracefully	0.000029
analytics to	1.000000
Carbonell	0.000029
<s> Narrow	0.000769
Test	0.000029
more effective	0.010526
Importance of	1.000000
the Vulcan	0.000692
published but	0.142857
n-dimensional real-valued	1.000000
with isolated	0.005464
on work	0.004717
on word	0.004717
machine processes	0.012658
dictionary entry	0.142857
Turn	0.000029
and legal	0.001445
ears ,	1.000000
constructs -RRB-	0.333333
medial	0.000029
sounds representing	0.066667
both left-most	0.032258
or answers	0.004505
Parsing can	0.200000
languages was	0.020000
reveal that	1.000000
9 parts	1.000000
represents an	0.250000
dBase system	1.000000
forecast	0.000029
enumerated	0.000029
evidence of	0.500000
is entirely	0.002033
<s> Full	0.000769
modifying words	1.000000
that apply	0.003546
extremely expensive	0.250000
by deep	0.005714
considered as	0.111111
tagging include	0.040000
a flight	0.001227
of word-frequency	0.000891
considered an	0.111111
are concerned	0.004149
so simply	0.033333
ELIZA was	0.111111
well human-ratings	0.035714
much additional	0.045455
use either	0.013889
material .	0.500000
speech With	0.006579
unusual	0.000029
U.S. Department	0.142857
coupons	0.000029
-LRB- Black	0.002710
script used	0.250000
for modeling	0.003610
one video	0.015385
distinctive groups	0.500000
the water	0.000692
and assessing	0.001445
of Energy	0.000891
which consists	0.007246
decide :	0.250000
Thompson ,	1.000000
everyday	0.000029
<s> Front-End	0.000769
, call	0.000561
Two vertices	0.142857
multiscript	0.000029
get high	0.142857
the detection	0.000692
Commanders	0.000029
helped overall	0.333333
was historically	0.012987
markup	0.000029
by PageRank	0.005714
Scope	0.000029
of digital	0.000891
also terminate	0.014493
Margaret	0.000029
main drawback	0.125000
several summarization	0.045455
they think	0.025000
accurately if	0.500000
are too	0.004149
after stemming	0.083333
be weighted	0.004219
his or	0.083333
implicate	0.000029
interpretable	0.000029
technologies for	0.250000
is angry	0.002033
London	0.000029
to classify	0.001328
and eigenvector	0.001445
<s> Google	0.000769
-LRB- FAS	0.002710
usefully be	1.000000
systems however	0.008929
error-prone	0.000029
are generated	0.004149
fully articulated	0.166667
, style	0.000561
measuring	0.000029
moderate should	0.200000
notable	0.000029
splitting is	0.500000
dictionary or	0.142857
ten-year-long	0.000029
corpora such	0.090909
world of	0.066667
recognizing difficult	0.200000
for cartoon	0.003610
related information	0.066667
combining it	0.250000
systems :	0.008929
<s> Context	0.000769
Harold	0.000029
decode	0.000029
Obama	0.000029
-RRB- MorphoChallenge	0.002817
Extractor	0.000029
be similar	0.004219
language will	0.006757
knowledge representation	0.037037
takes as	0.333333
shallow .	0.166667
networks Main	0.071429
operation .	0.500000
than conversation	0.022222
Reiter and	1.000000
the volume	0.000692
area includes	0.090909
sample corpus	0.333333
retrained	0.000029
all quantitative	0.023256
in reconfiguring	0.001873
Commercial research	0.500000
require exponential	0.045455
account several	0.333333
word boundaries	0.016667
active area	0.500000
301 computer	1.000000
rise of	0.500000
feedback on	0.500000
any domain	0.032258
to wreck	0.001328
E-set :	1.000000
1930s .	1.000000
1952 and	0.500000
and Markov	0.001445
Given basic	0.071429
cheque -LRB-	1.000000
main knowledge	0.125000
each input	0.022222
several choices	0.045455
cut and	1.000000
straightforward	0.000029
to reformulate	0.001328
concatenating	0.000029
person was	0.052632
on Text	0.004717
most practical	0.017241
and became	0.001445
complex cognitive	0.041667
Whether a	0.500000
most text	0.017241
comparison uses	0.333333
contractions like	0.500000
instances ,	0.333333
movement	0.000029
<s> Language	0.000769
create tokens	0.058824
promising	0.000029
Puma helicopter	1.000000
speeches	0.000029
produced tones	0.111111
sentence-end	0.000029
rules from	0.023256
general speech	0.045455
especially inflectional	0.066667
candidates for	0.200000
the broadcast	0.000692
or indiscriminate	0.004505
e.g. transformational	0.017857
phonemes of	0.166667
slowly and	0.500000
start with	0.142857
, plus	0.000561
analog signal	0.500000
call routing	0.333333
usually not	0.031250
confusion with	1.000000
Aerospace -LRB-	0.500000
new sentences	0.041667
Ask.com	0.000029
More powerful	0.111111
every 10	0.333333
their effectiveness	0.029412
translation Main	0.013514
on Mandarin	0.004717
step towards	0.066667
multiple approaches	0.076923
predicate logic	1.000000
500,000 .	1.000000
the issues	0.000692
payments .	1.000000
graph would	0.076923
Lamb ,	1.000000
`` understanding	0.005291
often addressed	0.022727
compare automatic	0.142857
Products ,	0.500000
Lisp	0.000029
CLAWS pioneered	0.250000
is broad	0.002033
larger context	0.062500
would enable	0.018868
'' could	0.005376
recognition -RRB-	0.008264
are divided	0.004149
standard metric	0.071429
its nascent	0.028571
independent systems	0.500000
a security	0.001227
, aspect	0.000561
help blind	0.111111
very recent	0.024390
often and	0.022727
previously-written human	1.000000
for words	0.003610
helicopter pilot	0.250000
should we	0.052632
Potter	0.000029
generally evaluated	0.090909
abstraction involves	0.250000
ports	0.000029
subsystem	0.000029
sciences ,	0.500000
parsing input	0.035714
two summaries	0.034483
factory -RRB-	1.000000
user could	0.071429
an entire	0.007576
ambiguous word	0.083333
the realm	0.000692
takes into	0.333333
largely dependent	0.200000
machine ''	0.012658
contextual polarity	0.500000
language interface	0.006757
more formally	0.010526
some rules	0.012048
answered ,	0.200000
intelligence and	0.125000
could thus	0.062500
deep parsing	0.142857
performed an	0.100000
not included	0.008929
be generated	0.004219
RSI became	1.000000
phase is	1.000000
machine-learning-based implementation	1.000000
algorithms requires	0.028571
statement	0.000029
, How	0.000561
different levels	0.020408
criteria is	0.250000
positives by	1.000000
are important	0.004149
, followed	0.000561
other automatic	0.014286
the printed	0.000692
Problem	0.000029
and sub-categories	0.001445
Text simplification	0.166667
real human	0.111111
person-years	0.000029
speed is	0.142857
service on	0.200000
were easy	0.024390
Snyder -LRB-	0.500000
edges build	0.142857
Glass-box evaluation	1.000000
Text segmentation	0.166667
2006 and	0.333333
foreign word	0.500000
no means	0.076923
steered toward	1.000000
This criterion	0.015873
translation is	0.013514
actual NLP	0.200000
all rules	0.023256
including web	0.071429
recognition for	0.008264
Sample	0.000029
Baum-Welch algorithm	1.000000
nine ''	1.000000
especially of	0.066667
were simply	0.024390
with realistic	0.005464
keywords ,	0.500000
fonts used	0.333333
, how	0.000561
depended	0.000029
that used	0.003546
<s> Yet	0.000769
highly and	0.111111
would need	0.018868
Jurafsky	0.000029
Studies -RRB-	1.000000
improvement by	0.250000
Lao ,	1.000000
, TaleSpin	0.000561
A. D.	0.200000
Technolangue\/Easy project	0.500000
additional evidence	0.166667
some assertive	0.012048
is subject	0.002033
translating Quechua	0.250000
, Brill	0.000561
superseded	0.000029
hand-produced rules	1.000000
the Lancaster-Oslo-Bergen	0.000692
processing step	0.018519
Terry	0.000029
word stems	0.016667
model ''	0.033333
as first	0.003484
Modern general-purpose	0.333333
although usually	0.166667
'' This	0.005376
worse if	1.000000
a generated	0.001227
tag ``	0.062500
ranking over	0.142857
he or	0.142857
meeting	0.000029
` naturally	0.062500
emergence of	1.000000
himself with	0.500000
indicate speech	0.333333
involve learning	0.166667
500,000	0.000029
an idea	0.007576
the adviser	0.000692
be any	0.004219
otherwise ,	0.500000
post-secondary	0.000029
solid	0.000029
effects of	1.000000
in .	0.001873
and was	0.001445
first few	0.030303
even for	0.037037
quoting people	1.000000
apple the	0.333333
text linguistics	0.006289
<s> Features	0.000769
late 1960s	0.111111
Shipibo Paragraph	0.500000
BLEU .	0.333333
all .	0.023256
when there	0.028571
EBMT -RRB-	1.000000
pre-defined or	0.500000
state -RRB-	0.071429
and paragraphs	0.001445
are remarkably	0.004149
more consistent	0.010526
Schegloff	0.000029
also cut	0.014493
Institute -LRB-	1.000000
parametric	0.000029
Kittredge ,	0.500000
one observation	0.015385
longer sentences	1.000000
right answer	0.100000
, paper	0.000561
and questions	0.001445
tagging Koine	0.040000
million words	0.333333
from natural	0.009615
past-tense	0.000029
capitalization at	0.333333
evaluation comes	0.018519
Did	0.000029
To translate	0.111111
agglutinative	0.000029
search Query	0.090909
systems since	0.008929
techniques could	0.043478
A very	0.020000
, recall	0.000561
of active	0.000891
`` out	0.005291
fine tune	0.500000
some major	0.012048
one on	0.015385
Strzalkowski	0.000029
were workshops	0.024390
them in	0.052632
sub-problems	0.000029
he developed	0.142857
1982 -RRB-	0.333333
affects	0.000029
that detected	0.003546
PC platform	0.250000
and QA	0.001445
been shown	0.014706
tag probabilities	0.062500
dictionaries ,	1.000000
Typically	0.000029
1-July-2005 ,	1.000000
searching for	0.333333
automated target	0.142857
analyses of	0.200000
are in-principle	0.004149
post-process the	1.000000
get ranked	0.142857
module looks	0.333333
proportional	0.000029
contexts make	0.142857
successful in	0.111111
using sentence	0.016949
pronunciation	0.000029
visual detection	0.500000
, Reukos	0.000561
this system	0.010989
state-of-the-art in	0.500000
hopes	0.000029
is transformed	0.002033
directed	0.000029
dynamic programming	0.200000
hit you	1.000000
significant increases	0.111111
, Sandra	0.000561
psychology Response	0.250000
the hidden	0.000692
in Statistical	0.001873
messages .	0.500000
a sophisticated	0.001227
Answering	0.000029
parliament	0.000029
because many	0.033333
as working	0.003484
fluency	0.000029
specify precisely	1.000000
humanities	0.000029
word breaks	0.016667
spectral-domain	0.000029
combine the	0.333333
might select	0.038462
applied different	0.066667
lend	0.000029
of supervised	0.000891
large ,	0.043478
waves would	0.142857
, Battle	0.000561
2005	0.000029
2008	0.000029
into two	0.012821
Goodwin ,	1.000000
every 10msec	0.333333
automatically The	0.047619
as controlled	0.003484
Ethnography of	1.000000
upload paper	1.000000
: Instead	0.009804
might provide	0.038462
, Flickinger	0.000561
intensive	0.000029
eventually spun	1.000000
decomposition	0.000029
undirected	0.000029
co-articulation	0.000029
Santoni B.	1.000000
interface commercially	0.250000
manually assigned	0.250000
to internal	0.001328
terminate a	1.000000
one used	0.015385
grammar for	0.027027
e.g. Constraints	0.017857
independent system	0.500000
`` proper	0.005291
walks and	0.500000
was FoG	0.012987
leaders of	1.000000
, supervised	0.000561
replicated	0.000029
Extrinsic evaluation	0.500000
confusable words	1.000000
more often	0.010526
deterministic rules	0.250000
produce interpretable	0.045455
transcribe such	1.000000
opinion has	0.200000
and Pang	0.001445
with weights	0.005464
merging of	0.500000
Paul Chilton	0.200000
wide use	0.250000
rules based	0.023256
these simple	0.023810
Cloud Computing	1.000000
themselves as	0.250000
formally expressed	0.500000
early 20th-century	0.100000
made feasible	0.062500
of unstructured	0.000891
omni-font	0.000029
involve counting	0.166667
politics ,	1.000000
Dale	0.000029
explore and	0.250000
-LRB- NER	0.002710
language Prolog	0.006757
would fail	0.018868
system generates	0.010753
Basically	0.000029
as keeping	0.003484
customisation by	1.000000
meaning then	0.043478
of extracted	0.000891
non-trivial ,	0.500000
subscription	0.000029
SWER	0.000029
Extracted sentences	1.000000
some improvement	0.012048
presents the	1.000000
of discourses	0.000891
the shops	0.000692
with hand-written	0.005464
Kurzweil and	0.142857
are expected	0.004149
far ,	0.125000
word vector	0.016667
deciding on	0.166667
More up	0.111111
not well	0.008929
working for	0.142857
AI-complete problem	0.333333
-LRB- p.	0.002710
the ARNS	0.000692
the inferior	0.000692
company for	0.333333
column of	1.000000
lexicons with	0.500000
automatically the	0.047619
UMLS -RRB-	1.000000
<s> Vocalizations	0.000769
D.S. 1998	1.000000
to reflect	0.001328
of process	0.000891
summaries automatically	0.023256
output quality	0.038462
classification task	0.058824
Methods Computers	0.250000
Canada to	0.166667
good approximation	0.076923
own expert	0.166667
<s> Open	0.000769
make use	0.050000
day	0.000029
verifying	0.000029
that part	0.003546
to message	0.001328
and potential	0.001445
From	0.000029
made between	0.062500
formalisms such	0.500000
the centers	0.000692
defining programming	1.000000
English-French record	1.000000
and coverage	0.001445
general learning	0.045455
for computers	0.003610
hours .	0.500000
Compare speech	1.000000
summary covers	0.023810
of great	0.000891
might include	0.038462
different aspects	0.020408
context dependency	0.030303
since 2000	0.100000
respectively .	1.000000
Later ,	1.000000
The English	0.005208
grammar Rhetoric	0.027027
A procedure	0.020000
Advanced ,	0.200000
a car	0.001227
more descriptive	0.010526
Gail Jefferson	1.000000
of omni-font	0.000891
then combining	0.028571
most basic	0.017241
Association	0.000029
paragraphs ,	0.250000
grammatical and	0.090909
paragraphs .	0.250000
Scansoft ,	1.000000
the annual	0.000692
-LRB- titled	0.002710
in agglutinative	0.001873
original training	0.076923
prune	0.000029
certain restrictions	0.142857
varying degrees	1.000000
new opportunities	0.041667
Note ,	0.111111
performance has	0.055556
as 7	0.003484
as 1	0.003484
accuracy over	0.032258
curves	0.000029
performance had	0.055556
similarity classes	0.100000
to highly	0.001328
answer may	0.033333
<s> Working	0.000769
journal ``	0.333333
automatically learning	0.047619
unless	0.000029
keyphrases formed	0.028571
word senses	0.016667
as `	0.003484
rendered view	1.000000
Maximum entropy-based	0.333333
Automatic learning	0.111111
Beigi covers	1.000000
gather	0.000029
Modern NLP	0.333333
under stress	0.200000
selection	0.000029
speech recogniton	0.006579
assumptions on	0.200000
is part	0.002033
EUROPARL	0.000029
Airline Ticket	1.000000
Hybrid machine	0.500000
asked for	0.333333
key clauses	0.166667
in testing	0.001873
unusual in	1.000000
`` Natural	0.005291
often be	0.022727
calling	0.000029
system comprising	0.010753
used on	0.008850
Bar-Hillel .	1.000000
of Arabic	0.000891
using elements	0.016949
now we	0.076923
professor at	1.000000
post-processed	0.000029
Grows	0.000029
to disseminate	0.001328
phases	0.000029
Bois ,	1.000000
a discussion	0.001227
Brazil ,	1.000000
for avoiding	0.003610
continuous recognition	0.166667
Questions are	1.000000
how big	0.034483
Schank at	0.200000
structure grammar	0.083333
design feature	0.250000
: Transfer-based	0.009804
as weather	0.003484
correctly .	1.000000
generated summaries	0.066667
think about	0.333333
portions .	1.000000
Advanced Fighter	0.200000
results can	0.047619
dismiss the	1.000000
quantitative approaches	0.250000
received a	0.500000
biomedical	0.000029
where metrics	0.028571
normalized by	1.000000
Moore 's	1.000000
designed grammars	0.142857
plain	0.000029
of domains	0.000891
taking only	0.200000
: noun	0.009804
expressions that	0.333333
In computer	0.009524
file	0.000029
logic -RRB-	0.250000
concern .	1.000000
possibilities .	0.200000
possibilities ,	0.200000
simple implementations	0.038462
Produce	0.000029
Real progress	0.500000
define these	0.500000
Canadian parliament	0.500000
Marcus	0.000029
keeping the	0.500000
's that	0.019608
following are	0.066667
that an	0.003546
lookup algorithms	1.000000
a hierarchy	0.001227
geography ,	1.000000
differences themselves	0.333333
contexts and	0.142857
the sequence	0.000692
three to	0.333333
whether an	0.076923
capabilities of	0.200000
workday	0.000029
perhaps ,	0.166667
extraction depends	0.032258
counting cases	1.000000
of implementing	0.000891
would output	0.018868
the collection	0.000692
realized on	1.000000
open world	0.250000
analysis could	0.015385
selection is	1.000000
watertight barmaid	1.000000
several methods	0.045455
Dijk	0.000029
being asked	0.055556
: it	0.009804
engine ,	0.166667
large collections	0.043478
Documents	0.000029
segmentation in	0.030303
an original	0.007576
highlighting	0.000029
scores for	0.200000
journals include	0.500000
example generic	0.012346
-LRB- Realtime	0.002710
stemming or	0.500000
groups :	0.200000
tasks is	0.031250
as first-order	0.003484
legal word	0.333333
groups ,	0.200000
approximating	0.000029
December	0.000029
DCD library	1.000000
In 1914	0.009524
polynomial-size representations	1.000000
real-valued vectors	0.333333
by Homayoon	0.005714
Marc Angenot	1.000000
Interspeech	0.000029
shallow ''	0.166667
support the	0.250000
expected .	0.142857
expected ,	0.142857
weak ,	1.000000
calculator program	0.500000
The simplest	0.005208
machine is	0.012658
<s> Knowledge	0.000769
the identities	0.000692
and isolated	0.001445
at by	0.014706
changed from	0.500000
Compare	0.000029
operating system	0.500000
ones are	0.100000
the clusters	0.000692
Semi-supervised	0.000029
to most	0.001328
important -RRB-	0.062500
annotating texts	1.000000
a written-out	0.001227
model Modern	0.033333
not using	0.008929
system exhibited	0.010753
Vice	0.000029
claiming	0.000029
<s> Semantic	0.000769
importance is	0.166667
solving larger	1.000000
robustness in	0.250000
of intelligence	0.000891
emoticons ,	1.000000
words must	0.009174
strategy for	0.200000
multi-word	0.000029
have all	0.009615
mapping the	0.500000
unrealistically high	1.000000
, queries	0.000561
places and	0.500000
marks may	0.250000
module uses	0.333333
-LRB- including	0.002710
the production	0.000692
these problems	0.023810
good ''	0.076923
unexpected features	1.000000
while abstraction	0.050000
set appends	0.025641
first primitive	0.030303
sound pattern	0.050000
function -LRB-	0.125000
system-generated summary	0.500000
known type	0.038462
resolution ,	0.250000
October 2007	1.000000
EBMT	0.000029
resolution :	0.250000
Alenia Aermacchi	1.000000
valuable detailed	0.500000
and processing	0.001445
as OnlineOCR	0.003484
sizes generally	0.333333
handwritten cursive	0.500000
as objective	0.003484
they had	0.025000
we wanted	0.022222
science disciplines	0.100000
on large	0.004717
Work in	0.500000
feature which	0.076923
four decades	0.142857
name is	0.200000
Searches ,	1.000000
so most	0.033333
digits	0.000029
if documents	0.035714
In normal	0.009524
to rescore	0.001328
readily reveal	0.333333
develop in	0.200000
changes	0.000029
achieving fully	0.500000
might skip	0.038462
discussion groups	0.500000
multi-way scale	1.000000
be answered	0.004219
processing task	0.018519
market to	0.333333
by rules	0.005714
question or	0.023810
forums	0.000029
are directly	0.004149
showing comparative	0.500000
complex spoken	0.041667
How should	0.142857
The various	0.005208
scanned can	0.333333
rarity and	1.000000
appraisal	0.000029
watertight	0.000029
: Interlingual	0.009804
argued that	1.000000
, responding	0.000561
Sparkle campaign	1.000000
A parser	0.020000
country ,	0.250000
keyphrases ``	0.028571
distinguish names	0.200000
resulting classifier	0.250000
widespread	0.000029
for businesses	0.003610
recognize For	0.111111
specific voice	0.047619
Levenshtein distance	1.000000
to documents	0.001328
algorithms currently	0.028571
probabilistic context-free	0.142857
criterion of	0.500000
with computer-aided	0.005464
SAM	0.000029
exploit domain-specific	1.000000
engine page	0.166667
common strategy	0.040000
are pre-determined	0.004149
to suggest	0.001328
most notably	0.017241
, correlation	0.000561
though automating	0.100000
to represent	0.001328
Baum-Welch	0.000029
contains no	0.100000
an integrated	0.007576
in evaluating	0.001873
opinion mining	0.200000
by experts	0.005714
grammars for	0.071429
Theo van	1.000000
sentences correct	0.013158
is related	0.002033
One can	0.076923
Real time	0.500000
does ,	0.100000
driving	0.000029
Gina	0.000029
look-up tables	1.000000
have much	0.009615
wanted	0.000029
The machine-learning	0.005208
true keyphrases	0.500000
vowels depends	0.333333
developed by	0.038462
large multilingual	0.043478
second system	0.100000
consumed	0.000029
efficient parsers	0.333333
learning As	0.023256
whose easy-to-use	0.333333
percentage	0.000029
discussing what	0.500000
quite high	0.125000
before classifying	0.166667
Machine learning	0.111111
from any	0.009615
; ``	0.021277
senses ,	0.500000
compute the	0.500000
's and	0.019608
restricted vocabulary	0.250000
-RRB- from	0.002817
Rubin ,	1.000000
Cary Grant	1.000000
at IBM	0.014706
relatively	0.000029
clearly visible	0.333333
understanding in	0.030303
by further	0.005714
in deaf	0.001873
<s> Relationship	0.000769
properties as	0.250000
has given	0.011905
commanding	0.000029
Defense Advanced	1.000000
times they	0.200000
and cognition	0.001445
highly complex	0.111111
that specific	0.003546
Markov chain	0.055556
for Italian	0.003610
disambiguation Word-sense	0.100000
APEXC machine	1.000000
availability	0.000029
Big	0.000029
what categories	0.031250
morphosyntactic	0.000029
later part-of-speech	0.100000
or poetry	0.004505
-LRB- 1966	0.002710
simply too	0.083333
NP-complete	0.000029
abstraction .	0.250000
is publicly	0.002033
<s> Use	0.000769
databases -RRB-	0.125000
-LRB- icon	0.002710
by supplying	0.005714
recognition technology	0.008264
the forward-backward	0.000692
in vastly	0.001873
Cleave and	1.000000
the optical	0.000692
practice of	0.500000
Performance	0.000029
end a	0.125000
answers to	0.083333
sound signal	0.050000
of elaborate	0.000891
evaluation requires	0.018519
Today there	1.000000
Digest and	0.333333
Unsupervised approaches	0.166667
end .	0.125000
end ,	0.125000
and have	0.001445
been debated	0.014706
Since the	0.200000
faces	0.000029
are three	0.004149
Automatically translate	1.000000
high pollen	0.055556
VRX	0.000029
negative up	0.125000
the intermediary	0.000692
some perception	0.012048
Input -RRB-	0.500000
the details	0.000692
pre-marked	0.000029
very dependent	0.024390
<s> Read	0.000769
a sublanguage	0.001227
exchange of	1.000000
Animate	0.000029
uninterrupted and	1.000000
or noun	0.004505
definite on	1.000000
new token	0.041667
with larger	0.005464
networks has	0.071429
1989 -RRB-	0.500000
committed into	1.000000
translation at	0.013514
then direct	0.028571
commercializing paper-to-computer	1.000000
Parseval\/GEIG project	1.000000
offer the	1.000000
rely are	0.142857
Recently ,	1.000000
strategies ,	0.500000
the text-to-speech	0.000692
11 point	1.000000
Canada and	0.166667
two general	0.034483
: navigation	0.009804
parsers .	0.076923
more dynamic	0.010526
that tell	0.003546
Strzalkowski T.	1.000000
a limit	0.001227
begin and	0.333333
Some scholars	0.047619
unwanted	0.000029
system output	0.010753
the feature	0.000692
be roughly	0.004219
demonstrate .	1.000000
, Wallace	0.000561
processing tools	0.018519
businesses looking	0.500000
OCR and	0.020408
a journal	0.001227
lexical statistics	0.076923
boundary markers	0.166667
very effective	0.024390
many consecutive	0.019231
many programmers	0.019231
Robotics	0.000029
Answer formulation	0.333333
some common	0.012048
burden on	1.000000
breaking -LRB-	0.500000
enough information	0.200000
NP for	1.000000
work for	0.041667
as hidden	0.003484
rapidly changing	0.500000
beforehand -LRB-	1.000000
translation Statistical	0.013514
for help	0.003610
what knowledge	0.031250
produces all	0.250000
unigrams to	0.083333
established within	1.000000
and check	0.001445
steadily	0.000029
of running	0.000891
series -RRB-	0.125000
paraphrases	0.000029
interrogative -LRB-	1.000000
presence	0.000029
against any	0.200000
text structure	0.006289
Petrov ,	1.000000
shape of	1.000000
truck A	1.000000
nice side	0.250000
, texts	0.000561
using CSIS	0.016949
lead-in	0.000029
Petrov	0.000029
and generally	0.001445
syntax and	0.090909
-RRB- ``	0.002817
synthesis	0.000029
by heteroscedastic	0.005714
removes	0.000029
a strength	0.001227
including recognition	0.071429
removed	0.000029
like this	0.035714
into phonetic-based	0.012821
NLG -RRB-	0.047619
and limited	0.001445
Introduction	0.000029
orthography to	0.500000
be automated	0.004219
years long	0.047619
of stochastic	0.000891
or after	0.004505
perform data	0.090909
The cache	0.005208
research may	0.023810
of low	0.000891
distinctive initial	0.500000
models upon	0.038462
this genre	0.010989
ideal deep	1.000000
Guzman ,	1.000000
longer	0.000029
have questioned	0.009615
for substantial	0.003610
Putting words	1.000000
, unlike	0.000561
or topics	0.004505
expensive since	0.142857
remarkably	0.000029
Ncmsan ,	1.000000
Today	0.000029
Components and	1.000000
of organized	0.000891
1946	0.000029
The extractor	0.005208
new entrants	0.041667
: Vocabulary	0.009804
Bell Telephone	1.000000
central ``	0.333333
culminating	0.000029
McCarthy	0.000029
NLP comes	0.021277
no information	0.076923
Language understanding	0.083333
Sociologist	0.000029
-RRB- Court	0.002817
units such	0.142857
another ,	0.076923
knowledge but	0.037037
stands	0.000029
Automotive	0.000029
Page ,	1.000000
where word	0.028571
←	0.000029
human translators	0.021739
approaches presume	0.035714
water	0.000029
baseball	0.000029
supplying	0.000029
= Machine	0.111111
and which	0.001445
cache	0.000029
, cited	0.000561
, Alan	0.000561
modifying	0.000029
has fairly	0.011905
operational	0.000029
also similar	0.014493
piecewise stationary	1.000000
intermediary ,	0.333333
with certain	0.005464
but other	0.014706
to write	0.001328
October	0.000029
and analyze	0.001445
outputs	0.000029
same summary	0.040000
`` can	0.005291
why applying	0.142857
device converted	0.500000
insights	0.000029
are confusable	0.004149
Oil Company	1.000000
the biomedical	0.000692
human judgments	0.021739
syntax is	0.090909
input ;	0.024390
up ''	0.045455
theorists of	1.000000
including PARRY	0.071429
the presence	0.000692
NP-complete .	1.000000
use hidden	0.013889
possible unigrams	0.041667
British National	0.333333
Coulthard ,	1.000000
names of	0.142857
working examples	0.142857
probably ``	0.250000
to Xerox	0.001328
larger volume	0.062500
of itself	0.000891
input a	0.024390
close the	1.000000
classroom	0.000029
language analysis	0.006757
one font	0.015385
vice versa	1.000000
agreement among	0.333333
the -LRB-	0.000692
that carried	0.003546
analyzing written	0.200000
kind to	0.090909
determination :	1.000000
occurring '	1.000000
include voice	0.037037
others assign	0.083333
of complex	0.000891
1991 A	0.333333
same example-generation	0.040000
responsible for	1.000000
advent	0.000029
realistic	0.000029
serial numbers	1.000000
English-French	0.000029
that now	0.003546
Gee ,	1.000000
maintained within	0.500000
exclamation	0.000029
discourse relationships	0.027778
<s> Acoustical	0.000769
even appears	0.037037
follow-the-bouncing-ball	0.000029
factory	0.000029
extrapolate	0.000029
with learning	0.005464
2005 -RRB-	1.000000
Deborah Schiffrin	0.500000
deep are	0.142857
technology devised	0.045455
Dog	0.000029
for extracting	0.003610
<s> E.	0.000769
Command -RRB-	0.500000
also capitalized	0.014493
financial section	0.250000
minimum classification	0.500000
errors in	0.200000
motion	0.000029
primitive computer-type	1.000000
context in	0.030303
progress and	0.142857
digital dictation	0.142857
involves preliminary	0.100000
that merely	0.003546
space is	0.200000
symbolic	0.000029
less time	0.083333
researchers must	0.100000
concatenated text	1.000000
Computers can	1.000000
features or	0.038462
cope with	1.000000
coupons returned	1.000000
If it	0.100000
Short history	1.000000
several modules	0.045455
Data	0.000029
QA research	0.047619
exploring	0.000029
season	0.000029
PDF	0.000029
HTML and	1.000000
distinctions -LRB-	0.500000
of 1,500	0.000891
lowest	0.000029
alignment software	0.500000
topics automatically	0.142857
short summary	0.125000
about feature	0.025000
areas --	0.166667
statistics readily	0.125000
The fact	0.005208
using votes	0.016949
actual forecast	0.200000
University introduced	0.111111
computer applications	0.022727
performance on	0.055556
to 1966	0.001328
formed the	0.200000
multiply	0.000029
on several	0.004717
impossible .	0.500000
fact ambiguous	0.090909
reproducing formatted	1.000000
Guidelines see	0.500000
collecting a	1.000000
as discussions	0.003484
increased so	0.200000
answer a	0.033333
conflicting objectives	1.000000
see computational	0.050000
Other segmentation	0.142857
Emergent grammar	1.000000
hand-written by	0.142857
and controversial	0.001445
nasality ,	1.000000
n being	0.500000
Foucault himself	0.333333
answer ,	0.033333
inaccurate or	1.000000
severe in	1.000000
intelligence -LRB-	0.125000
indeed ,	0.333333
is ambiguous	0.002033
One example	0.076923
Man dog	0.500000
encouraged	0.000029
suffer	0.000029
so we	0.033333
were realized	0.024390
' -RRB-	0.052632
machine-encoded text	1.000000
inseparable	0.000029
is apple	0.002033
a probability	0.001227
your head	0.500000
missions	0.000029
MUC and	1.000000
Sublanguage analysis	1.000000
Re-encoding this	1.000000
des parties	1.000000
Open source	1.000000
Duranti ,	1.000000
and duplicate	0.001445
happy .	1.000000
on functional	0.004717
two simple	0.034483
confusable	0.000029
Systran ,	1.000000
Tom Clancy	1.000000
all handwritten	0.023256
The LexRank	0.005208
's SPHINX	0.019608
and Martin	0.001445
many instances	0.019231
broader and	1.000000
gestures ,	0.500000
'' highly	0.005376
would not	0.018868
recall may	0.333333
shops	0.000029
combined with	0.500000
Additional	0.000029
Sparkle	0.000029
`` happy	0.005291
appear ``	0.062500
performed using	0.100000
Du Bois	1.000000
what type	0.031250
IT	0.000029
driven	0.000029
various genres	0.055556
a quantity	0.001227
ID	0.000029
minimize	0.000029
on context	0.004717
First summarizes	1.000000
say whether	0.142857
including the	0.071429
<s> Named	0.000769
if word	0.035714
of hidden	0.000891
captured	0.000029
Broadly	0.000029
lip-synch timing	1.000000
for accuracy	0.003610
correlate best	0.333333
<s> Xerox	0.000769
made WebOCR	0.062500
<s> Topic	0.000769
Fully	0.000029
Stemming Text	1.000000
transcended the	1.000000
Avionics	0.000029
Another key	0.076923
Spoken	0.000029
noise ,	0.125000
atmosphere -LRB-	1.000000
character-by-character OCR	1.000000
L'action	0.000029
extraction can	0.032258
: for	0.009804
International	0.000029
Knowing	0.000029
acts in	0.333333
subproblem	0.000029
speech signal	0.006579
by domain	0.005714
perspectives and	1.000000
of constraints	0.000891
Continuous speech	1.000000
have started	0.009615
research direction	0.023810
but deep	0.014706
linguistic nuances	0.062500
formalism which	1.000000
Garfinkel who	1.000000
found .	0.071429
next four	0.142857
of connected	0.000891
particular note	0.076923
the Parliament	0.000692
machine recognition	0.012658
19th -	1.000000
discourse turns	0.027778
code ,	0.142857
later licensed	0.100000
tuned weights	1.000000
and ontology	0.001445
Once these	0.200000
orthogonal to	1.000000
an hour	0.007576
personalised business	1.000000
RDF	0.000029
and patented	0.001445
a tagging	0.001227
but steadily	0.014706
or grammatical	0.004505
numbers after	0.142857
new domains	0.041667
considerable success	0.200000
Louise	0.000029
of extractive	0.000891
single language	0.071429
the Bayes	0.000692
structured resources	0.166667
-LRB- actual	0.002710
summaries must	0.023256
ASR is	0.166667
two ?	0.034483
term parsing	0.055556
calls	0.000029
A first	0.020000
man-hours worked	1.000000
lack of	1.000000
whole discourses	0.111111
making a	0.142857
matrix ,	1.000000
meant that	0.500000
improve the	0.076923
lack	0.000029
Turing published	0.500000
The method	0.005208
construct over	0.333333
stutering	0.000029
set and	0.025641
creating pre-defined	0.142857
opportunities	0.000029
doctors make	0.333333
setting of	0.200000
progress -	0.142857
not appear	0.008929
task entirely	0.023810
: an	0.009804
hand-compiled list	1.000000
psychologist	0.000029
ultraviolet	0.000029
had similar	0.071429
intended emotional	0.200000
or Latin	0.004505
Reukos S.	1.000000
align	0.000029
accuracy reported	0.032258
, taught	0.000561
would choose	0.018868
an F-score	0.007576
BioCreative Message	1.000000
meanings depending	0.250000
precise ones	0.333333
to choose	0.001328
state .	0.071429
card OCR	0.250000
Short	0.000029
: Putting	0.009804
have produced	0.009615
can add	0.005525
summaries for	0.023256
, substantial	0.000561
to discover	0.001328
state a	0.071429
book-new	0.000029
Intuitively	0.000029
whether it	0.076923
opening ''	1.000000
n't see	0.250000
sentence transformations	0.020833
approaches Automatic	0.035714
recognition using	0.008264
heuristic to	0.333333
unlabeled data	1.000000
following the	0.066667
accurate results	0.142857
plural common	0.200000
the fixed	0.000692
an individual	0.007576
machine at	0.012658
Such perceptions	0.125000
certainty of	1.000000
operators	0.000029
developing Q&A	0.250000
a non-whitespace	0.001227
by Schank	0.005714
be located	0.004219
other NLP	0.014286
earlier Brown	0.250000
depends greatly	0.125000
commercial products	0.090909
memory Political	0.500000
Tagger	0.000029
like summarization	0.035714
In 1994	0.009524
In 1996	0.009524
simulates the	1.000000
In 1993	0.009524
challenging	0.000029
metrics often	0.111111
or produce	0.004505
this issue	0.010989
characterized DARPA	0.250000
fall between	0.250000
the creation	0.000692
talk-in-interaction	0.000029
values to	0.125000
recursive	0.000029
sound impressive	0.050000
relevant to	0.142857
reflect	0.000029
and large-scale	0.001445
various features	0.055556
solve algebra	0.250000
Heritage ,	1.000000
predefined template	1.000000
1,915,993	0.000029
unambiguously identified	1.000000
and manage	0.001445
This reader	0.015873
he had	0.142857
Many systems	0.083333
commercial perspective	0.090909
standard telegraph	0.071429
, Number	0.000561
M. 1999	0.250000
correct ''	0.066667
Lightning	0.000029
American camp	0.200000
recognition since	0.008264
variability ,	1.000000
, Guy	0.000561
approximated as	1.000000
Telephone	0.000029
Telephony	0.000029
Languages which	0.333333
Ray	0.000029
sense that	0.125000
A well-known	0.020000
necessary anymore	0.100000
capabilities and	0.200000
undertake	0.000029
water .	1.000000
of Hidden	0.000891
`` not	0.005291
parsing community	0.035714
Interactive QA	0.500000
commonly associated	0.125000
The experiment	0.005208
Reiter	0.000029
The construction	0.005208
develop as	0.200000
in NIST	0.001873
all get	0.023256
unique	0.000029
Sync	0.000029
prestige ''	1.000000
proceeds in	1.000000
These findings	0.058824
aspects such	0.142857
fancy	0.000029
Gary Hendrix	1.000000
provided within	0.200000
humans transcribe	0.083333
now common	0.076923
which discourse	0.007246
aspect is	0.500000
splicing and	1.000000
the elements	0.000692
call to	0.333333
option	0.000029
domain -LRB-	0.050000
Evaluation techniques	0.111111
convinced	0.000029
and would	0.001445
question domain	0.023810
ideas -RRB-	0.250000
a categorical	0.001227
many stochastic	0.019231
Speech Communication	0.032258
test the	0.100000
simply model	0.083333
real-world knowledge	0.166667
so for	0.033333
classifying its	0.200000
certain cases	0.142857
, associating	0.000561
a generic	0.001227
of context-free	0.000891
these two	0.023810
Closed-domain	0.000029
cues help	1.000000
suitable ontology	0.250000
best application	0.055556
was entertaining	0.012987
Carston ,	1.000000
the closest	0.000692
linear regression	0.142857
or positive	0.004505
for recognizing	0.003610
% error	0.025641
individual sentences	0.083333
real-time written	0.500000
theoretical aspects	0.333333
of deciding	0.000891
hit	0.000029
usually evaluated	0.031250
longest	0.000029
these other	0.023810
for continued	0.003610
also manual	0.014493
Canada Post	0.166667
engines ,	0.333333
attached to	0.500000
tool to	0.500000
arm	0.000029
learns	0.000029
When processing	0.142857
formatted	0.000029
the basics	0.000692
wrote ELIZA	0.166667
encouraging ,	1.000000
and voice	0.001445
initially	0.000029
general-purpose	0.000029
Parsing algorithms	0.200000
c	0.000029
sentiment strength	0.040000
they differ	0.025000
final post-processing	0.111111
arbitrarily	0.000029
other research	0.014286
estimated probability	1.000000
and manipulate	0.001445
but switched	0.014706
by IMR	0.005714
about each	0.025000
systems will	0.008929
ATC simulators	0.200000
evaluating NLG	0.200000
's specific	0.019608
input-stream by	1.000000
any human	0.032258
Integration -LRB-	1.000000
models of	0.038462
yes-no question	1.000000
techniques on	0.043478
engineers	0.000029
merged with	1.000000
count .	0.200000
only specific	0.026316
lengths	0.000029
some machine	0.012048
sometimes ,	0.076923
rules and	0.023256
fastens	0.000029
a writer	0.001227
Tipster	0.000029
gets around	0.500000
, written	0.000561
count T	0.200000
suitability as	0.500000
steady increase	0.500000
motion during	1.000000
possibility to	0.250000
grammar having	0.027027
intervals	0.000029
Northern areas	0.333333
could co-occur	0.062500
perform by	0.090909
most prior	0.017241
Naturally Speaking	1.000000
field comes	0.037037
find only	0.076923
displayed as	0.500000
2 -RRB-	0.200000
unlimited	0.000029
preferred computer-generated	1.000000
The rule-based	0.005208
with regards	0.005464
identify and	0.083333
ignore	0.000029
be sufficient	0.004219
that simple	0.003546
of papers	0.000891
their hands	0.029412
are easier	0.004149
lessened .	1.000000
trends of	1.000000
underpinnings	0.000029
unambiguous sentence-ending	0.500000
Applied linguistics	0.500000
selected based	0.500000
importance would	0.166667
Patent 2,663,758	0.333333
e.g. with	0.017857
modal	0.000029
cutoff	0.000029
, 1952	0.000561
accepted ,	1.000000
word at	0.016667
in service	0.001873
restaurant reviews	0.500000
intra-texual .	1.000000
issue is	0.125000
OCR or	0.020408
IBM .	0.333333
issue in	0.125000
accurate by	0.142857
NLG input	0.047619
repeatedly	0.000029
a rainbow	0.001227
perform adaptive	0.090909
parsing comes	0.035714
Another popular	0.076923
from multiple	0.009615
approximately divided	0.500000
mining refers	0.200000
will cover	0.028571
mainly came	0.166667
relative certainty	0.333333
the supervised	0.000692
invention of	1.000000
's work	0.019608
question into	0.023810
into consideration	0.012821
Informally	0.000029
could imagine	0.062500
personalised	0.000029
global semitied	0.333333
complex formalisms	0.041667
it easily	0.008547
linguist to	0.500000
to 90	0.001328
direct hand	0.166667
language like	0.006757
to 98	0.001328
my hand-compiled	1.000000
-LRB- plural	0.002710
After 30	0.333333
features\/aspects	0.000029
different meanings	0.020408
email address	0.500000
, graphic	0.000561
wishes	0.000029
IT technology	1.000000
for parse	0.003610
; Each	0.021277
: Merging	0.009804
norm .	1.000000
classifies features	1.000000
What distinguishes	0.090909
summarise electronic	0.333333
surrounding vowels	0.200000
universities	0.000029
Part-of-speech Tagging	0.500000
Union as	1.000000
neutral or	0.500000
computing :	0.500000
computing .	0.500000
as Eugene	0.003484
stored more	1.000000
USA in	1.000000
summaries There	0.023256
several systems	0.045455
and synthesis	0.001445
with rules	0.005464
Hardy	0.000029
Re-encoding	0.000029
which often	0.007246
-LRB- various	0.002710
languages of	0.020000
see below	0.050000
text documents	0.006289
giving the	0.500000
emerged as	1.000000
Decoding the	0.500000
languages or	0.020000
him perform	0.500000
for comparison	0.003610
markup like	1.000000
if they	0.035714
Vietnamese	0.000029
and combine	0.001445
time factor	0.030303
Sync -RRB-	1.000000
be poorly	0.004219
like that	0.035714
noise levels	0.125000
employed within	1.000000
and EUROPARL	0.001445
and slang	0.001445
consider sequences	0.250000
uses only	0.071429
object ,	0.500000
scanner to	0.333333
the techniques	0.000692
instructions .	1.000000
main underlying	0.125000
reduction of	0.500000
tell us	0.333333
for ASR	0.003610
particular case	0.076923
as language	0.003484
serial	0.000029
debated much	1.000000
polarity helped	0.125000
and paragraph	0.001445
SPOTLIGHT system	1.000000
Conversational analysis	1.000000
similarity metrics	0.100000
for inclusion	0.003610
, Grishman	0.000561
Aermacchi	0.000029
date is	0.333333
, previously	0.000561
noise pertain	0.125000
one element	0.015385
cepstral coefficients	0.500000
figure on	0.500000
Germany .	0.500000
tokens from	0.142857
Germany ,	0.500000
into each	0.012821
trivial word	0.250000
interrogative	0.000029
occurrence ,	0.500000
anywhere on	1.000000
the relationship	0.000692
drawn right-to-left	1.000000
RCA 301	0.200000
co-founded Google	1.000000
Adam	0.000029
a fully	0.001227
Voice commands	0.200000
new POS	0.041667
The learning	0.005208
different left	0.020408
translations ,	0.500000
information extraction	0.021739
Who is	0.500000
and possessives	0.001445
T final	0.166667
is responsible	0.002033
preselects	0.000029
reformulate	0.000029
and -RRB-	0.001445
of word-forms	0.000891
and depth	0.001445
abstracts ,	0.500000
, 13	0.000561
Medical Language	0.500000
a greater	0.001227
<s> Rule-based	0.000769
run-time .	1.000000
explanation ,	1.000000
several -RRB-	0.045455
commonly teach	0.125000
and also	0.001445
accent	0.000029
specific task	0.047619
then common	0.028571
the core	0.000692
create both	0.058824
remember	0.000029
short textual	0.125000
which showed	0.007246
proposes some	1.000000
was -LRB-	0.012987
several words	0.045455
also considered	0.014493
Paul Gee	0.200000
The importance	0.005208
perform complex	0.090909
and extract	0.001445
Independent	0.000029
grammars are	0.071429
using their	0.016949
vs. manual	0.083333
`` a	0.005291
or neutral	0.004505
adapt to	1.000000
<s> Compare	0.000769
20 %	1.000000
be satisfactory	0.004219
and most	0.001445
HLT ,	1.000000
`` A	0.005291
`` B	0.005291
archiving	0.000029
`` I	0.005291
, internet	0.000561
vision .	1.000000
, stored	0.000561
known .	0.038462
speaker can	0.055556
-RRB- formal	0.002817
analyst is	1.000000
purely	0.000029
as that	0.003484
area -RRB-	0.090909
of Roger	0.000891
high degree	0.055556
In natural	0.009524
the needs	0.000692
for detecting	0.003610
that combines	0.003546
Paragraph	0.000029
interoperability	0.000029
e.g. pictures	0.017857
are confirmed	0.004149
speech which	0.006579
the Grace	0.000692
at binary	0.014706
networks emerged	0.071429
concerned in	0.200000
Mariani J.	1.000000
of substantial	0.000891
than sixty	0.022222
uncertainties at	1.000000
and Thai	0.001445
discouraged the	1.000000
bill payment	0.500000
functions such	0.500000
by mapping	0.005714
text itself	0.006289
fidelity of	1.000000
pre-defined by	0.500000
closed	0.000029
undertake harder	1.000000
require minimal	0.045455
know is	0.500000
inter-annotator agreement	1.000000
is rarely	0.002033
of 15-20	0.000891
, strategies	0.000561
captioning	0.000029
the Turing	0.000692
by comparing	0.005714
Church independently	0.333333
operated successfully	0.500000
complex sets	0.041667
spacecraft ,	1.000000
only succeeding	0.026316
forecasts in	0.200000
clarification .	0.333333
a concept	0.001227
particular feature	0.076923
late 1930s	0.111111
to ones	0.001328
unambiguous .	0.500000
-LRB- MMR	0.002710
developed for	0.038462
V ,	1.000000
early precursor	0.100000
thesis at	1.000000
NLG may	0.047619
Eight years	1.000000
Language Generation	0.083333
a reading	0.001227
<s> Intuitively	0.000769
-LRB- MMI	0.002710
Navigation	0.000029
or fuse	0.004505
formally ,	0.500000
artifacts ,	1.000000
A good	0.020000
characters themselves	0.062500
by many	0.005714
Manual analysis	0.333333
content question	0.083333
of typical	0.000891
Alan Turing	1.000000
the label	0.000692
chart parsing	1.000000
are MARGIE	0.004149
1999 -RRB-	0.500000
and pasted	0.001445
from MUC	0.009615
web pages	0.125000
question can	0.023810
some variant	0.012048
le français	1.000000
<s> High-order	0.000769
Speaker Recognition	0.166667
of arbitrary	0.000891
the Vocabulary	0.000692
and perspective	0.001445
fashion ,	1.000000
WordNet ,	0.500000
WordNet .	0.500000
from Moore	0.009615
distortion ,	1.000000
systems read	0.008929
, Dr.	0.000561
for plural	0.003610
like what	0.035714
weighted to	0.333333
such representation	0.008130
Drum	0.000029
-LRB- role	0.002710
them for	0.052632
of about	0.000891
features into	0.038462
measures of	0.166667
rare --	0.250000
Nagao	0.000029
and do	0.001445
'' http:\/\/arxiv.org\/abs\/1104.2086	0.005376
construct lightweight	0.333333
, Animate	0.000561
software varied	0.037037
psycholinguistics ,	0.500000
Jonathan	0.000029
Speech can	0.032258
considered for	0.111111
subjective Yes\/No	0.166667
the improvement	0.000692
those East	0.045455
sociolinguistics Ethnography	0.500000
locate	0.000029
address -	0.250000
previously unseen	0.500000
probably important	0.250000
simply apply	0.083333
reference model	0.125000
nice beach	0.250000
dependence	0.000029
breaking ,	0.500000
as supervised	0.003484
portable to	0.333333
tag the	0.062500
ranking task	0.142857
Vulcan later	0.500000
using will	0.016949
one human	0.015385
entire content	0.333333
evaluations have	0.166667
meaning part	0.043478
testing accuracy	0.200000
silence are	1.000000
more categories	0.010526
DARPA funding	0.250000
of automated	0.000891
For nouns	0.016393
similarities in	0.500000
language that	0.006757
Tipster project	1.000000
ELIZA sometimes	0.111111
non-existent	0.000029
helicopter .	0.250000
meaningless	0.000029
that cause	0.003546
typically produces	0.055556
selects important	0.500000
similar in	0.037037
Several MT	0.333333
long-time	0.000029
terms do	0.076923
accurate transcription	0.142857
Weaver	0.000029
shared-task events	1.000000
the theoretical	0.000692
defective flood-control	1.000000
probabilistic decisions	0.285714
are both	0.008299
the recognition	0.001384
produce more	0.090909
of similar	0.001783
the automatic	0.001384
translate text	0.333333
the GALE	0.001384
Question answering	0.285714
purposes .	0.500000
LL	0.000058
LR	0.000058
verb .	0.153846
sentences but	0.026316
-RRB- for	0.005634
count of	0.400000
point ,	0.666667
texts of	0.117647
a US	0.002454
publication of	0.666667
<s> Increasingly	0.001537
a string	0.002454
entity recognition	0.400000
feasibility	0.000058
translator 's	0.285714
organization of	0.400000
into meaningful	0.025641
commercial OCR	0.181818
helicopter environment	0.500000
most famous	0.034483
on statistical	0.009434
common ,	0.080000
graph-based ranking	1.000000
of unigrams	0.001783
texts to	0.117647
of their	0.001783
and recall	0.002890
expression .	0.200000
expression ,	0.200000
tasks like	0.062500
Isles	0.000058
appropriately	0.000058
weights to	0.400000
In other	0.019048
systems with	0.017857
redundancy in	0.666667
by people	0.011429
applies a	0.285714
is actually	0.004065
text-to-speech and	0.500000
We can	0.285714
This task	0.031746
ME	0.000058
into separate	0.025641
, bigrams	0.001123
originally	0.000058
same input	0.080000
sociolinguistics	0.000058
Tablet PC	1.000000
larger system	0.125000
or subjective	0.009009
entering	0.000058
Deborah	0.000058
of syntactic	0.001783
classes of	0.400000
minimizes	0.000058
domains .	0.250000
or two	0.009009
History	0.000058
speech as	0.013158
answering .	0.166667
since it	0.200000
learning procedures	0.046512
turned	0.000058
the Unix	0.001384
opposite	0.000058
to summarization	0.002656
In order	0.019048
Top-down	0.000058
assess how	0.666667
well it	0.071429
precision and	0.400000
the speaker	0.001384
word that	0.033333
-LRB- sailor	0.005420
recall-based	0.000058
, glossary	0.001123
them .	0.105263
gestures	0.000058
January 2010	0.500000
`` AI-complete	0.010582
parameters for	0.500000
more sophisticated	0.021053
Real	0.000058
Read	0.000058
each segment	0.044444
genetic algorithm	1.000000
to input	0.002656
The ``	0.010417
experience	0.000058
, verb	0.001123
script .	0.500000
Answer extraction	0.666667
in France	0.003745
, audio	0.001123
French were	0.250000
operation	0.000058
see the	0.100000
pairs	0.000058
is on	0.004065
large quantities	0.086957
sound ,	0.100000
event ,	0.666667
data in	0.025974
Interlingual machine	0.666667
on their	0.009434
sentences from	0.026316
controller ,	0.500000
analog	0.000058
length ,	0.250000
sense disambiguation	0.250000
a cluster	0.002454
intelligence that	0.250000
exponential	0.000058
from machine	0.019231
sounds ,	0.133333
adjacent words	0.333333
corresponding to	0.333333
soft decisions	0.500000
the news	0.001384
OS	0.000058
translation was	0.027027
User	0.000058
needed to	0.095238
diverse	0.000058
the given	0.001384
methodologies	0.000058
dynamics	0.000058
multimedia	0.000058
1980s .	0.222222
topic ,	0.250000
Category	0.000058
top-down parsing	0.500000
<s> Words	0.001537
bilingual	0.000058
input devices	0.048780
graph will	0.153846
grammars ,	0.142857
grammars .	0.142857
in 1997	0.003745
ratings are	0.222222
will ``	0.057143
to see	0.002656
thought of	0.666667
progress was	0.285714
mainland	0.000058
is routed	0.004065
semantic information	0.095238
from data	0.019231
Iraq	0.000058
site .	1.000000
, ELIZA	0.001123
natural and	0.026667
comprising	0.000058
a combination	0.002454
frame	0.000058
: e.g.	0.019608
wrote an	0.333333
P.	0.000058
genetic	0.000058
speech in	0.013158
important sentences	0.125000
boundary disambiguation	0.333333
off	0.000058
semantics or	0.142857
was not	0.025974
, whereas	0.001123
methods have	0.045455
represented as	0.333333
possible analyses	0.083333
statistical techniques	0.060606
process that	0.055556
find a	0.153846
hand-annotated with	1.000000
an RCA	0.015152
places	0.000058
and typically	0.002890
of medical	0.001783
details	0.000058
correlate with	0.666667
Corps	0.000058
strings	0.000058
the particular	0.001384
searched	0.000058
worth	0.000058
Then the	0.400000
quantitative evaluation	0.500000
each unigram	0.044444
loss function	1.000000
of around	0.001783
1997	0.000058
1999	0.000058
a digital	0.002454
generated text	0.133333
a meaningful	0.002454
system for	0.021505
failed to	1.000000
reasonable	0.000058
Summarization -RRB-	0.500000
GALE project	1.000000
, information	0.001123
, based	0.001123
electronic	0.000058
approximately	0.000058
technology for	0.090909
amounts of	1.000000
In theory	0.019048
a grammar	0.002454
most important	0.034483
a stationary	0.002454
images of	0.333333
it ,	0.017094
standards .	0.400000
speech-to-text	0.000058
on what	0.009434
away	0.000058
too expensive	0.333333
they all	0.050000
The two	0.010417
and on	0.002890
were very	0.048780
the individual	0.001384
fuse	0.000058
non-trivial	0.000058
similarities	0.000058
asking	0.000058
correspond to	1.000000
substitution	0.000058
a limited	0.002454
the Royal	0.001384
length of	0.250000
human-generated	0.000058
keyphrases can	0.057143
number .	0.046512
-LRB- roughly	0.005420
finding the	0.400000
the capital	0.001384
to put	0.002656
psycholinguistics	0.000058
involves the	0.200000
shared	0.000058
to that	0.002656
a feature	0.002454
a quantitative	0.002454
Carnegie Mellon	1.000000
French .	0.250000
centrality	0.000058
WordNet	0.000058
determine its	0.086957
discussion	0.000058
a solved	0.002454
Martin	0.000058
, identify	0.001123
, Japanese	0.001123
Use	0.000058
achieved with	0.200000
challenges	0.000058
are :	0.008299
dependencies	0.000058
is clearly	0.004065
mainland Scotland	1.000000
that might	0.007092
needed .	0.095238
different types	0.040816
of very	0.001783
is widely	0.004065
complex than	0.083333
Character	0.000058
tags used	0.333333
hurts	0.000058
50 %	0.666667
150	0.000058
consider the	0.500000
are grounded	0.008299
improve this	0.153846
evaluated to	0.285714
labels to	1.000000
, ^	0.001123
, +	0.001123
common for	0.080000
kit '	1.000000
one sentence	0.030769
even the	0.074074
A shallow	0.040000
research had	0.047619
Symantec	0.000058
may have	0.038462
sixty	0.000058
stationary signal	0.285714
apple is	0.666667
binary classification	0.500000
described as	0.333333
will have	0.057143
in ASR	0.003745
threshold or	0.500000
is working	0.004065
continued research	0.222222
boundaries between	0.181818
plural noun	0.400000
distance ,	0.666667
like English	0.071429
methods work	0.045455
learner	0.000058
can only	0.011050
vocabulary and	0.250000
diagramming	0.000058
requiring	0.000058
S.	0.000058
translation systems	0.027027
document may	0.055556
named entity	0.285714
-RRB- -RRB-	0.005634
NLG is	0.095238
utilize	0.000058
far northeast	0.250000
lower level	0.400000
collections ,	0.500000
Wall Street	1.000000
sections of	1.000000
closer to	1.000000
trees .	0.333333
-LRB- usually	0.005420
extraction :	0.064516
Adda	0.000058
second step	0.200000
as with	0.006969
ranking algorithm	0.285714
first step	0.060606
a basis	0.002454
a basic	0.002454
areas with	0.333333
usually with	0.062500
computational power	0.200000
In English	0.019048
covariance	0.000058
as simple	0.006969
guide	0.000058
Keyphrase extraction	0.500000
informal	0.000058
showing	0.000058
an approximation	0.015152
PageRank to	0.333333
processing techniques	0.037037
the success	0.001384
Norman	0.000058
various types	0.111111
characters .	0.125000
dictates into	1.000000
parse trees	0.222222
hand or	0.142857
amounts	0.000058
department	0.000058
Stanford	0.000058
, social	0.001123
`` barmaid	0.010582
camera	0.000058
historically	0.000058
formally	0.000058
useful in	0.142857
Mr.	0.000058
defective	0.000058
trigram ,	0.666667
temporal	0.000058
searched ,	1.000000
state transducer	0.142857
Ideally	0.000058
cause	0.000058
models ,	0.076923
improve recognition	0.153846
summarization in	0.040000
describe the	0.333333
achieve	0.000058
of recognition	0.001783
up for	0.090909
operated	0.000058
tend	0.000058
Artificial	0.000058
sound clip	0.100000
complexity ,	0.166667
far more	0.250000
classification .	0.117647
directly to	0.400000
Types	0.000058
best to	0.111111
, ranging	0.001123
loss	0.000058
and identify	0.002890
library	0.000058
knowledge and	0.074074
between them	0.051282
in specific	0.003745
that use	0.007092
when writing	0.057143
UC	0.000058
previously	0.000058
, read	0.001123
display	0.000058
functions	0.000058
star	0.000058
consists	0.000058
but may	0.029412
set a	0.051282
set ,	0.051282
with disabilities	0.010929
, have	0.001123
is extremely	0.004065
whether the	0.153846
of different	0.001783
various ways	0.111111
we want	0.044444
implementations	0.000058
group of	0.500000
not accommodate	0.017857
you can	0.153846
grammar is	0.054054
system-generated	0.000058
Royal	0.000058
which a	0.014493
that should	0.007092
software is	0.074074
of 4	0.001783
Transactions on	1.000000
resource management	0.400000
type is	0.142857
program that	0.090909
automatically learn	0.095238
northeast	0.000058
a leftmost	0.002454
hand-crafted	0.000058
Many of	0.166667
Evaluating summaries	1.000000
Chinese ,	0.285714
As an	0.111111
entered	0.000058
Robert E.	0.500000
deciding to	0.333333
<s> Why	0.001537
meets	0.000058
one to	0.030769
even in	0.074074
assigned	0.000058
yet	0.000058
NLG system	0.095238
Sager	0.000058
Accuracy rates	0.285714
predicting	0.000058
HMMs -RRB-	0.250000
Italy ,	1.000000
not have	0.017857
marking	0.000058
be identified	0.008439
, will	0.001123
delimited ,	0.500000
article and	0.068966
dealing	0.000058
international	0.000058
, made	0.001123
merely	0.000058
and statistics	0.002890
in question	0.003745
automatic summary	0.086957
translation has	0.027027
languages -RRB-	0.040000
summaries can	0.046512
is sufficient	0.004065
, morphology	0.001123
Jelinek	0.000058
developed .	0.076923
weather reports	0.285714
E. Longacre	0.500000
7 in	0.285714
or other	0.009009
Question classes	0.285714
Black	0.000058
not typically	0.017857
sailor ''	0.400000
other words	0.028571
200	0.000058
<s> Search	0.001537
W.	0.000058
capable	0.000058
Turing	0.000058
attaching	0.000058
Birkbeck College	1.000000
: Creating	0.019608
for many	0.007220
than others	0.044444
stock .	0.666667
a supervised	0.002454
a finite	0.002454
to accommodate	0.002656
1991 -RRB-	0.666667
grammar which	0.054054
news article	0.153846
evaluation tests	0.037037
barmaid ''	0.333333
to limit	0.002656
the IEEE	0.001384
% ,	0.051282
recognition task	0.016529
humans ,	0.166667
Training	0.000058
situation	0.000058
the steady	0.001384
content overlap	0.166667
specialized	0.000058
many words	0.038462
greatly .	0.285714
to manipulate	0.002656
keyphrases are	0.057143
primary	0.000058
beginning	0.000058
especially input	0.133333
businesses	0.000058
is constructed	0.004065
The idea	0.010417
foreign	0.000058
During this	0.500000
computer in	0.045455
-LRB- often	0.005420
^ ,	0.666667
% accurate	0.051282
published a	0.285714
the phonemes	0.001384
non-annotated	0.000058
transfer-based machine	0.666667
centroid	0.000058
makes the	0.250000
and far	0.002890
reports -RRB-	0.400000
speaker adaptation	0.111111
lead to	1.000000
translation -LRB-	0.027027
<s> Parsers	0.001537
we create	0.044444
analysis and	0.030769
most spoken	0.034483
This approach	0.031746
tagged ''	0.666667
rightmost derivation	1.000000
their systems	0.058824
Mandarin and	1.000000
procedures can	0.500000
limited .	0.200000
varies	0.000058
<s> History	0.001537
subtask of	1.000000
per second	0.500000
phonetic	0.000058
summaries depending	0.046512
approached	0.000058
the 1960s	0.001384
sentence that	0.041667
reached	0.000058
fuse with	1.000000
to describe	0.002656
parsing or	0.071429
transducer	0.000058
parsing of	0.071429
abstracts	0.000058
concerns	0.000058
deep understanding	0.285714
1,000	0.000058
teams	0.000058
fixed	0.000058
<s> Hence	0.001537
difficulties	0.000058
functioning as	0.666667
a collection	0.002454
and neural	0.002890
recognizers	0.000058
essentially a	0.250000
Nations	0.000058
tense	0.000058
II	0.000058
conversion of	0.666667
-RRB- would	0.005634
idea of	0.285714
sentence -RRB-	0.041667
IE -RRB-	0.666667
recommendation	0.000058
introduced	0.000058
is what	0.004065
predict task-effectiveness	0.333333
character is	0.090909
grammatical tagging	0.181818
detail	0.000058
than only	0.044444
disciplines	0.000058
blue	0.000058
selected	0.000058
most natural	0.034483
of context	0.001783
Translation process	0.666667
Automatic summarization	0.222222
given sentence	0.083333
now named	0.153846
them are	0.105263
In both	0.019048
is easier	0.004065
capable of	1.000000
associate	0.000058
section requires	0.333333
filter	0.000058
are called	0.008299
, setting	0.001123
dedicated to	0.666667
traditionally	0.000058
n-gram	0.000058
world .	0.133333
Convert	0.000058
entertaining	0.000058
LREC	0.000058
end up	0.250000
form .	0.100000
term ``	0.111111
With the	0.285714
get the	0.285714
sophisticated algorithms	0.285714
conference	0.000058
also very	0.028986
formalization	0.000058
n	0.000058
POS tags	0.153846
Japanese and	0.250000
' .	0.105263
Rate -LRB-	1.000000
breaks	0.000058
supervised keyphrase	0.125000
of achieving	0.001783
discontinuous speech	0.666667
tested	0.000058
to end	0.002656
<s> Text	0.001537
resources ,	0.333333
frequencies	0.000058
impressive	0.000058
methodologies .	1.000000
trend	0.000058
<s> e.g.	0.001537
inflectional	0.000058
Corporation -LRB-	0.500000
this field	0.021978
Therefore	0.000058
it requires	0.017094
was shown	0.025974
machine would	0.025316
figure	0.000058
fields of	0.333333
too many	0.333333
Adverse conditions	1.000000
NLP problem	0.042553
, syntax	0.001123
of POS	0.001783
OCR in	0.040816
platform	0.000058
research is	0.047619
human-written	0.000058
a small	0.002454
by an	0.011429
use or	0.027778
France ,	0.500000
documents with	0.052632
Commercial	0.000058
that requires	0.007092
IMR	0.000058
the corresponding	0.001384
some methods	0.024096
the parsing	0.001384
are two	0.008299
sciences	0.000058
about speech	0.050000
Optical character	0.666667
dealing with	1.000000
predicted	0.000058
multiple possible	0.153846
densely connected	1.000000
period	0.000058
strings of	1.000000
a common	0.002454
phoneme	0.000058
addition ,	0.333333
-RRB- The	0.005634
, Inc.	0.001123
is necessary	0.004065
a tool	0.002454
-LRB- although	0.005420
of continuous	0.001783
using statistical	0.033898
in summary	0.003745
and that	0.002890
sixty Russian	1.000000
that there	0.007092
enough data	0.400000
tend to	1.000000
sentence position	0.041667
a maximum	0.002454
Sentence segmentation	0.400000
features that	0.076923
into segments	0.025641
summarization -LRB-	0.040000
summary and	0.047619
higher levels	0.285714
would like	0.037736
: Rules	0.019608
`` tagged	0.010582
Black-box	0.000058
very useful	0.048780
natural ''	0.026667
any of	0.064516
algorithms are	0.057143
understand the	0.285714
probability -RRB-	0.285714
leading	0.000058
Larry	0.000058
, MT	0.001123
've	0.000058
customize	0.000058
using some	0.033898
use training	0.027778
in computational	0.003745
Evaluation -RRB-	0.222222
posed in	0.666667
emails	0.000058
contextual	0.000058
attention	0.000058
flight	0.000058
The same	0.010417
in statistical	0.003745
methods -LRB-	0.045455
one meaning	0.030769
a great	0.002454
leftmost	0.000058
plural ,	0.400000
long	0.000058
another problem	0.153846
and allows	0.002890
or automatically	0.009009
short-time	0.000058
source document	0.083333
`` blue	0.010582
the test	0.001384
and without	0.002890
devices .	0.500000
Audio	0.000058
model .	0.066667
P	0.000058
a part	0.002454
concluded	0.000058
, Deborah	0.001123
<s> Their	0.001537
an open	0.015152
just a	0.222222
Microsoft	0.000058
Australian	0.000058
to predict	0.002656
10 milliseconds	0.250000
Schank and	0.400000
of two	0.001783
, OCR	0.001123
interpreter	0.000058
and expensive	0.002890
to those	0.002656
which have	0.014493
excess	0.000058
affective	0.000058
hence	0.000058
pilot to	0.400000
<s> Summarization	0.001537
in free	0.003745
clip	0.000058
<s> Ideally	0.001537
<s> SHRDLU	0.001537
people who	0.125000
answering deals	0.166667
`` recommend	0.010582
written texts	0.076923
job	0.000058
output a	0.076923
environments	0.000058
language and	0.013514
but have	0.029412
order ,	0.142857
keyphrases ,	0.057143
computer to	0.045455
undertaken	0.000058
do this	0.076923
techniques that	0.086957
smoothly	0.000058
carried	0.000058
to ''	0.002656
Birkbeck	0.000058
which were	0.014493
result is	0.181818
Future	0.000058
pumps	0.000058
installed at	0.666667
sources .	0.333333
for Gisting	0.007220
may contain	0.038462
and document	0.002890
already been	0.400000
errors -LRB-	0.400000
methodology	0.000058
questions .	0.076923
is split	0.004065
been done	0.029412
-LRB- by	0.005420
where sentences	0.057143
a deterministic	0.002454
Maximum entropy	0.666667
information about	0.043478
Typical	0.000058
the ability	0.001384
deemed	0.000058
only some	0.052632
conceptual	0.000058
represent a	0.222222
DeRose 's	0.400000
readers	0.000058
structure .	0.166667
text corpus	0.012579
opinions	0.000058
4 .	0.400000
of Scotland	0.001783
conducted in	0.400000
-LRB- Recall-Oriented	0.005420
possibly	0.000058
construction of	0.666667
left and	0.333333
steps	0.000058
hard to	0.333333
definition ,	0.400000
vertex for	0.666667
Hirschman	0.000058
reducing	0.000058
Methods for	0.500000
Statistical NLP	0.222222
, entering	0.001123
phrases ,	0.125000
NIST	0.000058
deciding whether	0.333333
Tablet	0.000058
extraction and	0.064516
Unsupervised keyphrase	0.333333
speech and	0.013158
Who	0.000058
a movie	0.002454
and developed	0.002890
problem involves	0.045455
which they	0.014493
as their	0.006969
Snyder	0.000058
experiment was	0.400000
audio ,	1.000000
of mainland	0.001783
query relevant	0.666667
representing	0.000058
cross-lingual	0.000058
technology .	0.090909
common use	0.080000
of many	0.001783
inflectional morphology	1.000000
an automatic	0.015152
Products	0.000058
have used	0.019231
this way	0.021978
contain the	0.166667
went to	0.400000
an edge	0.015152
management of	0.285714
data mining	0.025974
combined	0.000058
standard -LRB-	0.142857
sentences have	0.026316
question .	0.047619
fall into	0.500000
that TextRank	0.007092
answer extraction	0.066667
of 2007	0.001783
Air Force	0.666667
parser The	0.125000
of characters	0.001783
in common	0.003745
Understudy for	1.000000
to appear	0.002656
growing field	0.500000
dimensions of	0.666667
match the	0.333333
some time	0.024096
within three	0.111111
Acoustical	0.000058
and others	0.002890
<s> Answer	0.001537
hours	0.000058
parsers will	0.153846
full stop	0.400000
and grammar	0.002890
speech can	0.013158
keeping	0.000058
due to	0.400000
in that	0.003745
Conference	0.000058
more robust	0.021053
extraction as	0.064516
two sentences	0.068966
dependent on	0.666667
, rather	0.001123
which includes	0.014493
commands .	0.400000
both ``	0.064516
Adverse	0.000058
was much	0.025974
a translation	0.002454
impact	0.000058
failed	0.000058
made in	0.125000
large-vocabulary speech	0.666667
FoG	0.000058
way we	0.083333
co-occurrence graph	0.666667
applications in	0.080000
to help	0.002656
volume of	0.500000
accommodate ambiguity	0.400000
increases in	1.000000
The product	0.010417
canned	0.000058
Rate	0.000058
about 70	0.050000
allows users	0.250000
subtasks	0.000058
of sound	0.001783
stop character	1.000000
processing ''	0.037037
ACL	0.000058
primarily	0.000058
specifically	0.000058
users to	0.222222
defines	0.000058
<s> Consider	0.001537
points	0.000058
of ways	0.001783
a typical	0.002454
Street Journal	0.666667
cursive script	0.400000
language -RRB-	0.013514
, particularly	0.001123
that will	0.007092
shown to	0.400000
to match	0.002656
F-16	0.000058
decisions based	0.200000
for their	0.007220
both the	0.064516
how it	0.068966
central ''	0.666667
often as	0.045455
achieved accuracy	0.200000
bar	0.000058
insufficient .	1.000000
stochastic ,	0.250000
inter-texual	0.000058
frequency	0.000058
of Turney	0.001783
, writing	0.001123
robot	0.000058
recognition computer	0.016529
of tokens	0.001783
look at	0.400000
1998 -RRB-	0.500000
application ,	0.142857
Whether	0.000058
data can	0.025974
email	0.000058
on attaching	0.009434
seen before	0.200000
output that	0.076923
command	0.000058
of as	0.001783
including :	0.142857
Our brain	0.666667
corpus ,	0.064516
derived by	0.333333
the edges	0.001384
the order	0.001384
gained	0.000058
advanced scanning	0.400000
naturally	0.000058
question-answering	0.000058
aims to	0.666667
denote	0.000058
, are	0.001123
separate it	0.200000
the size	0.001384
alphabet ,	0.666667
developed at	0.076923
names that	0.285714
world knowledge	0.133333
service ,	0.400000
problems and	0.117647
people to	0.125000
choose	0.000058
punctuation marks	0.285714
provide a	0.333333
'' approaches	0.010753
if-then	0.000058
produce output	0.090909
generally more	0.181818
bigrams ,	1.000000
hand-annotated	0.000058
and larger	0.002890
translation -RRB-	0.027027
-LRB- more	0.005420
Rule-based	0.000058
heuristics	0.000058
if you	0.071429
the essence	0.001384
of potential	0.001783
contains errors	0.200000
de	0.000058
while LexRank	0.100000
, text-to-speech	0.001123
of printed	0.001783
these numbers	0.047619
likelihood linear	0.666667
are being	0.008299
extraction is	0.064516
require extensive	0.090909
sounds of	0.133333
if there	0.071429
discourses	0.000058
sort of	0.666667
very small	0.048780
1976	0.000058
different parts	0.040816
distinguish between	0.400000
adding	0.000058
telephony ,	0.666667
of linguistic	0.001783
implementations of	1.000000
online reviews	0.250000
by voice	0.011429
determine which	0.086957
for determining	0.007220
<s> Manual	0.001537
-LRB- U.S.	0.005420
second layer	0.200000
for singular	0.007220
evidence	0.000058
: give	0.019608
evaluation step	0.037037
<s> Applications	0.001537
worked on	0.400000
cluster of	1.000000
rightmost	0.000058
repetitive	0.000058
when we	0.057143
words were	0.018349
, US	0.001123
NLP tasks	0.042553
meant	0.000058
human-made	0.000058
pre-defined	0.000058
criterion	0.000058
allowable	0.000058
-LRB- of	0.005420
-LRB- on	0.005420
-RRB- that	0.005634
Transactions	0.000058
window	0.000058
between two	0.051282
entirely	0.000058
reading and	0.250000
use this	0.027778
algebra	0.000058
impossible	0.000058
the end	0.001384
mostly	0.000058
Inc.	0.000058
and Arabic	0.002890
making the	0.285714
shapes of	0.666667
been hand-annotated	0.029412
techniques ,	0.086957
can represent	0.011050
`` Who	0.010582
because there	0.066667
in conjunction	0.003745
is especially	0.004065
stems	0.000058
been more	0.029412
flood-control pumps	1.000000
easily portable	0.222222
: ``	0.019608
environment .	0.333333
syntactic analysis	0.153846
Before	0.000058
recorded	0.000058
information into	0.043478
ontology	0.000058
to rate	0.002656
might use	0.076923
in helicopters	0.003745
even though	0.074074
is similar	0.004065
of knowledge	0.001783
very broad	0.048780
<s> Programming	0.001537
for more	0.007220
of top-down	0.001783
limited number	0.200000
splitting	0.000058
referring	0.000058
30 years	0.666667
Another approach	0.153846
also the	0.028986
This corpus	0.031746
make up	0.100000
rudimentary	0.000058
new text	0.083333
This allows	0.031746
names .	0.285714
names ,	0.285714
Creating	0.000058
algorithm to	0.071429
inter-word spaces	1.000000
robustness against	0.500000
People with	1.000000
left-most	0.000058
from text	0.019231
pauses between	0.500000
software to	0.074074
resolve ambiguities	0.500000
with two	0.010929
collection of	0.400000
recursively	0.000058
Once performed	0.400000
task-effectiveness	0.000058
NLP algorithms	0.042553
audio	0.000058
` kit	0.125000
Therefore ,	1.000000
scanning	0.000058
, computer	0.001123
genre	0.000058
Hard	0.000058
Most	0.000058
probabilities .	0.181818
`` recommendation	0.010582
Issues	0.000058
seems to	1.000000
for them	0.007220
distances	0.000058
linguistics -RRB-	0.100000
use by	0.027778
...	0.000058
parsers for	0.153846
Computing	0.000058
creation	0.000058
, Michel	0.001123
Computer Speech	0.333333
and include	0.002890
Their	0.000058
maximum likelihood	0.333333
lexical and	0.153846
himself	0.000058
with human	0.010929
identification of	0.400000
to fulfill	0.002656
Northern Isles	0.666667
-LRB- based	0.005420
English alphabet	0.054054
rules :	0.046512
applications include	0.080000
, verbs	0.001123
program a	0.090909
program to	0.090909
focuses	0.000058
polarity ''	0.250000
This model	0.031746
not all	0.017857
both of	0.064516
been using	0.029412
reliable results	0.500000
Beginning	0.000058
<s> Issues	0.001537
Automated	0.000058
warping is	0.500000
suitability	0.000058
achieves	0.000058
distinguishes	0.000058
providing	0.000058
segmentation problems	0.060606
CLAWS ,	0.500000
supervised classification	0.125000
evident	0.000058
\* ,	0.500000
Dragon	0.000058
1970s and	0.666667
real-valued weights	0.666667
reader designed	0.200000
excess of	1.000000
categories and	0.222222
Communications -LRB-	1.000000
search engines	0.181818
solved problem	0.400000
of texts	0.001783
the high	0.001384
TextRank and	0.142857
-LRB- POS	0.005420
Character Recognition	1.000000
the diagramming	0.001384
run the	0.400000
The accuracy	0.010417
blogs	0.000058
work .	0.083333
choices What	0.400000
varies greatly	1.000000
those languages	0.090909
companies	0.000058
in Germany	0.003745
text about	0.012579
Italy	0.000058
text from	0.012579
recommend	0.000058
sentences -LRB-	0.026316
separated by	0.666667
term applies	0.111111
created ,	0.285714
led to	0.666667
used when	0.017699
approaches have	0.071429
not .	0.017857
earliest-used	0.000058
Alternatively	0.000058
the phenomenon	0.001384
major OCR	0.166667
semantic theory	0.095238
that in	0.007092
messages	0.000058
of simple	0.001783
Corps of	1.000000
the tag	0.001384
the left	0.001384
communication -LRB-	0.400000
Two of	0.285714
judges	0.000058
TextRank ,	0.142857
the ranking	0.001384
stop	0.000058
, simple	0.001123
linguist	0.000058
being considered	0.111111
; e.g.	0.042553
reports into	0.400000
a speaker	0.002454
large number	0.086957
AVRADA	0.000058
Orleans	0.000058
, handling	0.001123
each example	0.044444
recognition :	0.016529
grammar of	0.054054
in-depth knowledge	0.666667
10 %	0.250000
would produce	0.037736
to more	0.002656
Critical	0.000058
a whole	0.002454
concepts are	0.400000
<s> Maximum	0.001537
1950s ,	0.500000
the idea	0.001384
of hand-printed	0.001783
assume	0.000058
vocabulary .	0.250000
, these	0.001123
J. ,	0.666667
human -RRB-	0.043478
general purpose	0.090909
Substantial	0.000058
learning from	0.046512
speed ,	0.285714
-LRB- IE	0.005420
cepstral	0.000058
breaking	0.000058
generation :	0.222222
generation .	0.222222
, either	0.001123
make it	0.100000
mechanisms	0.000058
-LRB- among	0.005420
achieved ,	0.200000
; for	0.042553
ISO	0.000058
for real-world	0.007220
cell phone	1.000000
Post	0.000058
accurately	0.000058
Parsing is	0.400000
Genre	0.000058
finding a	0.400000
creating an	0.285714
summaries to	0.046512
out in	0.142857
which would	0.014493
with speech	0.010929
to act	0.002656
progress in	0.285714
or an	0.009009
or as	0.009009
be derived	0.008439
had failed	0.142857
been achieved	0.029412
creation of	1.000000
which make	0.014493
system in	0.021505
New	0.000058
positive and	0.285714
Statistical machine	0.222222
makes it	0.250000
1978 -RRB-	0.666667
a piece	0.002454
necessary to	0.200000
Major	0.000058
titles	0.000058
operating	0.000058
training step	0.071429
post-processing step	0.666667
semi-supervised	0.000058
achieving	0.000058
the US	0.001384
of 500	0.001783
strategies	0.000058
token is	0.500000
followed by	0.500000
a correct	0.002454
as part	0.006969
never been	0.400000
measure of	0.181818
this reason	0.021978
comprehension of	0.285714
the controller	0.001384
the role	0.001384
take the	0.200000
1987 ,	0.666667
that human	0.007092
Gisting Evaluation	1.000000
as input	0.006969
window of	1.000000
select the	0.333333
Communications	0.000058
walk on	0.400000
generators	0.000058
world assumption	0.133333
needs a	0.200000
interfaces	0.000058
also :	0.028986
an utterance	0.015152
discriminant	0.000058
bill	0.000058
is another	0.004065
speaker of	0.111111
assignment	0.000058
Quechua ,	1.000000
In 1950	0.019048
alignment	0.000058
it ends	0.017094
are traditionally	0.008299
of them	0.001783
stage is	0.400000
only in	0.052632
range from	0.285714
a native	0.002454
very limited	0.048780
Genre Analysis	1.000000
medical data	0.333333
approach that	0.057143
giving	0.000058
on one	0.009434
to date	0.002656
to data	0.002656
, standard	0.001123
; but	0.042553
regions	0.000058
overfitting	0.000058
estimate the	0.500000
one natural	0.030769
who have	0.200000
bunch	0.000058
the tokens	0.001384
systems developed	0.017857
syntactic and	0.153846
involved fully	0.333333
programmed	0.000058
method .	0.125000
build an	0.666667
how a	0.068966
<s> Lexical	0.001537
idioms ,	1.000000
represented by	0.333333
disambiguation -RRB-	0.200000
contains the	0.200000
Nuance Communications	0.666667
of course	0.001783
of news	0.001783
accuracy -RRB-	0.064516
machine representation	0.025316
is particularly	0.004065
use it	0.027778
the generated	0.001384
odd looking	1.000000
key area	0.333333
Guidelines	0.000058
feature .	0.153846
northeast of	1.000000
How to	0.285714
hybrid	0.000058
analysis can	0.030769
works	0.000058
M. ,	0.500000
<s> Optical	0.001537
language ''	0.013514
1989	0.000058
single source	0.142857
Wall	0.000058
clarification of	0.666667
battle management	1.000000
a separate	0.002454
be necessary	0.008439
analyses .	0.400000
these tasks	0.047619
specification	0.000058
path	0.000058
real-time	0.000058
may require	0.038462
Fundamentals	0.000058
looking to	0.400000
a context	0.002454
expectations	0.000058
<s> Both	0.001537
1955 ,	1.000000
automatic translation	0.086957
aircraft ,	0.285714
text mining	0.012579
tool	0.000058
of automatic	0.001783
upper level	1.000000
a wide	0.002454
Word sense	0.285714
this approach	0.021978
<s> Research	0.001537
other areas	0.028571
isolation	0.000058
handwritten	0.000058
grammars -RRB-	0.142857
merging	0.000058
we say	0.044444
the expression	0.001384
algorithm for	0.071429
leftmost derivation	1.000000
Bush	0.000058
up a	0.090909
proposed keyphrases	0.222222
core	0.000058
BASEBALL	0.000058
signal can	0.333333
called the	0.111111
head	0.000058
hear	0.000058
Electronic	0.000058
`` sailor	0.010582
be implemented	0.008439
performance and	0.111111
`` be	0.010582
concepts .	0.400000
translation can	0.027027
document classification	0.055556
yesterday with	0.666667
less likely	0.166667
language -LRB-	0.013514
methods need	0.045455
R. ,	0.333333
In any	0.019048
below .	0.400000
domain of	0.100000
for use	0.007220
requirements	0.000058
the primary	0.001384
as described	0.006969
List	0.000058
simplified	0.000058
millions	0.000058
each one	0.044444
known to	0.076923
proposed a	0.222222
statistically evaluated	1.000000
transcription	0.000058
the areas	0.001384
is worth	0.004065
input and	0.048780
simpler sounds	0.666667
; rejecting	0.042553
, whose	0.001123
these are	0.047619
segmentation tools	0.060606
similarity between	0.200000
During the	0.500000
were compared	0.048780
the computer	0.001384
specialised	0.000058
chatterbots	0.000058
information ,	0.043478
<s> Whether	0.001537
system or	0.021505
provider	0.000058
John Swales	0.250000
formal grammar	0.222222
house	0.000058
qualitative	0.000058
strongly	0.000058
generates a	0.666667
that within	0.007092
spoken language	0.142857
font .	0.666667
recall .	0.666667
a reference	0.002454
many of	0.038462
are much	0.008299
contexts .	0.285714
contexts ,	0.285714
, systems	0.001123
battle	0.000058
to support	0.002656
debates	0.000058
be programmed	0.008439
understanding .	0.060606
Carnegie	0.000058
creating a	0.285714
character ,	0.090909
in excess	0.003745
People	0.000058
-RRB- If	0.005634
summary in	0.047619
<s> Therefore	0.001537
summary is	0.047619
performance ,	0.111111
Mellon University	1.000000
2.0	0.000058
with high	0.010929
of grammar	0.001783
reasons	0.000058
AI systems	0.666667
the European	0.001384
after the	0.166667
States .	0.285714
President Bush	0.500000
needed for	0.095238
more deterministic	0.021053
40 %	1.000000
deployed	0.000058
inter-word	0.000058
Increasingly ,	1.000000
overlaps	0.000058
expectations ,	1.000000
and speed	0.002890
term used	0.111111
up in	0.090909
for what	0.007220
but is	0.029412
are obtained	0.008299
scope of	1.000000
but in	0.029412
source sentence	0.083333
abstractive methods	0.333333
relate to	1.000000
evaluations are	0.333333
induction	0.000058
LOB Corpus	1.000000
ALPAC	0.000058
and ICR	0.002890
or paragraphs	0.009009
a first	0.002454
many cases	0.038462
these summaries	0.047619
the basic	0.001384
planning	0.000058
formal language	0.222222
a reasonable	0.002454
displayed	0.000058
blend smoothly	0.666667
Fundamentals of	1.000000
arguably	0.000058
Force	0.000058
expressions .	0.666667
Scotland .	0.400000
linear discriminant	0.285714
rare .	0.500000
parsers are	0.153846
transform ,	0.400000
only by	0.052632
representation and	0.105263
larger corpus	0.125000
applications have	0.080000
<s> Evaluating	0.001537
expressed on	0.333333
an understanding	0.015152
distinction is	0.400000
of parser	0.001783
in 1954	0.003745
Science	0.000058
record	0.000058
person to	0.105263
Lander	0.000058
can have	0.011050
the ALPAC	0.001384
weights .	0.400000
John 's	0.250000
optical character	1.000000
common .	0.080000
processes used	0.400000
Harris 's	0.222222
to discriminate	0.002656
sentiment in	0.080000
database or	0.200000
wave is	0.222222
database of	0.200000
created by	0.285714
a keyphrase	0.002454
discourse in	0.055556
person or	0.105263
Work	0.000058
systems for	0.017857
speeds	0.000058
the past	0.001384
in recognizing	0.003745
<s> Speaker	0.001537
came	0.000058
relationship extraction	0.333333
in Europe	0.003745
, containing	0.001123
essence of	1.000000
or may	0.009009
funding for	0.250000
How are	0.285714
dynamically	0.000058
the 1990s	0.001384
delta-delta	0.000058
toolkit	0.000058
simulated	0.000058
methods were	0.045455
of simpler	0.001783
opposite of	1.000000
Lexical	0.000058
consists of	1.000000
rules for	0.046512
be fully	0.008439
Knowledge	0.000058
Hybrid	0.000058
resulted	0.000058
steady	0.000058
textbook	0.000058
e.g. The	0.035714
first commercial	0.060606
-LRB- especially	0.005420
answers from	0.166667
, find	0.001123
a rightmost	0.002454
breadth	0.000058
inflected	0.000058
to artificial	0.002656
occurrence	0.000058
, artificial	0.001123
angry	0.000058
scope	0.000058
as of	0.006969
of hard	0.001783
returned from	0.500000
the expected	0.001384
between words	0.051282
sentence in	0.041667
sentence is	0.041667
1950 ,	1.000000
by analyzing	0.011429
language models	0.013514
methods of	0.045455
Task and	0.666667
Penn tag	0.222222
evaluating summaries	0.400000
other systems	0.028571
other text	0.028571
artificial processes	0.181818
non-annotated data	1.000000
average	0.000058
Applied	0.000058
a qualitative	0.002454
as many	0.006969
Thai	0.000058
complex NLP	0.083333
reference to	0.250000
considers	0.000058
enable	0.000058
especially common	0.133333
not rely	0.017857
intended for	0.400000
records .	0.500000
Algorithms	0.000058
delta and	1.000000
formed ?	0.400000
her	0.000058
guide the	1.000000
The methods	0.010417
Some systems	0.095238
roughly ,	0.666667
Web .	0.222222
that did	0.007092
EVALITA	0.000058
the table	0.001384
<s> Most	0.001537
Treebank .	0.333333
<s> LREC	0.001537
very simple	0.048780
ROUGE is	0.400000
favor	0.000058
This section	0.031746
The only	0.010417
100 %	0.666667
sounds -LRB-	0.133333
lexicon of	0.222222
fundamental	0.000058
during a	0.200000
measurement	0.000058
the unigrams	0.001384
more basic	0.021053
'' would	0.010753
factor	0.000058
Different types	1.000000
effective in	0.333333
a higher	0.002454
been tried	0.029412
or interpreter	0.009009
by humans	0.011429
processing of	0.037037
performed by	0.200000
languages -LRB-	0.040000
data and	0.025974
abbreviation	0.000058
advertisements	0.000058
format	0.000058
<s> LexRank	0.001537
it will	0.017094
translation Interlingual	0.027027
us	0.000058
parses	0.000058
nautical	0.000058
then the	0.057143
but most	0.029412
colloquially	0.000058
lower levels	0.400000
in recognition	0.003745
Janet	0.000058
words ''	0.018349
, researchers	0.001123
Fourier transform	0.666667
invented	0.000058
On-line character	0.666667
bar code	1.000000
a sentiment	0.002454
, thus	0.001123
the keyphrases	0.001384
multiple documents	0.153846
compared .	0.285714
Such models	0.250000
degrees	0.000058
2011	0.000058
never be	0.400000
random walks	0.285714
between lexical	0.051282
, statistics	0.001123
e-communities	0.000058
tagging was	0.080000
represent .	0.222222
is like	0.004065
the ones	0.001384
available for	0.117647
LREC Granada	1.000000
Because	0.000058
<s> Neural	0.001537
ends	0.000058
systems usually	0.017857
corpora are	0.181818
-RRB- ''	0.005634
been a	0.029412
site	0.000058
ask the	0.500000
Shipibo	0.000058
inflected languages	1.000000
users .	0.222222
vocabularies ,	1.000000
Company	0.000058
these words	0.047619
like to	0.071429
and produce	0.002890
at Yale	0.029412
if we	0.071429
whether a	0.153846
compute	0.000058
human judges	0.043478
characterized by	0.500000
be effective	0.008439
to them	0.002656
Longacre	0.000058
analysis was	0.030769
development ,	0.166667
blue ''	1.000000
well .	0.071429
items	0.000058
the National	0.001384
an article	0.015152
opinion in	0.400000
total	0.000058
a patent	0.002454
in document	0.003745
<s> Intrinsic	0.001537
services .	0.666667
south	0.000058
evaluate the	0.500000
speech into	0.013158
based ,	0.037037
schemes	0.000058
+ ,	0.333333
campaigns	0.000058
10msec	0.000058
creates	0.000058
method for	0.125000
hand-printed text	0.500000
or discourse	0.009009
in recent	0.003745
<s> Document	0.001537
Computer Products	0.333333
keywords	0.000058
co-occur	0.000058
summary ''	0.047619
implementation	0.000058
idioms	0.000058
summary 's	0.047619
spoken languages	0.142857
unable	0.000058
Battle	0.000058
basic sound	0.153846
Understudy	0.000058
TextRank was	0.142857
the algorithms	0.001384
aim	0.000058
citations to	0.666667
, video	0.001123
Pallet	0.000058
to explicitly	0.002656
done with	0.181818
comes from	0.400000
rate is	0.181818
Then ,	0.400000
into English	0.025641
accepts	0.000058
French and	0.250000
HMMs are	0.250000
true	0.000058
can determine	0.011050
prone to	1.000000
a nice	0.002454
computing	0.000058
of part-of-speech	0.001783
symbol .	0.500000
division	0.000058
segmentation and	0.060606
entries	0.000058
problems colloquially	0.117647
natural speech	0.026667
subjectivity	0.000058
selects	0.000058
with questions	0.010929
<s> Extraction	0.001537
attribute	0.000058
derivations of	1.000000
trigrams	0.000058
of converting	0.001783
-LRB- May	0.005420
NLP problems	0.042553
to automate	0.002656
1955	0.000058
1950	0.000058
1952	0.000058
Parsers	0.000058
Peru	0.000058
algorithms that	0.057143
, Emanuel	0.001123
an application	0.015152
unambiguous	0.000058
capitalized ,	0.666667
message	0.000058
checked	0.000058
Separate	0.000058
vowel in	1.000000
and efficient	0.002890
setting ,	0.400000
distorted	0.000058
<s> Algorithms	0.001537
Speereo	0.000058
successive	0.000058
Goldberg	0.000058
is intended	0.004065
can benefit	0.011050
is considered	0.004065
last decade	0.400000
<s> Commercial	0.001537
a name	0.002454
some systems	0.024096
tagging ,	0.080000
tagging .	0.080000
differing contexts	1.000000
automatic summarization	0.086957
closest	0.000058
communicative goal	0.666667
valuable	0.000058
other .	0.028571
-LRB- in	0.005420
Mars	0.000058
statistical NLP	0.060606
, Zellig	0.001123
removing	0.000058
Speech is	0.064516
copied	0.000058
unable to	1.000000
reliability	0.000058
United Nations	0.222222
computerized	0.000058
people speaking	0.125000
Contrary to	1.000000
adaptive summarization	0.666667
is using	0.004065
aimed	0.000058
identical to	1.000000
LOB	0.000058
they require	0.050000
thousands of	0.666667
the sounds	0.001384
portion of	1.000000
`` tag	0.010582
first statistical	0.060606
hierarchy	0.000058
when such	0.057143
the impact	0.001384
languages can	0.040000
east .	1.000000
context The	0.060606
be linked	0.008439
divided into	0.666667
weapon	0.000058
small ,	0.222222
letters of	0.200000
Evaluating	0.000058
flood-control	0.000058
classifiers	0.000058
the semantic	0.001384
to by	0.002656
Online	0.000058
do n't	0.076923
Software	0.000058
reads	0.000058
subject ,	0.250000
subject .	0.250000
south east	1.000000
being a	0.111111
Internet	0.000058
mathematical	0.000058
large sets	0.086957
following example	0.133333
Decoding	0.000058
Longacre ,	1.000000
is commonly	0.004065
properly	0.000058
most successful	0.034483
tags ,	0.333333
tags .	0.333333
polarity of	0.250000
closely related	0.400000
choice of	0.250000
accuracy for	0.064516
supervised methods	0.125000
visual	0.000058
spoken ,	0.142857
the semantics	0.001384
Canadian	0.000058
Manual evaluation	0.666667
`` 12	0.010582
the previous	0.001384
, creating	0.001123
in reference	0.003745
to unsupervised	0.002656
many applications	0.038462
subjective information	0.333333
-LRB- 3	0.005420
program in	0.090909
evaluation criteria	0.037037
intermediary representation	0.666667
Lehnert ,	0.666667
to ,	0.002656
simple and	0.076923
attaching real-valued	1.000000
derivations	0.000058
prone	0.000058
to explore	0.002656
a news	0.002454
this context	0.021978
editing	0.000058
acoustic modeling	0.333333
early AI	0.200000
statistically	0.000058
; these	0.042553
to customize	0.002656
conjunction with	0.666667
vs. ``	0.166667
that may	0.007092
-LRB- DA	0.005420
slowly	0.000058
capture	0.000058
user interfaces	0.142857
domains and	0.250000
transformational	0.000058
frequently	0.000058
vertices .	0.222222
stationary distribution	0.285714
<s> LL	0.001537
expected to	0.285714
neutral	0.000058
Increasingly	0.000058
tagging or	0.080000
Spanish	0.000058
the second	0.001384
derivation -LRB-	0.500000
abbreviations ,	0.400000
images ,	0.333333
ranging from	1.000000
, separate	0.001123
input -LRB-	0.048780
Naomi Sager	1.000000
might not	0.076923
president	0.000058
set ''	0.051282
mean	0.000058
democratizing	0.000058
ATC training	0.400000
-RRB- have	0.005634
annotated	0.000058
outputting	0.000058
Consider	0.000058
provided by	0.400000
discourse analysts	0.055556
papers on	0.666667
seem	0.000058
graph .	0.153846
the concept	0.001384
of Canada	0.001783
we are	0.044444
to return	0.002656
or what	0.009009
Overview	0.000058
architecture	0.000058
classification for	0.117647
An intrinsic	0.125000
resulted in	1.000000
potential to	0.285714
Gismo	0.000058
the types	0.001384
differing	0.000058
kit	0.000058
P. ,	1.000000
why he	0.285714
the tagging	0.001384
split into	0.500000
In a	0.019048
at MIT	0.029412
be evaluated	0.008439
of communication	0.001783
Interactive	0.000058
: TextRank	0.019608
Lauriault\/Loriot	0.000058
retrieval and	0.285714
given approach	0.083333
is presented	0.004065
be ''	0.008439
with it	0.010929
programs ,	0.181818
only on	0.052632
slow	0.000058
best that	0.111111
seen an	0.200000
of Engineers	0.001783
confused	0.000058
map	0.000058
Swales	0.000058
Yale	0.000058
is produced	0.004065
through a	0.250000
writing systems	0.222222
is concerned	0.004065
be represented	0.008439
his students	0.166667
speech-recognition engine	0.666667
13	0.000058
document -LRB-	0.055556
or people	0.009009
can ''	0.011050
the Wall	0.001384
wide range	0.500000
who is	0.200000
nearly	0.000058
years development	0.095238
`` universal	0.010582
ongoing	0.000058
forms of	0.333333
to eliminate	0.002656
-RRB- task-based	0.005634
Google .	0.500000
'' -	0.010753
or phrases	0.009009
human user	0.043478
or to	0.009009
formalisms	0.000058
that determines	0.007092
returning	0.000058
domain-specific	0.000058
ideas in	0.500000
to these	0.002656
Naomi	0.000058
representation -LRB-	0.105263
comparing	0.000058
LR parsers	1.000000
<s> Its	0.001537
issue .	0.250000
conversation with	0.500000
difficult tasks	0.071429
Ideally ,	1.000000
formal representations	0.222222
output nodes	0.076923
is where	0.004065
is performed	0.004065
isolated speech	0.400000
same as	0.080000
assumption	0.000058
then we	0.057143
state-of-the-art	0.000058
example :	0.024691
unigrams .	0.166667
propositions ,	1.000000
Unix	0.000058
`` Speaker	0.010582
is ``	0.004065
reverse	0.000058
For a	0.032787
say ,	0.285714
say `	0.285714
a user	0.002454
It was	0.052632
College	0.000058
signals are	1.000000
coherence and	0.666667
next word	0.285714
data sources	0.025974
the sentiment	0.001384
more data	0.021053
very common	0.048780
, interlingual	0.001123
robust when	0.500000
for developing	0.007220
much slower	0.090909
milliseconds	0.000058
May	0.000058
Man	0.000058
-RRB- into	0.005634
helps	0.000058
with equivalent	0.010929
network approaches	0.333333
Recent research	0.666667
have focused	0.019231
Recognition of	0.250000
basis for	0.333333
error -LRB-	0.166667
such corpora	0.016260
Web pages	0.222222
translation :	0.027027
stage of	0.400000
2,000	0.000058
's job	0.039216
they refer	0.050000
leading to	1.000000
and create	0.002890
normally	0.000058
has not	0.023810
that minimizes	0.007092
in 1987	0.003745
step --	0.133333
of existing	0.001783
Example-based machine	0.666667
place in	0.500000
detailed	0.000058
finished	0.000058
Topics of	1.000000
work has	0.083333
walks	0.000058
any arbitrary	0.064516
language or	0.013514
soft ,	0.500000
propositions	0.000058
unsupervised summarization	0.250000
test documents	0.200000
commercially available	1.000000
and negative	0.002890
Generation	0.000058
functional	0.000058
repeated	0.000058
automatically and	0.095238
40	0.000058
GALE	0.000058
is getting	0.004065
people .	0.125000
Henry	0.000058
levels will	0.090909
graph-based	0.000058
of spoken	0.001783
reader was	0.200000
we produce	0.044444
Part-of-speech	0.000058
HMM-based approach	0.666667
this are	0.021978
CSIS	0.000058
have to	0.019231
, why	0.001123
Some current	0.095238
distribution that	0.500000
a real	0.002454
extraction system	0.064516
, words	0.001123
in systems	0.003745
toy	0.000058
speech tagging	0.013158
approach ,	0.057143
in use	0.003745
1969	0.000058
hard if-then	0.333333
`` central	0.010582
to place	0.002656
of individual	0.001783
the future	0.001384
solutions	0.000058
scale ,	0.333333
effective .	0.333333
combination with	0.400000
detection	0.000058
number -RRB-	0.046512
president of	1.000000
word can	0.033333
of computerized	0.001783
1 %	0.500000
, TextRank	0.001123
summaries -LRB-	0.046512
the south	0.001384
and syntactic	0.002890
at Brown	0.029412
Word splitting	0.285714
performance is	0.111111
in spoken	0.003745
Granada	0.000058
human -LRB-	0.043478
diagramming of	1.000000
systems based	0.017857
measures how	0.333333
so it	0.066667
environments .	1.000000
developments in	0.666667
It 's	0.052632
combine various	0.666667
advertisements .	1.000000
extractor	0.000058
Using	0.000058
the domain	0.001384
is how	0.004065
mapping	0.000058
Transfer-based machine	1.000000
be recognized	0.008439
structures that	0.400000
often the	0.045455
necessarily	0.000058
gives	0.000058
released	0.000058
List of	1.000000
Turney and	0.222222
and may	0.002890
workshops	0.000058
ways ,	0.250000
ways :	0.250000
define	0.000058
by selecting	0.011429
discussing	0.000058
subsequent	0.000058
instances of	0.666667
outside	0.000058
the publication	0.001384
densely	0.000058
-RRB- a	0.005634
for most	0.007220
This work	0.031746
500	0.000058
lexicons	0.000058
In Europe	0.019048
& OnlineOCR	0.250000
D. ,	0.400000
vowel	0.000058
actions	0.000058
seems	0.000058
a speech	0.002454
not necessarily	0.017857
when discussing	0.057143
HTK	0.000058
Error	0.000058
the provider	0.001384
slower ,	1.000000
words will	0.018349
is made	0.004065
and 1980s	0.002890
of syntax	0.001783
translation would	0.027027
these ,	0.047619
the emotional	0.001384
semantics which	0.142857
clip of	1.000000
ambiguous words	0.166667
been created	0.029412
Parliament	0.000058
and right	0.002890
as sentence	0.006969
then applied	0.057143
essence	0.000058
style	0.000058
several years	0.090909
, 1976	0.001123
, 1978	0.001123
Reading	0.000058
be performed	0.008439
one language	0.030769
optical	0.000058
to judge	0.002656
New Orleans	1.000000
check	0.000058
Germany	0.000058
shown in	0.400000
for people	0.007220
induction .	1.000000
the art	0.001384
understanding to	0.060606
a linear	0.002454
references -RRB-	0.500000
recogniton	0.000058
which words	0.014493
test and	0.200000
orthography	0.000058
About	0.000058
recognition ''	0.016529
<s> Alternatively	0.001537
In many	0.019048
claimed that	1.000000
customers	0.000058
of abbreviations	0.001783
Recall-Oriented Understudy	1.000000
sub-committee	0.000058
Command	0.000058
sizes of	0.666667
dialog	0.000058
sections	0.000058
DA -RRB-	0.666667
delta	0.000058
A typical	0.040000
-LRB- Harris	0.005420
punctuation and	0.285714
focuses on	1.000000
have different	0.019231
Read vs.	1.000000
given unfamiliar	0.083333
work of	0.083333
understand simple	0.285714
in four	0.003745
OCR ''	0.040816
of accuracy	0.001783
at Birkbeck	0.029412
not use	0.017857
other cases	0.028571
Input	0.000058
input .	0.048780
first major	0.060606
six	0.000058
meaning .	0.086957
made more	0.125000
the specification	0.001384
material	0.000058
use only	0.027778
punctuation ,	0.285714
transformational grammar	1.000000
, see	0.001123
fields ,	0.333333
be to	0.008439
Engineers	0.000058
taught the	0.666667
the Blind	0.001384
informativeness of	0.666667
spoken words	0.142857
corpus in	0.064516
sentence or	0.041667
US patent	0.285714
main difficulty	0.250000
The grammar	0.010417
, search	0.001123
selecting a	0.400000
and delta-delta	0.002890
plateaued	0.000058
was proposed	0.025974
gets	0.000058
applying PageRank	0.500000
and reasoning	0.002890
, part-of-speech	0.001123
words from	0.018349
as easily	0.006969
<s> WebOCR	0.001537
introduced the	1.000000
only a	0.052632
word being	0.033333
difficulty in	0.285714
and abstraction	0.002890
van	0.000058
more commonly	0.021053
approximates	0.000058
the web	0.001384
fire	0.000058
segment ,	0.222222
the opposite	0.001384
ranks	0.000058
goal of	0.285714
pairs ,	1.000000
a phrase	0.002454
the president	0.001384
the recognized	0.001384
are at	0.008299
not been	0.017857
here	0.000058
intrinsic evaluation	0.500000
like Chinese	0.071429
until	0.000058
often not	0.045455
to start	0.002656
TextRank uses	0.142857
classify	0.000058
Brown University	0.142857
feedback	0.000058
12 \*	0.400000
expression and	0.200000
a dialogue	0.002454
such an	0.016260
a known	0.002454
ranging	0.000058
the picture	0.001384
object	0.000058
recommend ''	1.000000
acoustic noise	0.333333
four different	0.285714
Agency	0.000058
is required	0.004065
, sentences	0.001123
scripts -LRB-	0.666667
This phenomenon	0.031746
between adjacent	0.051282
include an	0.074074
subject of	0.250000
This covers	0.031746
characterize	0.000058
Contrary	0.000058
echoes	0.000058
east	0.000058
reader .	0.200000
LILOG	0.000058
on tasks	0.009434
the notion	0.001384
Many words	0.166667
trend to	1.000000
limit the	0.500000
returning a	1.000000
though it	0.200000
project compared	0.153846
summaries and	0.046512
-- are	0.080000
, research	0.001123
articles or	0.250000
the set	0.001384
the major	0.001384
processing in	0.037037
processing is	0.037037
was by	0.025974
commercial efforts	0.181818
have in	0.019231
-LRB- An	0.005420
along	0.000058
prefer	0.000058
<s> Types	0.001537
explored	0.000058
stress	0.000058
derive	0.000058
Overview of	1.000000
context -LRB-	0.060606
web site	0.250000
sentences of	0.026316
routed	0.000058
accuracy rate	0.064516
Isolated	0.000058
called evaluation	0.111111
and development	0.002890
draft	0.000058
surrounding words	0.400000
before -RRB-	0.333333
system would	0.021505
evaluation can	0.037037
a toy	0.002454
the proposed	0.001384
working in	0.285714
on to	0.009434
quantities of	0.666667
approach -RRB-	0.057143
has many	0.023810
naval resource	0.666667
as one	0.006969
a lexicon	0.002454
CSR -RRB-	0.666667
size and	0.333333
scientific	0.000058
<s> Instead	0.001537
the area	0.001384
<s> Overview	0.001537
eigenvector	0.000058
an abstractive	0.015152
document\/text	0.000058
`` to	0.010582
characters which	0.125000
book -LRB-	0.250000
growing interest	0.500000
approach .	0.057143
heteroscedastic linear	1.000000
sound should	0.100000
the purpose	0.001384
`` Fundamentals	0.010582
objectives	0.000058
Russian	0.000058
English has	0.054054
if in	0.071429
if it	0.071429
glass-box	0.000058
passages	0.000058
trade	0.000058
attitude	0.000058
rapidly	0.000058
Application-Oriented	0.000058
-LRB- HMMs	0.005420
aimed at	1.000000
camp with	0.500000
letter shapes	0.333333
not consistently	0.017857
use lexical	0.027778
the surrounding	0.001384
features .	0.076923
cockpit	0.000058
for those	0.007220
syllables	0.000058
James A.	0.500000
by adding	0.011429
`` processing	0.010582
from those	0.019231
with no	0.010929
in several	0.003745
into more	0.025641
In 1969	0.019048
if-then rules	1.000000
the book	0.001384
termed ``	0.500000
in linguistic	0.003745
below -RRB-	0.400000
find an	0.153846
Edges are	1.000000
are available	0.008299
you 've	0.153846
handling	0.000058
very difficult	0.048780
calculator	0.000058
just as	0.222222
Turney paper	0.222222
shorter	0.000058
virtually	0.000058
Consider the	1.000000
discriminative training	1.000000
real-world data	0.333333
signals	0.000058
projects	0.000058
contrast to	0.250000
dictates	0.000058
pages .	0.285714
Programming languages	0.666667
evaluation :	0.037037
submit	0.000058
custom	0.000058
model for	0.066667
the American	0.001384
its domain	0.057143
These are	0.117647
becomes easier	0.500000
languages have	0.040000
or text	0.009009
illustrates	0.000058
idea that	0.285714
provides	0.000058
odd	0.000058
adaptation .	0.666667
duplicate	0.000058
-- if	0.080000
fulfill	0.000058
with known	0.010929
the resulting	0.001384
the Canadian	0.001384
approach which	0.057143
and linguistics	0.002890
doing	0.000058
start of	0.285714
is always	0.004065
has never	0.023810
AI-complete ''	0.666667
'' might	0.010753
a time	0.002454
final keyphrases	0.222222
<s> Recognition	0.001537
the name	0.001384
: Separate	0.019608
obtained a	0.285714
device	0.000058
difficult .	0.071429
express the	0.400000
normalization .	0.333333
glass-box evaluation	1.000000
UK .	0.500000
<s> Work	0.001537
for part-of-speech	0.007220
, propositions	0.001123
the intended	0.001384
Medical	0.000058
There has	0.181818
increases	0.000058
Systems released	0.166667
a linguistic	0.002454
and compare	0.002890
easier than	0.250000
recognition tasks	0.016529
insufficient	0.000058
contractions	0.000058
Extrinsic	0.000058
positive or	0.285714
systems which	0.017857
informational	0.000058
would run	0.037736
due both	0.400000
<s> Using	0.001537
method based	0.125000
phones	0.000058
<s> Early	0.001537
Isles and	1.000000
mentioned earlier	0.333333
turned into	1.000000
consisting	0.000058
-LRB- so	0.005420
In France	0.019048
Health	0.000058
then it	0.057143
confused with	1.000000
<s> Sound	0.001537
of pollen	0.001783
also used	0.028986
to keep	0.002656
Xerox	0.000058
An important	0.125000
break	0.000058
when describing	0.057143
commercially	0.000058
following :	0.133333
the 1980s	0.001384
following .	0.133333
date -LRB-	0.666667
discriminant analysis	1.000000
opportunity	0.000058
version of	0.666667
sequences .	0.222222
A speaker	0.040000
materials	0.000058
and some	0.002890
analytical	0.000058
received	0.000058
relations among	0.166667
attempts at	0.333333
or negative	0.009009
2007 .	0.400000
independent	0.000058
interaction .	0.250000
NLP The	0.042553
apply to	0.400000
`` language	0.010582
`` blocks	0.010582
the ambiguous	0.001384
a better	0.002454
prisoners	0.000058
<s> vs.	0.001537
authors claimed	0.400000
, organization	0.001123
usually done	0.062500
Examples are	0.666667
recognition from	0.016529
shallow approach	0.333333
<s> NLG	0.001537
the Northern	0.001384
upper	0.000058
S. ,	1.000000
to define	0.002656
in its	0.003745
easier to	0.250000
were found	0.048780
or using	0.009009
methods are	0.045455
area is	0.181818
, German	0.001123
<s> CLAWS	0.001537
training are	0.071429
choice is	0.250000
example for	0.024691
Vulcan	0.000058
and ELIZA	0.002890
Blind	0.000058
end of	0.250000
writing ,	0.222222
Conferences	0.000058
that NLG	0.007092
Kittredge	0.000058
Tauschek	0.000058
computationally	0.000058
be possible	0.008439
was also	0.025974
is distorted	0.004065
notations	0.000058
phrase structure	0.200000
% to	0.051282
the natural	0.001384
computers ,	0.222222
computers .	0.222222
of sublanguage	0.001783
recognition rates	0.016529
would look	0.037736
or her	0.009009
's house	0.039216
Edges	0.000058
ones .	0.200000
deal with	0.500000
level ;	0.100000
a coherent	0.002454
statistical inference	0.060606
Web-based OCR	0.666667
<s> Typical	0.001537
any topic	0.064516
domain ontologies	0.100000
but rather	0.029412
questions are	0.076923
your	0.000058
processed with	0.333333
actions .	1.000000
equivalence	0.000058
: Convert	0.019608
a heuristic	0.002454
Corpus was	0.125000
a gold	0.002454
discriminative	0.000058
with highest	0.010929
SpeechTEK	0.000058
the standard	0.001384
compare the	0.285714
MIT	0.000058
Why does	0.285714
tagging is	0.080000
work by	0.083333
subtask	0.000058
a learning	0.002454
language parsing	0.013514
earliest	0.000058
verb -LRB-	0.153846
parsing -	0.071429
parsing ,	0.071429
sponsored	0.000058
mobile	0.000058
clean	0.000058
The apple	0.010417
and sentences	0.002890
these approaches	0.047619
approximation to	0.333333
dialogue	0.000058
Wilensky	0.000058
to work	0.002656
history of	0.500000
Understanding	0.000058
FAA	0.000058
an answer	0.015152
language being	0.013514
Quechua	0.000058
Army Corps	0.500000
ambiguous and	0.166667
like a	0.071429
visit	0.000058
delta-delta coefficients	1.000000
Aerospace	0.000058
of whole	0.001783
instance of	0.142857
have keyphrases	0.019231
pronouns	0.000058
pollen level	0.153846
`` in	0.010582
more and	0.021053
cell	0.000058
1965 ,	0.500000
word ,	0.033333
and making	0.002890
addressed	0.000058
the vowel	0.001384
converting	0.000058
helicopters	0.000058
a credit	0.002454
, question	0.001123
journals	0.000058
Italian	0.000058
computed	0.000058
- and	0.125000
to their	0.002656
parsing can	0.071429
user-specified	0.000058
studies ,	0.500000
than that	0.044444
treat	0.000058
senses	0.000058
into one	0.025641
glossary	0.000058
for reading	0.007220
effect	0.000058
T unigrams	0.333333
position in	0.500000
devised	0.000058
between sentences	0.051282
model summaries	0.066667
tests the	0.500000
will likely	0.057143
classifying a	0.400000
mental processes	0.666667
utility	0.000058
to test	0.002656
Isolated ,	1.000000
applies both	0.285714
a cell	0.002454
the importance	0.001384
<s> Major	0.001537
Like	0.000058
portion	0.000058
a hybrid	0.002454
covers the	0.500000
<s> Shallow	0.001537
when given	0.057143
the part	0.001384
active	0.000058
cost	0.000058
performed in	0.200000
the Web	0.001384
`` Man	0.010582
representation language	0.105263
Rules are	0.666667
Joseph Weizenbaum	1.000000
The algorithms	0.010417
scoring	0.000058
overcome	0.000058
starts	0.000058
record of	1.000000
somewhat	0.000058
bigrams	0.000058
the TextRank	0.001384
'' has	0.010753
the state	0.001384
simultaneously	0.000058
Early	0.000058
understanding ''	0.060606
using an	0.033898
pseudo-pilot	0.000058
qualities	0.000058
A different	0.040000
, does	0.001123
manual	0.000058
social sciences	0.142857
it may	0.017094
entities ,	0.285714
lies	0.000058
approximate	0.000058
builds	0.000058
attached	0.000058
stages	0.000058
to one	0.002656
results .	0.095238
results ,	0.095238
plateaued and	1.000000
millions of	1.000000
-LRB- Lehnert	0.005420
Kurzweil Computer	0.285714
hierarchy of	1.000000
a calculator	0.002454
avoiding	0.000058
discourse -LRB-	0.055556
that humans	0.007092
useful to	0.142857
field that	0.074074
mail	0.000058
relations ,	0.166667
either a	0.200000
Please help	0.666667
declared	0.000058
into an	0.025641
analysis -RRB-	0.030769
Court	0.000058
system -LRB-	0.021505
normal	0.000058
abstractive summarization	0.333333
potential of	0.285714
Corpus tag	0.125000
are currently	0.008299
for several	0.007220
it uses	0.017094
common nouns	0.080000
on how	0.009434
a template	0.002454
systems such	0.017857
extraction -LRB-	0.064516
areas of	0.333333
maintained	0.000058
important distinction	0.125000
, what	0.001123
head hurts	1.000000
characteristics	0.000058
cluster	0.000058
-LRB- linguistics	0.005420
segment text	0.222222
of automatically	0.001783
the earliest-used	0.001384
start symbol	0.285714
aspect	0.000058
the design	0.001384
words such	0.018349
IEEE Transactions	0.666667
the extent	0.001384
in automatic	0.003745
practical	0.000058
, typewritten	0.001123
and phrases	0.002890
Wilensky ,	1.000000
of pairs	0.001783
children	0.000058
echoes ,	1.000000
much of	0.090909
translations	0.000058
results when	0.095238
of problems	0.001783
the current	0.001384
A. Lauriault\/Loriot	0.400000
OCR service	0.040816
phone ,	0.500000
Application-Oriented OCR	1.000000
along with	1.000000
response	0.000058
Generally speaking	0.400000
detected	0.000058
into French	0.025641
: the	0.019608
meaning in	0.086957
produced systems	0.222222
benefits	0.000058
pilots	0.000058
have not	0.019231
pre-existing	0.000058
sub-committee is	1.000000
fine	0.000058
LUNAR ,	0.666667
in January	0.003745
annual	0.000058
' structures	0.105263
transformations	0.000058
NLP techniques	0.042553
Shallow	0.000058
in `	0.003745
simple as	0.076923
a meaning	0.002454
question posed	0.047619
big	0.000058
cognitive	0.000058
follows	0.000058
one or	0.030769
eliminate	0.000058
consisting of	1.000000
taggers and	0.285714
wave .	0.222222
2002	0.000058
2001	0.000058
base ,	0.500000
to decide	0.002656
complex system	0.083333
questioner ,	0.500000
Swales ,	1.000000
should represent	0.105263
next stage	0.285714
and NLP	0.002890
begin with	0.666667
for statistical	0.007220
employs	0.000058
In recent	0.019048
correspond	0.000058
Russian sentences	1.000000
labor	0.000058
semantic analysis	0.095238
that words	0.007092
<s> Contrary	0.001537
<s> Edges	0.001537
of government	0.001783
improvements	0.000058
time -LRB-	0.060606
provider dictates	1.000000
is -LRB-	0.004065
a commercial	0.002454
been learned	0.029412
disciplines ,	1.000000
answer is	0.066667
input that	0.048780
Wikipedia	0.000058
Mellon	0.000058
otherwise	0.000058
Solving	0.000058
are capable	0.008299
handwriting	0.000058
recommendation ''	1.000000
Lauriault\/Loriot ,	1.000000
a component	0.002454
claimed	0.000058
sounds are	0.133333
scholars	0.000058
machine-translation	0.000058
linguistics that	0.100000
purpose graph-based	0.400000
representation of	0.105263
of statistical	0.001783
techniques for	0.086957
step ,	0.133333
step .	0.133333
occur in	0.400000
some languages	0.024096
medical records	0.333333
whole sentences	0.222222
of that	0.001783
-LRB- CSR	0.005420
substitution of	1.000000
five years	0.400000
which found	0.014493
G.	0.000058
risk	0.000058
rise	0.000058
can serve	0.011050
changed	0.000058
analysts	0.000058
heteroscedastic	0.000058
for his	0.007220
human translation	0.043478
from small	0.019231
naive	0.000058
the strength	0.001384
country .	0.500000
subjective .	0.333333
Emanuel	0.000058
generated from	0.133333
correlation	0.000058
interpretation	0.000058
One of	0.153846
William	0.000058
perception	0.000058
does a	0.200000
a strong	0.002454
Search	0.000058
understanding is	0.060606
Its	0.000058
labels	0.000058
answer type	0.066667
research attempts	0.047619
On the	0.333333
the main	0.001384
be considered	0.008439
<s> Real	0.001537
sentences -RRB-	0.026316
to text	0.002656
Dragon Systems	1.000000
informative	0.000058
by air	0.011429
-LRB- For	0.005420
of numbers	0.001783
H.	0.000058
was conducted	0.025974
constructed	0.000058
As a	0.111111
1949	0.000058
Standard	0.000058
sentences ``	0.026316
for data	0.007220
slower	0.000058
measures can	0.333333
a hard	0.002454
numbers ,	0.285714
navigation	0.000058
memory	0.000058
minimum	0.000058
stream	0.000058
The notion	0.010417
bunch of	1.000000
done by	0.181818
constituents	0.000058
Top-down parsing	1.000000
on its	0.009434
ALPAC report	1.000000
it difficult	0.017094
computer programs	0.045455
capital of	0.666667
some written	0.024096
any other	0.064516
strengths	0.000058
performance of	0.111111
entity ,	0.400000
marked for	0.666667
information is	0.043478
example by	0.024691
information in	0.043478
rules similar	0.046512
assertions	0.000058
<s> DeRose	0.001537
summary that	0.047619
harder to	0.285714
telephone	0.000058
, translation	0.001123
give the	0.500000
of social	0.001783
top T	0.400000
the topic	0.001384
edges ?	0.285714
improvement of	0.500000
Applications	0.000058
samples	0.000058
often has	0.045455
can do	0.011050
such cases	0.016260
assign a	0.400000
data used	0.025974
you have	0.153846
affective state	1.000000
distinctions	0.000058
reason ,	0.500000
LL parsers	1.000000
modules	0.000058
with different	0.010929
5	0.000058
a standard	0.002454
not used	0.017857
implementation of	1.000000
Different	0.000058
, trigram	0.001123
decisions about	0.200000
stemming	0.000058
, he	0.001123
demonstration of	0.400000
Mandarin	0.000058
return	0.000058
summaries with	0.046512
Joseph	0.000058
Alternatively ,	1.000000
he went	0.285714
relate	0.000058
enable the	1.000000
, William	0.001123
determines the	0.666667
Dictionary-based	0.000058
much larger	0.090909
transcriptions	0.000058
Recall-Oriented	0.000058
ranked highly	0.400000
translation process	0.027027
and trigrams	0.002890
him	0.000058
art	0.000058
tasks such	0.062500
distinctive	0.000058
libraries	0.000058
consecutive	0.000058
reduced .	0.500000
possible transcriptions	0.083333
rejecting ``	0.666667
content and	0.166667
whom	0.000058
reduction	0.000058
colloquially termed	1.000000
units are	0.285714
behavior	0.000058
students at	0.666667
is much	0.004065
of users	0.001783
the above	0.001384
keyphrases for	0.057143
Many different	0.166667
<s> Extrinsic	0.001537
the identification	0.001384
of systems	0.001783
Technolangue\/Easy	0.000058
is far	0.004065
Court reporting	1.000000
to such	0.002656
grouped	0.000058
the formal	0.001384
step that	0.133333
reading comprehension	0.250000
some degree	0.024096
, only	0.001123
For more	0.032787
performed ,	0.200000
common way	0.080000
meaning to	0.086957
minimizes the	1.000000
Hence	0.000058
data that	0.025974
practice	0.000058
articles in	0.250000
aircraft -LRB-	0.285714
false	0.000058
door ''	0.500000
category	0.000058
, 10	0.001123
Corpus and	0.125000
Topics	0.000058
feasible	0.000058
Gisting	0.000058
of parsing	0.001783
vocabularies	0.000058
the scope	0.001384
1990 -RRB-	0.666667
methods for	0.045455
including linguistics	0.142857
a period	0.002454
Transfer-based	0.000058
dependencies .	1.000000
closer	0.000058
a science	0.002454
one .	0.030769
the statistical	0.001384
the work	0.001384
the length	0.001384
restaurant	0.000058
good summary	0.153846
or lexical	0.009009
achieved by	0.200000
or phonemes	0.009009
concluded that	1.000000
one word	0.030769
<s> Because	0.001537
an important	0.015152
a vertex	0.002454
identical	0.000058
know	0.000058
syntax to	0.181818
lead	0.000058
Types of	1.000000
debates ,	1.000000
a binary	0.002454
has the	0.023810
`` Gismo	0.010582
texts ,	0.117647
method of	0.125000
around 6	0.375000
the example	0.002076
way that	0.125000
among other	0.375000
reviews ,	0.500000
100	0.000087
difficulty of	0.428571
They	0.000087
model is	0.100000
transfer-based	0.000087
news articles	0.230769
Lehnert	0.000087
the research	0.002076
<s> Design	0.002306
but that	0.044118
to speech	0.003984
`` classification	0.015873
extremely difficult	0.750000
complicated	0.000087
multi-document summarization	0.750000
and statistical	0.004335
are able	0.012448
a subset	0.003681
be the	0.012658
newspaper	0.000087
grounded	0.000087
Intrinsic	0.000087
a rich	0.003681
sufficient .	0.600000
out the	0.214286
a database	0.003681
recognition in	0.024793
<s> Further	0.002306
linguists	0.000087
past	0.000087
prior	0.000087
in such	0.005618
traffic controllers	1.000000
automate	0.000087
company	0.000087
continuous speech	0.500000
installed	0.000087
automatic summaries	0.130435
of interest	0.002674
to segment	0.003984
speaker .	0.166667
in NLG	0.005618
model would	0.100000
adaptation	0.000087
despite	0.000087
Michel	0.000087
Intelligence	0.000087
summarise	0.000087
As mentioned	0.166667
, Paul	0.001684
with ``	0.016393
account	0.000087
the discourse	0.002076
of his	0.002674
to set	0.003984
related tasks	0.200000
psychology ,	0.750000
and LexRank	0.004335
Discourse analysis	1.000000
so-called	0.000087
possible to	0.125000
ambiguous .	0.250000
coherence	0.000087
research ,	0.071429
OCR to	0.061224
placed	0.000087
bigram	0.000087
data sets	0.038961
separated	0.000087
1991	0.000087
1990	0.000087
1993	0.000087
models that	0.115385
occurs	0.000087
machine language	0.037975
made of	0.187500
of English	0.002674
discussions	0.000087
adjectives	0.000087
English and	0.081081
automatic evaluation	0.130435
particular ,	0.230769
turns	0.000087
regardless	0.000087
system that	0.032258
term for	0.166667
for French	0.010830
These methods	0.176471
front door	1.000000
equipment	0.000087
would require	0.056604
Weizenbaum	0.000087
In general	0.028571
a compiler	0.003681
, syntactic	0.001684
<s> Statistics	0.002306
EMR	0.000087
metric	0.000087
good candidates	0.230769
the software	0.002076
dissertation	0.000087
user .	0.214286
So	0.000087
producing	0.000087
SR	0.000087
IBM	0.000087
sentences into	0.039474
measured by	0.500000
but the	0.044118
trees ,	0.500000
ASR in	0.500000
multilingual	0.000087
this time	0.032967
<s> They	0.002306
N	0.000087
that machine	0.010638
for machine	0.010830
such ambiguity	0.024390
Statistics	0.000087
and semantic	0.004335
in all	0.005618
models .	0.115385
<s> After	0.002306
to rank	0.003984
that we	0.010638
computer-aided	0.000087
increasingly	0.000087
air traffic	0.600000
highest	0.000087
universal	0.000087
WebOCR &	0.750000
feature of	0.230769
Shepard	0.000087
and translation	0.004335
the helicopter	0.002076
`` What	0.015873
, perhaps	0.001684
which generate	0.021739
Vocabulary	0.000087
to estimate	0.003984
even if	0.111111
, Kurzweil	0.001684
initial	0.000087
on which	0.014151
use .	0.041667
discourse ,	0.083333
an attempt	0.022727
sample	0.000087
developed a	0.115385
the English	0.002076
easy to	1.000000
Piron	0.000087
Optical	0.000087
^	0.000087
IEEE	0.000087
Biden	0.000087
Digest	0.000087
AI	0.000087
different sentences	0.061224
, online	0.001684
expressions	0.000087
mentions	0.000087
constructs	0.000087
recall	0.000087
acts	0.000087
Corpus -RRB-	0.187500
services	0.000087
strategy to	0.600000
that contain	0.010638
point	0.000087
70 %	0.750000
traffic	0.000087
alternative	0.000087
derived from	0.500000
entire	0.000087
, typically	0.001684
access	0.000087
the model	0.002076
Answer	0.000087
readable	0.000087
NLG to	0.142857
profile	0.000087
training documents	0.107143
a statistical	0.003681
symbols	0.000087
Roger Schank	0.750000
score .	0.500000
page ,	0.428571
the country	0.002076
likelihood	0.000087
around the	0.375000
is known	0.006098
keyphrases that	0.085714
systems can	0.026786
See also	0.500000
be very	0.012658
periods	0.000087
an algorithm	0.022727
taking the	0.600000
the early	0.002076
Mobile	0.000087
co-occurrence	0.000087
component of	0.600000
importance of	0.500000
1960s	0.000087
Winograd	0.000087
form a	0.150000
Extraction	0.000087
supervised ''	0.187500
papers	0.000087
faster	0.000087
years later	0.142857
clarification	0.000087
unfamiliar	0.000087
manner .	0.750000
knowledge about	0.111111
to disambiguate	0.003984
Languages	0.000087
, -LRB-	0.001684
those used	0.136364
OCR is	0.061224
Rules	0.000087
The authors	0.015625
to translate	0.003984
a demonstration	0.003681
aid in	0.750000
direction	0.000087
a field	0.003681
is analyzed	0.006098
but they	0.044118
author	0.000087
\/	0.000087
information from	0.065217
all possible	0.069767
to any	0.003984
version	0.000087
naval	0.000087
produced by	0.333333
speech-recognition	0.000087
data -RRB-	0.038961
how to	0.103448
Europe ,	0.600000
NLP evaluation	0.063830
are made	0.012448
possible .	0.125000
possible ,	0.125000
<s> Often	0.002306
correct part	0.200000
sold	0.000087
Manual	0.000087
a much	0.003681
capitalized	0.000087
allowing	0.000087
model ,	0.100000
EHR	0.000087
rules can	0.069767
? -RRB-	0.250000
<s> Hidden	0.002306
, produced	0.001684
Zellig	0.000087
social networks	0.214286
In addition	0.028571
Natural Language	0.230769
linked	0.000087
produce the	0.136364
a context-free	0.003681
local	0.000087
the world	0.002076
usually in	0.093750
disagree	0.000087
its output	0.085714
addition to	0.500000
fighter aircraft	0.500000
algorithms to	0.085714
adjective or	0.428571
increasing	0.000087
Church	0.000087
More sophisticated	0.333333
summary of	0.071429
<s> So	0.002306
Please	0.000087
piece of	1.000000
increase in	0.750000
and require	0.004335
fail	0.000087
is in	0.006098
'' to	0.016129
benefit from	1.000000
Georgetown experiment	1.000000
in different	0.005618
Approaches	0.000087
is being	0.006098
learn a	0.230769
Our	0.000087
with them	0.016393
date	0.000087
Maximum	0.000087
are typically	0.012448
million	0.000087
need for	0.142857
indicate	0.000087
future	0.000087
technology ,	0.136364
walking	0.000087
morphological	0.000087
, funding	0.001684
the grammatical	0.002076
beyond the	0.500000
dimensions	0.000087
industry	0.000087
image	0.000087
taught	0.000087
agree	0.000087
language for	0.020270
rules to	0.069767
the human	0.002076
U.S. Patent	0.428571
always	0.000087
Linguistics	0.000087
showed that	0.750000
determines	0.000087
difficult problems	0.107143
problems .	0.176471
citations	0.000087
, different	0.001684
are created	0.012448
we would	0.066667
or some	0.013514
case .	0.176471
case ,	0.176471
relevance	0.000087
agreement	0.000087
there were	0.075000
line	0.000087
networks .	0.214286
led	0.000087
<s> Recall	0.002306
Several	0.000087
Political discourse	1.000000
used a	0.026549
Aided	0.000087
increased from	0.600000
clearly	0.000087
theories of	0.600000
, parsing	0.001684
surprisingly	0.000087
construction	0.000087
informativeness	0.000087
adaptive	0.000087
a suitable	0.003681
potentially	0.000087
over the	0.250000
by computer	0.017143
That is	1.000000
1971	0.000087
1970	0.000087
as English	0.010453
class of	0.750000
to machine	0.003984
global	0.000087
-LRB- NLG	0.008130
-LRB- NLP	0.008130
rarely	0.000087
Brill	0.000087
labeled	0.000087
would have	0.056604
vary in	0.500000
dedicated	0.000087
tagged	0.000087
indeed	0.000087
algorithm ,	0.107143
the real	0.002076
by human	0.017143
specific domain	0.142857
necessary for	0.300000
a comprehensive	0.003681
`` Why	0.015873
which makes	0.021739
are usually	0.012448
central	0.000087
sales	0.000087
and use	0.004335
coverage	0.000087
more reliable	0.031579
-RRB- can	0.008451
source language	0.125000
less than	0.250000
occurs in	1.000000
spontaneous	0.000087
Semantic	0.000087
<s> Current	0.002306
<s> Human	0.002306
unigram ,	0.600000
strength of	0.600000
blend	0.000087
famous	0.000087
<s> Methods	0.002306
by using	0.017143
news domain	0.230769
ontologies .	0.500000
, therefore	0.001684
AI-complete	0.000087
a translator	0.003681
and control	0.004335
depth	0.000087
program .	0.136364
into account	0.038462
Greek	0.000087
especially those	0.200000
of keyphrases	0.002674
manipulate	0.000087
The Brown	0.015625
printed text	0.250000
keep	0.000087
Generally ,	0.600000
generated .	0.200000
the front	0.002076
Recall	0.000087
be useful	0.012658
`` The	0.015873
unfamiliar input	1.000000
how they	0.103448
sizes	0.000087
controllers	0.000087
expansion	0.000087
recognizes	0.000087
discussed below	0.428571
work ,	0.125000
affect	0.000087
vector	0.000087
question processing	0.071429
tell	0.000087
An example	0.187500
keyboard	0.000087
that it	0.010638
to do	0.003984
and you	0.004335
most likely	0.051724
HMM	0.000087
from one	0.028846
matter	0.000087
a dictionary	0.003681
-LRB- which	0.008130
<s> Advanced	0.002306
quantities	0.000087
that contains	0.010638
evaluation in	0.055556
continued to	0.333333
interlingual machine	0.750000
-- the	0.120000
<s> Recent	0.002306
speed .	0.428571
to summarise	0.003984
because it	0.100000
and social	0.004335
are known	0.012448
of possible	0.002674
production	0.000087
intermediary	0.000087
another language	0.230769
Two years	0.428571
can make	0.016575
what a	0.093750
text or	0.018868
fully automatic	0.500000
students	0.000087
vertex	0.000087
rich lexicon	0.600000
What is	0.272727
system and	0.032258
of related	0.002674
construct	0.000087
words -RRB-	0.027523
Programming	0.000087
scripts	0.000087
the harder	0.002076
, like	0.001684
query	0.000087
maximum entropy	0.500000
effectively	0.000087
statistical machine	0.090909
include :	0.111111
include a	0.111111
value	0.000087
underlying	0.000087
Friday	0.000087
answered questions	0.600000
simpler	0.000087
1987	0.000087
1982	0.000087
disambiguate	0.000087
Zellig Harris	1.000000
, bigram	0.001684
data entry	0.038961
every	0.000087
post-processing	0.000087
visible	0.000087
as decision	0.010453
up with	0.136364
<s> At	0.002306
statistics .	0.375000
we have	0.066667
quite different	0.375000
be translated	0.012658
effectiveness	0.000087
has also	0.035714
take into	0.300000
a test	0.003681
medium	0.000087
it was	0.025641
be seen	0.012658
large-vocabulary	0.000087
can use	0.016575
written text	0.115385
a high	0.003681
conversations	0.000087
than one	0.066667
weighted	0.000087
sequences of	0.333333
of input	0.002674
segmentation :	0.090909
segmentation ,	0.090909
others .	0.250000
expensive ,	0.428571
be applied	0.012658
alphabet	0.000087
, regardless	0.001684
legal	0.000087
`` natural	0.015873
of several	0.002674
ICR	0.000087
sublanguage	0.000087
are given	0.012448
the summarization	0.002076
- based	0.187500
article ,	0.103448
framework .	0.750000
understanding ,	0.090909
as they	0.010453
automatic speech	0.130435
performance .	0.166667
recently	0.000087
there was	0.075000
to all	0.003984
technology is	0.136364
Examples	0.000087
in these	0.005618
useful for	0.214286
try to	1.000000
the 1950s	0.002076
sort	0.000087
, identifying	0.001684
Processing -LRB-	0.750000
The problem	0.015625
words -LRB-	0.027523
brain	0.000087
to extract	0.003984
domain ,	0.150000
layer	0.000087
success of	0.600000
markers	0.000087
in using	0.005618
definition of	0.600000
Recent	0.000087
and often	0.004335
possibility of	0.750000
is more	0.006098
discourse is	0.083333
1970s	0.000087
which will	0.021739
of applications	0.002674
evaluation would	0.055556
result of	0.272727
within the	0.166667
<s> Discourse	0.002306
how many	0.103448
across most	0.600000
previous	0.000087
that a	0.010638
work in	0.125000
work is	0.125000
on-line	0.000087
e.g. the	0.053571
theoretical	0.000087
correlate	0.000087
for QA	0.010830
, Speech	0.001684
more accurate	0.031579
; this	0.063830
-RRB- has	0.008451
That	0.000087
not words	0.026786
are delimited	0.012448
have more	0.028846
to say	0.003984
sometimes referred	0.230769
recognition software	0.024793
a corpus	0.003681
the documents	0.002076
is generated	0.006098
Sound	0.000087
the systems	0.002076
On-line	0.000087
Often	0.000087
extrinsic evaluation	0.500000
described above	0.500000
influenced by	1.000000
and related	0.004335
real world	0.333333
Fourier	0.000087
Both	0.000087
<s> Much	0.002306
internal representation	0.600000
extractive summarization	0.428571
try	0.000087
consistently	0.000087
a speech-recognition	0.003681
for Friday	0.010830
2010	0.000087
subset	0.000087
<s> Hulth	0.002306
text units	0.018868
decade	0.000087
is measured	0.006098
into text	0.038462
pragmatics	0.000087
-RRB- with	0.008451
Neural networks	0.750000
government	0.000087
produce a	0.136364
Computational Linguistics	1.000000
assess	0.000087
<s> TextRank	0.002306
for training	0.010830
data available	0.038961
not present	0.026786
containing the	0.375000
similar sentences	0.111111
<s> HMMs	0.002306
to answer	0.003984
European	0.000087
vowels	0.000087
complex sound	0.125000
an NLP	0.022727
posed	0.000087
to another	0.003984
morphemes	0.000087
Further	0.000087
For this	0.049180
takes	0.000087
degree of	0.500000
trigram	0.000087
discrete	0.000087
time-consuming	0.000087
extraction of	0.096774
redundancy	0.000087
-RRB- as	0.008451
an internal	0.022727
rates of	0.375000
1954	0.000087
In particular	0.028571
depend on	1.000000
what we	0.093750
Accuracy of	0.428571
<s> Dynamic	0.002306
summaries ,	0.069767
proved	0.000087
the POS	0.002076
uttered	0.000087
Nuance	0.000087
The main	0.015625
low	0.000087
lot	0.000087
are examples	0.012448
, often	0.001684
allows the	0.375000
control of	0.600000
OnlineOCR	0.000087
taken	0.000087
are systems	0.012448
soon	0.000087
English-like	0.000087
, both	0.001684
language input	0.020270
very different	0.073171
to allow	0.003984
grammar -RRB-	0.081081
depending on	0.750000
speech acts	0.019737
is now	0.006098
to .	0.003984
to 7	0.003984
the boundaries	0.002076
<s> Statistical	0.002306
generic	0.000087
<s> That	0.002306
more successful	0.031579
journal	0.000087
'' systems	0.016129
% -LRB-	0.076923
whose	0.000087
high level	0.166667
credit	0.000087
Also	0.000087
Language Processing	0.250000
distance	0.000087
that performance	0.010638
dog	0.000087
decided	0.000087
triples	0.000087
, at	0.001684
found in	0.214286
Georgetown	0.000087
filtered	0.000087
, probabilistic	0.001684
7 across	0.428571
correct .	0.200000
discriminate	0.000087
a problem	0.003681
depend	0.000087
programs .	0.272727
is sometimes	0.006098
and context	0.004335
of rules	0.002674
named entities	0.428571
Technology	0.000087
seen as	0.300000
subset of	1.000000
in various	0.005618
think	0.000087
little	0.000087
efficient	0.000087
Translation	0.000087
relative	0.000087
summaries is	0.069767
roughly	0.000087
'' a	0.016129
most popular	0.051724
readily	0.000087
all written	0.069767
→	0.000087
paragraph	0.000087
pioneered	0.000087
grounded in	1.000000
, ''	0.001684
LUNAR	0.000087
linguistics is	0.150000
doctors	0.000087
unigrams ,	0.250000
Patent	0.000087
be as	0.012658
be found	0.012658
There is	0.272727
real-valued	0.000087
notion of	0.750000
A number	0.060000
, semantics	0.001684
judgement	0.000087
parser is	0.187500
a task	0.003681
30	0.000087
ATNs	0.000087
high levels	0.166667
greater	0.000087
levels for	0.136364
of hand-written	0.002674
Modern	0.000087
was a	0.038961
, automatic	0.001684
been seen	0.044118
NLP systems	0.063830
Design	0.000087
any case	0.096774
summarization system	0.060000
reporting	0.000087
approaches .	0.107143
patent on	0.750000
from which	0.028846
layer of	1.000000
the last	0.002076
an input	0.022727
features are	0.115385
<s> Examples	0.002306
Web-based	0.000087
1966	0.000087
that was	0.010638
capitalization	0.000087
Cognitive	0.000087
of question	0.002674
verb or	0.230769
procedure	0.000087
on an	0.014151
suggest	0.000087
<s> Given	0.002306
50	0.000087
arbitrary	0.000087
successfully	0.000087
Much	0.000087
<s> Sentence	0.002306
whereas	0.000087
Design choices	1.000000
Also ,	1.000000
, no	0.001684
's Digest	0.058824
The difficulty	0.015625
presented in	0.500000
-LRB- now	0.008130
more general	0.031579
on this	0.014151
cases where	0.166667
representation ,	0.157895
a parser	0.003681
reference summary	0.375000
then ,	0.085714
spontaneous speech	1.000000
Speech segmentation	0.096774
, text	0.001684
separate words	0.300000
<s> Machine	0.002306
influenced	0.000087
expect	0.000087
Models	0.000087
aims	0.000087
, Robert	0.001684
right .	0.300000
compiler	0.000087
requires the	0.187500
political	0.000087
devoted to	0.600000
Interlingual	0.000087
tables	0.000087
Air	0.000087
shapes	0.000087
Friday have	1.000000
generates	0.000087
DTW	0.000087
capital	0.000087
the right	0.002076
light	0.000087
publication	0.000087
After	0.000087
the social	0.002076
that make	0.010638
to understand	0.003984
queries	0.000087
module	0.000087
and\/or	0.000087
attractive	0.000087
be expressed	0.012658
-LRB- with	0.008130
sentence boundary	0.062500
unit	0.000087
98	0.000087
analysis or	0.046154
a lot	0.003681
<s> While	0.002306
6 to	0.750000
Automatic segmentation	0.333333
release	0.000087
to both	0.003984
asked	0.000087
processing systems	0.055556
distinct from	0.428571
things	0.000087
easy	0.000087
Bayes	0.000087
in ``	0.005618
Computational	0.000087
vectors	0.000087
Constraints	0.000087
divided	0.000087
also possible	0.043478
and thus	0.004335
translation software	0.040541
course	0.000087
to high	0.003984
a different	0.003681
programming languages	0.600000
the actual	0.002076
credit card	1.000000
-LRB- how	0.008130
cosine	0.000087
-RRB- are	0.008451
for further	0.010830
Street	0.000087
attempts to	0.500000
telephony	0.000087
regardless of	1.000000
are in	0.012448
IR	0.000087
differ	0.000087
the definition	0.002076
dependent	0.000087
<s> Approaches	0.002306
movie	0.000087
rejecting	0.000087
for computer	0.010830
great	0.000087
the gold	0.002076
communicative	0.000087
phenomenon of	0.600000
either as	0.300000
pages ,	0.428571
systems is	0.026786
words of	0.027523
is essentially	0.006098
consideration	0.000087
rate of	0.272727
evaluation .	0.055556
evaluation ,	0.055556
comprehension .	0.428571
phrases and	0.187500
Hulth	0.000087
also called	0.043478
characters can	0.187500
we can	0.066667
Example-based	0.000087
a result	0.003681
BLEU	0.000087
automatically generated	0.142857
rule	0.000087
as its	0.010453
discontinuous	0.000087
Journal	0.000087
what is	0.093750
National	0.000087
Instead	0.000087
like ``	0.107143
<s> On-line	0.002306
clues	0.000087
engines	0.000087
therefore it	0.600000
Reader	0.000087
computer .	0.068182
and language	0.004335
algorithms have	0.085714
Although the	0.375000
into words	0.038462
and ,	0.004335
be filtered	0.012658
marked	0.000087
market	0.000087
<s> Please	0.002306
<s> ELIZA	0.002306
begin	0.000087
Political	0.000087
the program	0.002076
Markov Models	0.166667
available .	0.176471
ones ,	0.300000
benefit	0.000087
access to	1.000000
comparison	0.000087
most parts	0.051724
this area	0.032967
the author	0.002076
for evaluating	0.010830
a graph	0.003681
scanner	0.000087
scanned	0.000087
ability to	0.750000
, machine	0.001684
placed in	1.000000
trained	0.000087
of yesterday	0.002674
is likely	0.006098
tried	0.000087
actually	0.000087
that these	0.010638
event	0.000087
and an	0.004335
represents a	0.750000
The process	0.015625
difficult than	0.107143
parsing .	0.107143
the overall	0.002076
of any	0.002674
HMM-based	0.000087
combine	0.000087
media ,	0.500000
University of	0.333333
the need	0.002076
in-depth	0.000087
simulation	0.000087
to process	0.003984
At	0.000087
and evaluation	0.004335
front	0.000087
J.	0.000087
a threshold	0.003681
exactly	0.000087
Foucault	0.000087
the potential	0.002076
in fighter	0.005618
By	0.000087
a table	0.003681
input to	0.073171
converted	0.000087
piece	0.000087
call	0.000087
The Georgetown	0.015625
and after	0.004335
this type	0.032967
Speech Recognition	0.096774
the output	0.002076
three	0.000087
the appropriate	0.002076
using OCR	0.050847
is typically	0.006098
paradigm	0.000087
candidate	0.000087
background	0.000087
perform a	0.272727
1990s	0.000087
<s> Also	0.002306
and semantics	0.004335
<s> Our	0.002306
bites	0.000087
developments	0.000087
DA	0.000087
precise	0.000087
conjunction	0.000087
the structure	0.002076
Michel Foucault	1.000000
mark	0.000087
running	0.000087
using NLG	0.050847
models -LRB-	0.115385
extensive	0.000087
notably	0.000087
of dividing	0.002674
task-based evaluations	0.750000
result ,	0.272727
a second	0.003681
recognizes the	1.000000
mental	0.000087
text and	0.018868
instances	0.000087
with word	0.016393
built	0.000087
build	0.000087
dividing	0.000087
98 %	1.000000
act as	0.750000
consonants	0.000087
all ,	0.069767
same time	0.120000
yesterday	0.000087
the space	0.002076
to better	0.003984
other things	0.042857
in very	0.005618
Reader 's	1.000000
GRASSHOPPER	0.000087
2000	0.000087
2006	0.000087
2004	0.000087
2009	0.000087
human language	0.065217
parsed by	0.750000
stock	0.000087
lines	0.000087
descriptive	0.000087
mention	0.000087
Instead of	1.000000
CSR	0.000087
, would	0.001684
preliminary	0.000087
absorbing	0.000087
routing	0.000087
word segmentation	0.050000
helped	0.000087
Task	0.000087
moderate to	0.600000
broken into	0.600000
thought	0.000087
sentences can	0.039474
convey	0.000087
bigram ,	1.000000
tasks in	0.093750
human .	0.065217
integrated	0.000087
a general	0.003681
error rates	0.250000
fonts	0.000087
<s> Several	0.002306
the moderate	0.002076
portable	0.000087
, article	0.001684
blind people	0.750000
1978	0.000087
or any	0.013514
probabilities of	0.272727
<s> Keyphrase	0.002306
, David	0.001684
translation and	0.040541
corpus linguistics	0.096774
source documents	0.125000
differences	0.000087
the content	0.002076
versions	0.000087
neighbors	0.000087
<s> Languages	0.002306
another .	0.230769
input ,	0.073171
unigrams in	0.250000
factors	0.000087
verbs ,	0.600000
the examples	0.002076
conversion	0.000087
quantity	0.000087
year .	0.500000
review	0.000087
utterance	0.000087
more or	0.031579
with values	0.016393
IE	0.000087
in addition	0.005618
code .	0.428571
incorrect	0.000087
researchers have	0.300000
Discourse	0.000087
functioning	0.000087
will generate	0.085714
time and	0.090909
to resolve	0.003984
Intelligent	0.000087
be expected	0.012658
goal is	0.428571
British	0.000087
font	0.000087
Pang	0.000087
graph is	0.230769
of computational	0.002674
edge	0.000087
have increased	0.028846
the full	0.002076
not easily	0.026786
speech to	0.019737
searching	0.000087
to convey	0.003984
apple	0.000087
and how	0.004335
written language	0.115385
Northern	0.000087
preposition ,	1.000000
barmaid -RRB-	0.500000
Recognition ''	0.375000
thousands	0.000087
view	0.000087
Systems based	0.250000
to assign	0.003984
ELIZA ,	0.333333
the theory	0.002076
the specific	0.002076
preposition	0.000087
heuristic	0.000087
texts .	0.176471
table of	0.428571
are now	0.016598
estimate	0.000116
a larger	0.004908
recognize the	0.444444
some cases	0.048193
extent	0.000116
split	0.000116
warping	0.000116
The term	0.020833
role	0.000116
M.	0.000116
address	0.000116
word is	0.066667
word in	0.066667
rules of	0.093023
<s> How	0.003075
threshold	0.000116
, was	0.002246
methods ,	0.090909
them ,	0.210526
disabilities	0.000116
above ,	0.307692
accuracy of	0.129032
or ``	0.018018
time .	0.121212
followed	0.000116
weather forecasts	0.571429
door	0.000116
recognition performance	0.033058
to what	0.005312
ambiguities	0.000116
both to	0.129032
methods to	0.090909
for natural	0.014440
Viterbi	0.000116
camp	0.000116
to parse	0.005312
the result	0.002768
If the	0.400000
but this	0.058824
PC	0.000116
research .	0.095238
identity	0.000116
become	0.000116
are generally	0.016598
string of	1.000000
developed the	0.153846
in one	0.007491
machines	0.000116
1998	0.000116
the parser	0.002768
analysis -LRB-	0.061538
strong	0.000116
concept	0.000116
blind	0.000116
regard to	0.800000
because the	0.133333
World Wide	0.571429
decide	0.000116
ask	0.000116
means that	0.666667
context and	0.121212
France	0.000116
text-to-speech	0.000116
questioner	0.000116
of all	0.003565
meet	0.000116
problem ,	0.090909
intrinsic	0.000116
controller	0.000116
be made	0.016878
broad	0.000116
overlap	0.000116
UK	0.000116
or more	0.018018
Corporation	0.000116
personal	0.000116
open	0.000116
OCR systems	0.081633
problem in	0.090909
the type	0.002768
deal	0.000116
January	0.000116
use ,	0.055556
make a	0.200000
In some	0.038095
while others	0.200000
group	0.000116
<s> Moreover	0.003075
Moreover	0.000116
perspective	0.000116
Roger	0.000116
words into	0.036697
depending	0.000116
of one	0.003565
Processing	0.000116
1965	0.000116
summarization ,	0.080000
decision	0.000116
As in	0.222222
becomes	0.000116
determining the	0.666667
, James	0.002246
Systems that	0.333333
need a	0.190476
task ,	0.095238
analysis :	0.061538
that were	0.014184
a method	0.004908
that some	0.014184
understanding the	0.121212
late 1980s	0.444444
which means	0.028986
what the	0.125000
question is	0.095238
picture	0.000116
representations	0.000116
had a	0.285714
: This	0.039216
with some	0.021858
\*	0.000116
Grass pollen	1.000000
diversity	0.000116
was the	0.051948
and text	0.005780
decision trees	1.000000
needs to	0.400000
of large	0.003565
the way	0.002768
to as	0.005312
viewed as	1.000000
nice	0.000116
explore	0.000116
of other	0.003565
Turney 's	0.444444
ability	0.000116
rare	0.000116
`` learning	0.021164
volume	0.000116
we will	0.088889
top-down	0.000116
Dynamic time	0.800000
tag sets	0.250000
represents	0.000116
financial	0.000116
life	0.000116
fairly	0.000116
Wide Web	1.000000
collections	0.000116
Grass	0.000116
of OCR	0.003565
<s> Parsing	0.003075
computer science	0.090909
studies	0.000116
give	0.000116
and there	0.005780
records	0.000116
possibility	0.000116
'' with	0.021505
language to	0.027027
knowledge of	0.148148
act	0.000116
on any	0.018868
was used	0.051948
states	0.000116
machine-learning	0.000116
science ,	0.400000
is based	0.008130
the probabilities	0.002768
psychology	0.000116
some kind	0.048193
has focused	0.047619
model that	0.133333
POS tagger	0.307692
applications .	0.160000
applications ,	0.160000
blocks	0.000116
because they	0.133333
NLP -RRB-	0.085106
CLAWS	0.000116
values of	0.500000
related to	0.266667
OCR software	0.081633
this ,	0.043956
dogs ''	0.571429
output .	0.153846
techniques to	0.173913
study	0.000116
the fact	0.002768
What are	0.363636
translating	0.000116
during the	0.400000
manner	0.000116
notion	0.000116
output of	0.153846
patent	0.000116
During	0.000116
in their	0.007491
inference	0.000116
language use	0.027027
, neural	0.002246
algorithm .	0.142857
concerned with	0.800000
speech -LRB-	0.026316
be viewed	0.016878
developing	0.000116
, of	0.002246
Latin	0.000116
of nodes	0.003565
base	0.000116
put	0.000116
evaluate	0.000116
instead of	0.571429
multi-document	0.000116
Neural	0.000116
products	0.000116
social media	0.285714
at a	0.058824
it becomes	0.034188
in another	0.007491
limit	0.000116
WebOCR	0.000116
Summarization	0.000116
process to	0.111111
on .	0.018868
the U.S.	0.002768
marks	0.000116
string	0.000116
the desired	0.002768
template	0.000116
are likely	0.016598
summaries of	0.093023
effort	0.000116
growing	0.000116
Methods	0.000116
tasks ,	0.125000
tasks .	0.125000
analyze	0.000116
sets of	0.363636
-RRB- to	0.011268
n't	0.000116
structure of	0.333333
to form	0.005312
fall	0.000116
the UK	0.002768
token	0.000116
interactive	0.000116
field .	0.148148
much more	0.181818
per	0.000116
These systems	0.235294
boundaries .	0.363636
themselves	0.000116
are very	0.016598
tests	0.000116
aid	0.000116
efforts have	0.571429
combining	0.000116
are still	0.016598
James	0.000116
-LRB- See	0.010840
it has	0.034188
representation .	0.210526
delimited	0.000116
`` dogs	0.021164
German	0.000116
<s> OCR	0.003075
text that	0.025157
explicitly	0.000116
information .	0.086957
Army	0.000116
the data	0.002768
applying	0.000116
design	0.000116
serve as	0.800000
to get	0.005312
person ,	0.210526
robust	0.000116
vendors	0.000116
associated	0.000116
deterministic	0.000116
this article	0.043956
but it	0.058824
a QA	0.004908
looks	0.000116
given a	0.166667
the reader	0.002768
the basis	0.002768
Document	0.000116
range of	0.571429
increase	0.000116
% accuracy	0.102564
abstraction	0.000116
showed	0.000116
country	0.000116
logic	0.000116
quantitative	0.000116
support	0.000116
a particular	0.004908
devices	0.000116
This problem	0.063492
tasks are	0.125000
as to	0.013937
binary	0.000116
robustness	0.000116
an approach	0.030303
returned	0.000116
6	0.000116
the training	0.002768
termed	0.000116
Michael	0.000116
recent years	0.500000
for speech	0.014440
of what	0.003565
questions about	0.153846
speech -RRB-	0.026316
find the	0.307692
reliable	0.000116
focus on	0.571429
parsed	0.000116
to select	0.005312
resulting	0.000116
native	0.000116
embedded	0.000116
corpus -RRB-	0.129032
distribution	0.000116
only the	0.105263
the top	0.002768
sentence boundaries	0.083333
95 %	1.000000
card	0.000116
context-free grammars	0.363636
identity of	1.000000
history	0.000116
reason	0.000116
the analysis	0.002768
speech for	0.026316
and data	0.005780
describing	0.000116
; and	0.085106
evaluation of	0.074074
Words	0.000116
when a	0.114286
remains	0.000116
started	0.000116
deals with	1.000000
is difficult	0.008130
-RRB- in	0.011268
procedures	0.000116
to measure	0.005312
NLP system	0.085106
suitable	0.000116
it would	0.034188
many different	0.076923
when the	0.114286
Some of	0.190476
the results	0.002768
meanings	0.000116
finite state	0.800000
a program	0.004908
identifying the	0.666667
the final	0.002768
derivation	0.000116
also been	0.057971
coefficients	0.000116
knowledge base	0.148148
speakers	0.000116
through the	0.500000
solve	0.000116
references	0.000116
that appear	0.014184
difference	0.000116
90 %	1.000000
the start	0.002768
text is	0.025157
and natural	0.005780
learning ,	0.093023
learning .	0.093023
extremely	0.000116
in most	0.007491
semantics ,	0.285714
pattern recognition	0.666667
evaluation is	0.074074
take advantage	0.400000
translation .	0.054054
results are	0.190476
this task	0.043956
manually	0.000116
approaches :	0.142857
the Viterbi	0.002768
some form	0.048193
Moreover ,	1.000000
will not	0.114286
processing -LRB-	0.074074
to make	0.005312
has a	0.047619
report	0.000116
judge	0.000116
the questioner	0.002768
1	0.000116
place	0.000116
examples .	0.166667
of more	0.003565
ideas	0.000116
the phrase	0.002768
task-based	0.000116
helicopter	0.000116
<s> Since	0.003075
all of	0.093023
reduced	0.000116
algorithms .	0.114286
the person	0.002768
native speaker	1.000000
The following	0.020833
a more	0.004908
characterized	0.000116
in context	0.007491
70	0.000116
'' that	0.021505
Keyphrase	0.000116
grammar .	0.108108
grammar ,	0.108108
to compare	0.005312
criteria	0.000116
Google	0.000116
The task	0.020833
use a	0.055556
as is	0.013937
class	0.000116
of training	0.003565
90	0.000116
95	0.000116
theory ,	0.307692
random walk	0.571429
, Michael	0.002246
with regard	0.021858
but not	0.058824
alone	0.000116
to provide	0.005312
, although	0.002246
going	0.000116
the summaries	0.002768
power	0.000116
technologies	0.000116
Wide	0.000116
consider	0.000116
obtained by	0.571429
of summaries	0.003565
uses a	0.285714
system needs	0.043011
interface	0.000116
improved	0.000116
time warping	0.121212
human ratings	0.086957
appropriate	0.000116
elements	0.000116
databases .	0.500000
purposes	0.000116
singular	0.000116
produces	0.000116
basis of	0.666667
viewed	0.000116
more than	0.042105
trivial	0.000116
the extraction	0.002768
began to	0.571429
the possibility	0.002768
very similar	0.097561
information to	0.086957
President	0.000116
are often	0.016598
could be	0.250000
the goal	0.002768
person 's	0.210526
of written	0.003565
properties	0.000116
emotional	0.000116
advantage of	0.800000
can express	0.022099
algorithms for	0.114286
is still	0.008130
pauses	0.000116
annotation	0.000116
context ,	0.121212
Viterbi algorithm	1.000000
<s> During	0.003075
available ,	0.235294
improvement	0.000116
level ,	0.200000
to many	0.005312
business	0.000116
make soft	0.200000
application of	0.285714
engine .	0.666667
; the	0.085106
clear	0.000116
parameters	0.000116
probably	0.000116
translated	0.000116
-RRB- or	0.011268
letters .	0.400000
Arabic	0.000116
to ``	0.005312
-LRB- that	0.010840
the identity	0.002768
to evaluate	0.005312
In fact	0.038095
require the	0.181818
known keyphrases	0.153846
hand-printed	0.000116
extract	0.000116
restricted	0.000116
DARPA	0.000116
tagger ,	0.444444
rules that	0.093023
paragraphs	0.000116
covers	0.000116
years .	0.190476
of computer	0.003565
to meet	0.005312
critical	0.000116
resolution	0.000116
to solve	0.005312
: The	0.039216
to new	0.005312
E.	0.000116
, more	0.002246
-LRB- also	0.010840
resolve	0.000116
entry	0.000116
than the	0.088889
David	0.000116
was able	0.051948
constraints	0.000116
or less	0.018018
position	0.000116
statistical methods	0.121212
soft	0.000116
in some	0.007491
phone	0.000116
a wave	0.004908
the issue	0.002768
free	0.000116
to perform	0.005312
discourse and	0.111111
-LRB- most	0.010840
, deciding	0.002246
a good	0.004908
features of	0.153846
wide	0.000116
a process	0.004908
, that	0.002246
earlier	0.000116
symbol	0.000116
and Language	0.005780
framework	0.000116
script	0.000116
1950s	0.000116
deals	0.000116
Robert	0.000116
<s> What	0.003075
interlingual	0.000116
conversation	0.000116
examples and	0.166667
one ,	0.061538
getting	0.000116
errors	0.000145
language generation	0.033784
abbreviations	0.000145
therefore	0.000145
verb ,	0.384615
are not	0.020747
fact ,	0.454545
service	0.000145
Generally	0.000145
Then	0.000145
document ,	0.138889
rich	0.000145
at least	0.073529
Advanced	0.000145
MT	0.000145
which was	0.036232
<s> Unsupervised	0.003843
formed	0.000145
In contrast	0.047619
full	0.000145
intended	0.000145
organization	0.000145
system was	0.053763
definition	0.000145
recognizing	0.000145
DeRose	0.000145
last	0.000145
speaking ,	0.625000
information retrieval	0.108696
considerable	0.000145
process .	0.138889
document .	0.138889
video	0.000145
the subject	0.003460
patterns	0.000145
grammar rules	0.135135
require a	0.227273
entropy	0.000145
to distinguish	0.006640
to take	0.006640
it .	0.042735
the user	0.003460
occur	0.000145
Parsing	0.000145
develop	0.000145
area of	0.454545
learned	0.000145
in general	0.009363
phenomenon	0.000145
the quality	0.003460
ranked	0.000145
<s> Then	0.003843
Current	0.000145
`` supervised	0.026455
systems have	0.044643
NLP .	0.106383
special	0.000145
times	0.000145
documents -LRB-	0.131579
<s> Once	0.003843
and are	0.007225
<s> Question	0.003843
the evaluation	0.003460
<s> Evaluation	0.003843
combination	0.000145
problem is	0.113636
Voice	0.000145
computer program	0.113636
Schank	0.000145
enough	0.000145
across	0.000145
American	0.000145
in machine	0.009363
express	0.000145
the development	0.003460
tag set	0.312500
success	0.000145
conducted	0.000145
want to	0.833333
sentences that	0.065789
algorithm is	0.178571
are based	0.020747
setting	0.000145
understanding of	0.151515
standards	0.000145
of sentiment	0.004456
the known	0.003460
spaces	0.000145
pilot	0.000145
not the	0.044643
error rate	0.416667
called ``	0.277778
, John	0.002807
precision	0.000145
<s> Generally	0.003843
assumptions	0.000145
source text	0.208333
cursive	0.000145
our	0.000145
of information	0.004456
identification	0.000145
learning algorithms	0.116279
choices	0.000145
Human	0.000145
phrases .	0.312500
, by	0.002807
solved	0.000145
2	0.000145
project ,	0.384615
than a	0.111111
action	0.000145
closely	0.000145
, since	0.002807
which can	0.036232
'' as	0.026882
used .	0.044248
its own	0.142857
the ``	0.003460
forecasts	0.000145
stage	0.000145
count	0.000145
classifying	0.000145
strength	0.000145
coherent	0.000145
of documents	0.004456
appears	0.000145
explicit	0.000145
shown	0.000145
objective	0.000145
comes	0.000145
trying	0.000145
be more	0.021097
written languages	0.192308
ROUGE-1	0.000145
substantial	0.000145
context-free grammar	0.454545
finding	0.000145
run	0.000145
of human	0.004456
rules ,	0.116279
experiment	0.000145
a short	0.006135
done in	0.454545
Information	0.000145
Sentence	0.000145
dynamic	0.000145
never	0.000145
distinction	0.000145
contrast ,	0.625000
system to	0.053763
answered	0.000145
entity	0.000145
a natural	0.006135
according	0.000145
4	0.000145
broken	0.000145
refers	0.000145
found that	0.357143
of semantic	0.004456
'' by	0.026882
'' can	0.026882
have many	0.048077
to some	0.006640
learning algorithm	0.116279
been used	0.073529
of evaluation	0.004456
supervised learning	0.312500
in turn	0.009363
does not	0.500000
already	0.000145
serve	0.000145
approach is	0.142857
languages such	0.100000
but also	0.073529
to identify	0.006640
it into	0.042735
accommodate	0.000145
advantage	0.000145
groups	0.000145
possibilities	0.000145
a specific	0.006135
language is	0.033784
include the	0.185185
provided	0.000145
communication	0.000145
for instance	0.018051
speech segmentation	0.032895
due	0.000145
strategy	0.000145
trying to	1.000000
lower	0.000145
weights	0.000145
issues	0.000145
desired	0.000145
below	0.000145
commands	0.000145
sufficient	0.000145
capabilities	0.000145
the World	0.003460
analyses	0.000145
Paul	0.000145
later ,	0.500000
the more	0.003460
, also	0.002807
worked	0.000145
a way	0.006135
resource	0.000145
were developed	0.121951
the two	0.003460
internal	0.000145
comprehensive	0.000145
having	0.000145
<s> Each	0.003843
chosen	0.000145
Once	0.000145
selecting	0.000145
English .	0.135135
theories	0.000145
Analysis	0.000145
other hand	0.071429
Dynamic	0.000145
each of	0.111111
air	0.000145
within a	0.277778
'' or	0.026882
many other	0.096154
be able	0.021097
looking	0.000145
directly	0.000145
determine if	0.217391
equivalent	0.000145
at all	0.073529
assign	0.000145
authors	0.000145
While	0.000145
conditions	0.000145
distinguish	0.000145
In this	0.047619
generating	0.000145
look	0.000145
the term	0.003460
syntax ,	0.454545
be done	0.021097
summarization systems	0.100000
-LRB- a	0.013550
processes	0.000145
and more	0.007225
Sentiment analysis	0.833333
is then	0.010163
present in	0.833333
structures	0.000145
extracting	0.000145
modern	0.000145
up to	0.227273
against	0.000145
to develop	0.006640
<s> With	0.003843
12	0.000145
largely	0.000145
matching	0.000145
component	0.000145
Europe	0.000145
between discourse	0.128205
least	0.000145
, usually	0.002807
purpose	0.000145
objects	0.000145
1980s ,	0.555556
with an	0.027322
POS tagging	0.384615
taking	0.000145
The relations	0.026042
actual	0.000145
under	0.000145
top	0.000145
the features	0.003460
a major	0.006135
transform	0.000145
<s> Accuracy	0.003843
name	0.000145
of such	0.004456
algorithms ,	0.142857
it to	0.042735
regard	0.000145
sailor	0.000145
context of	0.151515
<s> On	0.003843
amount of	1.000000
plural	0.000145
used as	0.044248
walk	0.000145
the information	0.003460
as those	0.017422
-LRB- and	0.013550
reported	0.000145
reports	0.000145
concepts	0.000145
most of	0.086207
implemented	0.000145
these systems	0.119048
Scotland	0.000145
of NLP	0.004456
programming	0.000145
ATC	0.000145
textual	0.000145
in other	0.009363
unigram	0.000145
concerned	0.000145
quality of	0.500000
Machine translation	0.555556
approaches to	0.178571
in English	0.009363
relations between	0.416667
verbs	0.000145
evaluating	0.000145
QA system	0.238095
examples of	0.208333
existing	0.000145
opinion	0.000145
for this	0.018051
testing	0.000145
allow	0.000145
<s> Word	0.003843
an adjective	0.037879
a complex	0.006135
increased	0.000145
five	0.000145
and it	0.007225
designed to	0.714286
The most	0.026042
the rules	0.003460
as possible	0.017422
scores	0.000145
devoted	0.000145
ROUGE	0.000145
according to	1.000000
3	0.000145
analyzed	0.000145
documents .	0.131579
amount	0.000145
analyzing	0.000145
to which	0.006640
learning ''	0.116279
RCA	0.000145
fact that	0.454545
A.	0.000145
control	0.000145
an example	0.037879
connected	0.000145
document summarization	0.138889
gold standard	0.833333
be achieved	0.021097
segments	0.000145
i.e. the	0.263158
campaign	0.000145
went	0.000145
each word	0.111111
answer to	0.166667
did	0.000145
years ,	0.238095
state of	0.357143
mining	0.000145
or even	0.022523
D.	0.000145
moderate	0.000145
morphology ,	0.714286
particularly	0.000145
itself	0.000145
2007	0.000145
neural network	0.333333
NLG systems	0.238095
collection	0.000145
identified	0.000145
so on	0.166667
demonstration	0.000145
<s> ``	0.003843
`` the	0.026455
<s> Sentiment	0.003843
finite	0.000145
surrounding	0.000145
classes	0.000145
isolated	0.000145
advanced	0.000145
refers to	1.000000
the nature	0.003460
typewritten	0.000145
to each	0.006640
research and	0.119048
components	0.000145
of language	0.004456
Since	0.000145
other languages	0.071429
became	0.000145
for some	0.018051
Speech and	0.161290
of some	0.004456
apply	0.000145
classification ''	0.294118
candidates	0.000145
may not	0.096154
has to	0.059524
dependency	0.000145
of questions	0.004456
space	0.000145
aspects of	0.857143
<s> But	0.004612
want	0.000174
nature	0.000174
Sentiment	0.000174
to generate	0.007968
task is	0.142857
it can	0.051282
On	0.000174
to this	0.007968
resources	0.000174
systems of	0.053571
provide	0.000174
is called	0.012195
R.	0.000174
year	0.000174
to learn	0.007968
boundary	0.000174
analysis .	0.092308
a sequence	0.007362
recognition -LRB-	0.049587
Treebank	0.000174
determining	0.000174
summarization is	0.120000
key	0.000174
real-world	0.000174
described	0.000174
general ,	0.272727
before	0.000174
basis	0.000174
because of	0.200000
Each	0.000174
approach to	0.171429
identifying	0.000174
images	0.000174
a chunk	0.007362
that has	0.021277
Hidden Markov	1.000000
most common	0.103448
presented	0.000174
translate	0.000174
Computer	0.000174
the document	0.004152
a ``	0.007362
direct	0.000174
and their	0.008671
' ,	0.315789
generate a	0.333333
the correct	0.004152
research in	0.142857
The system	0.031250
identify the	0.500000
wrote	0.000174
degree	0.000174
abstractive	0.000174
perhaps	0.000174
in terms	0.011236
computational linguistics	0.600000
turn	0.000174
effective	0.000174
vary	0.000174
that have	0.021277
a noun	0.007362
letter	0.000174
score	0.000174
PageRank	0.000174
attempt to	1.000000
acoustic	0.000174
the context	0.004152
Canada	0.000174
section	0.000174
evaluations	0.000174
must be	0.428571
relationship	0.000174
expressed	0.000174
problems ,	0.352941
defined	0.000174
, determine	0.003369
so that	0.200000
+	0.000174
See	0.000174
left	0.000174
size	0.000174
media	0.000174
is one	0.012195
describe	0.000174
they can	0.150000
developed in	0.230769
fully	0.000174
deciding	0.000174
trees	0.000174
Furthermore	0.000174
signal	0.000174
rules .	0.139535
English ,	0.162162
summarization .	0.120000
ASR	0.000174
addition	0.000174
recognized	0.000174
, human	0.003369
medical	0.000174
fields	0.000174
phonemes	0.000174
continuous	0.000174
nouns ,	0.666667
nature of	1.000000
, when	0.003369
Markov models	0.333333
to recognize	0.007968
language ,	0.040541
areas	0.000174
summary ,	0.142857
, one	0.003369
we need	0.133333
input data	0.146341
maximum	0.000174
But	0.000174
Hidden	0.000174
Penn Treebank	0.666667
the time	0.004152
systems were	0.053571
<s> When	0.004612
measures	0.000174
measured	0.000174
, can	0.003369
might be	0.230769
shallow	0.000174
domain .	0.300000
T	0.000174
own	0.000174
sentences to	0.078947
research has	0.142857
logical	0.000174
SHRDLU	0.000174
and so	0.008671
how well	0.206897
refer	0.000174
gold	0.000174
using the	0.101695
refer to	1.000000
means	0.000174
to automatically	0.007968
QA systems	0.285714
that ``	0.021277
all the	0.139535
approximation	0.000174
forms	0.000174
summaries .	0.139535
Unsupervised	0.000174
the sentence	0.004152
extraction ,	0.193548
the next	0.004152
, though	0.003369
processed	0.000174
corresponding	0.000174
barmaid	0.000174
attempt	0.000174
reviews	0.000174
models for	0.230769
hard	0.000174
<s> Furthermore	0.004612
pattern	0.000174
match	0.000174
although	0.000174
represented	0.000174
rank	0.000174
too	0.000174
each other	0.133333
normalization	0.000174
There are	0.545455
environment	0.000174
engine	0.000174
systems use	0.053571
tags	0.000174
the graph	0.004152
also known	0.086957
additional	0.000174
the words	0.004152
present	0.000174
Text	0.000174
been applied	0.088235
Furthermore ,	1.000000
structured	0.000174
different from	0.122449
select	0.000174
, each	0.003369
fighter	0.000174
such a	0.048780
involved	0.000174
tools	0.000174
extrinsic	0.000174
a series	0.007362
relationships	0.000174
noun ,	0.428571
and is	0.008671
network	0.000174
text -LRB-	0.037736
case of	0.352941
the translation	0.004152
derived	0.000174
beyond	0.000174
mentioned	0.000174
overall	0.000174
importance	0.000174
ontologies	0.000174
sources	0.000174
a language	0.007362
subjective	0.000174
a verb	0.007362
involve	0.000174
rely on	0.857143
attempts	0.000174
predict	0.000174
is very	0.012195
systems ,	0.053571
scale	0.000174
adjacent	0.000174
sentence ,	0.125000
written by	0.230769
mainly	0.000174
original text	0.461538
by hand	0.034286
Speaker	0.000174
a new	0.007362
, this	0.003369
hand-written rules	0.857143
and even	0.008671
working	0.000203
edges	0.000203
next	0.000203
greatly	0.000203
entities	0.000203
a machine	0.008589
compared	0.000203
obtained	0.000203
dogs	0.000203
which has	0.050725
example of	0.086420
a list	0.008589
product	0.000203
start	0.000203
7	0.000203
<s> He	0.005380
Two	0.000203
Other	0.000203
series of	0.875000
US	0.000203
words and	0.064220
making	0.000203
We	0.000203
get	0.000203
the number	0.004844
i.e. ,	0.368421
numbers	0.000203
expensive	0.000203
Accuracy	0.000203
create a	0.411765
interest in	0.636364
analysis ,	0.107692
form of	0.350000
a sound	0.008589
of data	0.006239
discussed	0.000203
processing .	0.129630
probabilistic	0.000203
higher	0.000203
range	0.000203
For instance	0.114754
text into	0.044025
in natural	0.013109
why	0.000203
not only	0.062500
weather	0.000203
automated	0.000203
current	0.000203
reasoning	0.000203
a question	0.008589
code	0.000203
recognition accuracy	0.057851
appear in	0.437500
nodes	0.000203
classifier	0.000203
punctuation	0.000203
chunk of	1.000000
the task	0.004844
Kurzweil	0.000203
a document	0.008589
<s> Automatic	0.005380
'' in	0.037634
speed	0.000203
, i.e.	0.003930
read	0.000203
a variety	0.008589
, on	0.003930
the United	0.004844
<s> Natural	0.005380
probability	0.000203
hidden Markov	0.875000
. ''	0.437500
required	0.000203
chunk	0.000203
contexts	0.000203
accurate	0.000203
artificial intelligence	0.636364
he	0.000203
tokens	0.000203
development of	0.583333
modeling	0.000203
accuracy .	0.225806
digital	0.000203
morphology	0.000203
<s> Although	0.005380
designed	0.000203
text segmentation	0.044025
compare	0.000203
idea	0.000203
for each	0.025271
understand	0.000203
named	0.000203
names	0.000203
OCR ,	0.142857
<s> Two	0.005380
respect to	1.000000
random	0.000203
rely	0.000203
recognition and	0.057851
taggers	0.000203
sequence of	0.875000
statistical models	0.212121
includes	0.000203
systems that	0.062500
corpus of	0.225806
levels of	0.318182
table	0.000203
States	0.000203
four	0.000203
Word	0.000203
The first	0.036458
sentences are	0.092105
likely to	0.437500
aspects	0.000203
waves	0.000203
United States	0.777778
created	0.000203
applies	0.000203
to include	0.009296
of sentences	0.006239
terms of	0.538462
positive	0.000203
more difficult	0.073684
Why	0.000203
management	0.000203
Question	0.000203
page	0.000203
-LRB- as	0.018970
translator	0.000203
World	0.000203
topics	0.000203
potential	0.000203
meaning of	0.304348
deep	0.000203
text to	0.044025
also be	0.101449
Chinese	0.000203
relevant	0.000203
proper	0.000203
and then	0.010116
part-of-speech tagging	0.466667
expected	0.000203
focus	0.000203
adjective	0.000203
hand ,	0.500000
goal	0.000203
creating	0.000203
evaluated	0.000203
depends on	0.875000
recognition .	0.057851
in speech	0.013109
smaller	0.000203
extractive	0.000203
so the	0.233333
instead	0.000203
the following	0.004844
units	0.000203
<s> Other	0.005380
<s> We	0.005380
say	0.000203
pages	0.000203
words or	0.064220
stationary	0.000203
hand-written	0.000203
certain	0.000203
How	0.000203
currently	0.000203
with respect	0.038251
this problem	0.076923
and in	0.010116
context .	0.212121
With	0.000203
, not	0.003930
between the	0.179487
rule-based	0.000203
of each	0.006239
harder	0.000203
began	0.000203
-RRB- of	0.019718
some other	0.084337
linear	0.000203
technique	0.000203
When	0.000203
ranking	0.000203
published	0.000203
distinct	0.000203
retrieval	0.000203
difficulty	0.000203
in order	0.013109
aircraft	0.000203
, many	0.003930
they are	0.175000
sophisticated	0.000203
progress	0.000203
level of	0.350000
comprehension	0.000203
efforts	0.000203
-LRB- for	0.018970
sentence .	0.145833
Note that	0.777778
that they	0.024823
answer .	0.233333
U.S.	0.000203
respect	0.000203
cases ,	0.388889
dictionary	0.000203
, even	0.003930
widely used	0.875000
of summarization	0.007130
to find	0.010624
choice	0.000232
in NLP	0.014981
makes	0.000232
and not	0.011561
order to	0.571429
length	0.000232
web	0.000232
essentially	0.000232
can also	0.044199
domains	0.000232
-LRB- such	0.021680
French	0.000232
into the	0.102564
of research	0.007130
in an	0.014981
speaking	0.000232
among	0.000232
through	0.000232
<s> More	0.006149
% of	0.205128
<s> Such	0.006149
the complexity	0.005536
Recognition	0.000232
Research	0.000232
short	0.000232
the summary	0.005536
<s> Systems	0.006149
the Penn	0.005536
, because	0.004492
articles	0.000232
, with	0.004492
of machine	0.007130
questions ,	0.307692
the case	0.005536
commonly	0.000232
the other	0.005536
values	0.000232
vocabulary	0.000232
contrast	0.000232
sense	0.000232
is usually	0.016260
recent	0.000232
the sentences	0.005536
used ,	0.070796
are also	0.033195
function	0.000232
variety	0.000232
depends	0.000232
and can	0.011561
together	0.000232
in which	0.014981
referred	0.000232
the input	0.005536
in many	0.014981
, speech	0.004492
reference	0.000232
reading	0.000232
Although	0.000232
funding	0.000232
Markov model	0.444444
neural networks	0.533333
HMMs	0.000232
ambiguity	0.000232
target language	0.727273
kind of	0.727273
end	0.000232
Such	0.000232
. -RRB-	0.500000
of its	0.007130
polarity	0.000232
<s> If	0.006149
word .	0.133333
, they	0.004492
variety of	1.000000
&	0.000232
topic	0.000232
easier	0.000232
series	0.000232
, including	0.004492
languages .	0.160000
hidden	0.000232
about the	0.200000
around	0.000232
, most	0.004492
sentences in	0.105263
negative	0.000232
issue	0.000232
complexity of	0.666667
databases	0.000232
discourse analysis	0.222222
subject	0.000232
unsupervised	0.000232
sentences ,	0.105263
<s> To	0.006149
text in	0.050314
linguistics ,	0.400000
translation ,	0.108108
interaction	0.000232
containing	0.000232
the Brown	0.005536
-RRB- ;	0.022535
are used	0.033195
which the	0.057971
stochastic	0.000232
a large	0.009816
as in	0.027875
more complex	0.084211
John	0.000232
quite	0.000232
included	0.000232
meaningful	0.000232
rates	0.000232
online	0.000232
the late	0.005536
statistics	0.000232
intelligence	0.000232
problem of	0.181818
a summary	0.009816
10	0.000232
main	0.000232
list of	0.727273
further	0.000232
type of	0.571429
sentences .	0.105263
that of	0.028369
noise	0.000232
of ``	0.007130
referred to	1.000000
He	0.000232
ways	0.000232
far	0.000232
allows	0.000232
Japanese	0.000232
widely	0.000232
-LRB- ``	0.021680
the language	0.005536
the word	0.005536
-LRB- the	0.021680
sequence	0.000232
book	0.000232
metrics	0.000261
vertices	0.000261
small	0.000261
Web	0.000261
should be	0.473684
Penn	0.000261
popular	0.000261
To	0.000261
wave	0.000261
used by	0.079646
etc. .	0.409091
documents ,	0.236842
natural languages	0.120000
Statistical	0.000261
% .	0.230769
is ,	0.018293
proposed	0.000261
system is	0.096774
processing ,	0.166667
Turney	0.000261
successful	0.000261
Harris	0.000261
University	0.000261
nouns	0.000261
task of	0.214286
-RRB- :	0.025352
better	0.000261
determine the	0.391304
whole	0.000261
categories	0.000261
the target	0.006228
recognize	0.000261
instance ,	0.642857
tagger	0.000261
'' is	0.048387
real	0.000261
OCR technology	0.183673
would be	0.169811
<s> There	0.006918
users	0.000261
represent	0.000261
late	0.000261
recognition of	0.074380
significant	0.000261
to create	0.011952
this is	0.098901
the problem	0.006228
Note	0.000261
<s> Note	0.006918
=	0.000261
formal	0.000261
segment	0.000261
'' -LRB-	0.048387
highly	0.000261
1980s	0.000261
on some	0.042453
help	0.000261
, some	0.005053
computers	0.000261
recognition is	0.074380
Machine	0.000261
, especially	0.005053
parse	0.000261
to improve	0.011952
More	0.000261
sequences	0.000261
considered	0.000261
or the	0.040541
Natural language	0.692308
United	0.000261
the grammar	0.006228
continued	0.000261
produced	0.000261
Automatic	0.000261
typical	0.000261
pollen levels	0.692308
ELIZA	0.000261
ratings	0.000261
etc. -RRB-	0.409091
will be	0.257143
final	0.000261
just	0.000261
a single	0.011043
and other	0.013006
lexicon	0.000261
easily	0.000261
segmentation is	0.272727
writing	0.000261
question answering	0.214286
? ''	0.750000
Speech recognition	0.290323
Evaluation	0.000261
generation	0.000261
Given a	0.714286
to use	0.013280
: Given	0.098039
letters	0.000290
test	0.000290
phrase	0.000290
of which	0.008913
problem .	0.227273
necessary	0.000290
way to	0.416667
task .	0.238095
later	0.000290
researchers	0.000290
decisions	0.000290
who	0.000290
thus	0.000290
in this	0.018727
take	0.000290
expression	0.000290
known as	0.384615
science	0.000290
if the	0.357143
computational	0.000290
training data	0.357143
the speech	0.006920
-LRB- or	0.027100
since	0.000290
during	0.000290
is also	0.020325
focused on	0.909091
, e.g.	0.005615
performed	0.000290
recognition systems	0.082645
speech .	0.065789
need to	0.476190
to have	0.013280
words in	0.091743
data ,	0.129870
disambiguation	0.000290
contains	0.000290
system ,	0.107527
, if	0.005615
words are	0.091743
reader	0.000290
seen	0.000290
, an	0.005615
the meaning	0.006920
either	0.000290
a system	0.012270
limited	0.000290
though	0.000290
achieved	0.000290
the original	0.006920
second	0.000290
using a	0.169492
right	0.000290
is an	0.020325
involves	0.000290
does	0.000290
early	0.000290
database	0.000290
quality	0.000290
to produce	0.013280
similarity	0.000290
systems .	0.089286
needs	0.000290
ones	0.000290
, using	0.005615
If	0.000290
separate	0.000290
, there	0.006176
time ,	0.333333
paper	0.000318
artificial	0.000318
interest	0.000318
programs	0.000318
boundaries	0.000318
is often	0.022358
measure	0.000318
a word	0.013497
list	0.000318
kind	0.000318
keyphrases .	0.314286
character recognition	0.500000
of discourse	0.009804
a very	0.013497
question ,	0.261905
corpora	0.000318
, however	0.006176
focused	0.000318
context-free	0.000318
a human	0.013497
search	0.000318
What	0.000318
language .	0.074324
<s> An	0.008455
summary .	0.261905
are the	0.045643
rate	0.000318
, then	0.006176
-LRB- i.e.	0.029810
languages ,	0.220000
speech ,	0.072368
fact	0.000318
perform	0.000318
to determine	0.014608
probabilities	0.000318
system .	0.118280
commercial	0.000318
-RRB- is	0.030986
syntax	0.000318
difficult to	0.392857
translation of	0.148649
result	0.000318
grammatical	0.000318
of these	0.009804
target	0.000318
There	0.000318
area	0.000318
<s> Many	0.008455
applied to	0.733333
generally	0.000318
Thus ,	0.916667
and to	0.015896
sets	0.000318
a person	0.013497
done	0.000318
of this	0.009804
the process	0.007612
printed	0.000347
however ,	0.923077
error	0.000347
keyphrase extraction	0.631579
is that	0.024390
development	0.000347
<s> Thus	0.009224
Many	0.000347
-LRB- see	0.032520
answers	0.000347
a given	0.014724
identify	0.000347
individual	0.000347
field of	0.444444
process of	0.333333
Main	0.000347
not be	0.107143
Systems	0.000347
vs.	0.000347
after	0.000347
from a	0.115385
the source	0.008304
types of	0.857143
answering	0.000347
unigrams	0.000347
simply	0.000347
ambiguous	0.000347
complexity	0.000347
humans	0.000347
analysis of	0.184615
major	0.000347
Brown Corpus	0.857143
less	0.000347
Main article	1.000000
structure	0.000347
relations	0.000347
contain	0.000347
LexRank	0.000347
content	0.000347
, so	0.006738
Language	0.000347
<s> One	0.009224
others	0.000347
Thus	0.000347
over	0.000347
which are	0.086957
his	0.000347
learn	0.000376
sometimes	0.000376
One	0.000376
well as	0.464286
now	0.000376
lexical	0.000376
some of	0.156627
basic	0.000376
-LRB- citation	0.035230
which is	0.094203
however	0.000376
where the	0.371429
news	0.000376
without	0.000376
sentiment analysis	0.520000
that can	0.046099
Another	0.000376
parsers	0.000376
be a	0.054852
original	0.000376
of an	0.011586
above	0.000376
voice	0.000376
graph	0.000376
<s> Another	0.009992
verb	0.000376
another	0.000376
citation needed	1.000000
terms	0.000376
'' and	0.069892
improve	0.000376
no	0.000376
theory	0.000376
article :	0.448276
feature	0.000376
project	0.000376
the best	0.008997
, to	0.007299
, is	0.007299
have a	0.125000
'' .	0.069892
citation	0.000376
as an	0.045296
is used	0.026423
Natural	0.000376
pollen	0.000376
whether	0.000376
syntactic	0.000376
systems are	0.116071
multiple	0.000376
you	0.000376
do not	0.500000
POS	0.000376
particular	0.000376
good	0.000376
find	0.000376
needed -RRB-	0.619048
had	0.000405
spoken	0.000405
Brown	0.000405
hand	0.000405
as ``	0.048780
rather than	0.875000
application	0.000405
including	0.000405
a text	0.017178
noun	0.000405
a sentence	0.017178
there is	0.350000
grammars	0.000405
state	0.000405
out	0.000405
language understanding	0.094595
TextRank	0.000405
uses	0.000405
user	0.000405
instance	0.000405
type	0.000405
recognition ,	0.115702
, while	0.007861
<s> As	0.010761
types	0.000405
found	0.000405
standard	0.000405
the answer	0.009689
networks	0.000405
single	0.000405
a set	0.017178
social	0.000405
In the	0.133333
order	0.000405
as well	0.048780
semantics	0.000405
Given	0.000405
useful	0.000405
one of	0.215385
must	0.000405
following	0.000434
world	0.000434
that are	0.053191
similar to	0.555556
still	0.000434
the use	0.010381
, where	0.008422
neural	0.000434
used for	0.132743
words ,	0.137615
a computer	0.018405
at the	0.220588
part-of-speech	0.000434
<s> Speech	0.011530
applied	0.000434
the first	0.010381
can not	0.082873
of words	0.013369
step	0.000434
sounds	0.000434
there are	0.375000
generated	0.000434
related	0.000434
correct	0.000434
especially	0.000434
<s> These	0.012298
parts	0.000463
likely	0.000463
requires	0.000463
Corpus	0.000463
rather	0.000463
larger	0.000463
people	0.000463
`	0.000463
could	0.000463
words .	0.146789
<s> Some	0.012298
the question	0.011073
phrases	0.000463
parser	0.000463
appear	0.000463
linguistic	0.000463
supervised	0.000463
parts of	1.000000
important	0.000463
-	0.000463
made	0.000463
method	0.000463
An	0.000463
able	0.000463
able to	1.000000
that is	0.056738
characters	0.000463
and a	0.023121
tag	0.000463
These	0.000492
case	0.000492
problems	0.000492
create	0.000492
, we	0.009545
texts	0.000492
the field	0.011765
available	0.000492
This is	0.269841
classification	0.000492
data .	0.220779
into a	0.217949
being	0.000521
speaker	0.000521
performance	0.000521
cases	0.000521
best	0.000521
high	0.000521
Markov	0.000521
generate	0.000521
by a	0.102857
typically	0.000521
within	0.000521
term	0.000521
'' -RRB-	0.096774
As	0.000521
for example	0.064982
various	0.000521
called	0.000521
or a	0.085586
'	0.000550
representation	0.000550
is to	0.038618
them	0.000550
be used	0.080169
keyphrase	0.000550
person	0.000550
should	0.000550
machine learning	0.240506
is not	0.038618
<s> -LRB-	0.014604
i.e.	0.000550
the most	0.013149
sound	0.000579
level	0.000579
see	0.000579
-RRB- and	0.056338
, etc.	0.011230
form	0.000579
and ``	0.028902
linguistics	0.000579
domain	0.000579
make	0.000579
a number	0.024540
with a	0.109290
the system	0.013841
while	0.000579
needed	0.000608
years	0.000608
QA	0.000608
semantic	0.000608
automatically	0.000608
use of	0.291667
results	0.000608
specific	0.000608
Some	0.000608
may be	0.403846
need	0.000608
NLG	0.000608
much	0.000637
technology	0.000637
produce	0.000637
of natural	0.019608
etc.	0.000637
, for	0.012353
levels	0.000637
those	0.000637
part of	0.814815
several	0.000637
program	0.000637
up	0.000637
the same	0.015225
character	0.000637
general	0.000637
from the	0.211538
require	0.000637
used to	0.194690
techniques	0.000666
It is	0.605263
on a	0.108491
meaning	0.000666
that the	0.081560
large	0.000666
automatic	0.000666
used in	0.203540
, as	0.012914
determine	0.000666
source	0.000695
possible	0.000695
new	0.000695
of text	0.021390
examples	0.000695
complex	0.000695
way	0.000695
, it	0.013476
?	0.000695
given	0.000695
it is	0.205128
work	0.000695
, ``	0.014037
sentiment	0.000724
applications	0.000724
same	0.000724
tagging	0.000724
--	0.000724
common	0.000724
output	0.000753
simple	0.000753
e.g. ,	0.464286
questions	0.000753
do	0.000753
known	0.000753
developed	0.000753
written	0.000753
have been	0.250000
might	0.000753
models	0.000753
features	0.000753
the text	0.017993
similar	0.000782
knowledge	0.000782
text .	0.169811
include	0.000782
by the	0.154286
field	0.000782
software	0.000782
part	0.000782
as the	0.094077
even	0.000782
algorithm	0.000811
approaches	0.000811
like	0.000811
set of	0.717949
if	0.000811
difficult	0.000811
to a	0.037185
well	0.000811
has been	0.333333
training	0.000811
parsing	0.000811
with the	0.153005
article	0.000840
for a	0.104693
two	0.000840
how	0.000840
text ,	0.188679
model	0.000869
so	0.000869
'' ,	0.161290
answer	0.000869
because	0.000869
corpus	0.000897
extraction	0.000897
for the	0.111913
Speech	0.000897
any	0.000897
accuracy	0.000897
both	0.000897
However ,	0.864865
tasks	0.000926
usually	0.000926
what	0.000926
, or	0.018529
language processing	0.222973
first	0.000955
segmentation	0.000955
understanding	0.000955
statistical	0.000955
context	0.000955
time	0.000955
<s> It	0.026134
, in	0.019090
their	0.000984
as a	0.118467
when	0.001013
then	0.001013
keyphrases	0.001013
algorithms	0.001013
, such	0.019652
approach	0.001013
where	0.001013
its	0.001013
will	0.001013
process	0.001042
document	0.001042
number of	0.837209
discourse	0.001042
English	0.001071
<s> However	0.028440
grammar	0.001071
However	0.001071
For example	0.622951
documents	0.001100
only	0.001100
-LRB- e.g.	0.102981
It	0.001100
set	0.001129
between	0.001129
machine translation	0.493671
%	0.001129
there	0.001158
they	0.001158
about	0.001158
very	0.001187
were	0.001187
and the	0.059249
input	0.001187
research	0.001216
task	0.001216
question	0.001216
summary	0.001216
these	0.001216
summaries	0.001245
number	0.001245
rules	0.001245
to be	0.057105
all	0.001245
learning	0.001245
methods	0.001274
problem	0.001274
<s> A	0.033820
computer	0.001274
often	0.001274
than	0.001303
is the	0.091463
we	0.001303
each	0.001303
based on	0.833333
information	0.001332
human	0.001332
of speech	0.040998
;	0.001361
NLP	0.001361
, a	0.026951
, but	0.026951
sentence	0.001390
OCR	0.001419
different	0.001419
languages	0.001448
summarization	0.001448
A	0.001448
in a	0.093633
's	0.001477
many	0.001505
may	0.001505
<s> This	0.039969
would	0.001534
evaluation	0.001563
is a	0.109756
processing	0.001563
based	0.001563
example ,	0.666667
, which	0.031443
e.g.	0.001621
natural language	0.760000
<s> For	0.043812
most	0.001679
using	0.001708
word	0.001737
For	0.001766
This	0.001824
speech recognition	0.421053
one	0.001882
on the	0.306604
analysis	0.001882
at	0.001969
but	0.001969
been	0.001969
also	0.001998
other	0.002027
use	0.002084
translation	0.002142
natural	0.002171
sentences	0.002200
data	0.002229
to the	0.102258
was	0.002229
into	0.002258
-RRB- ,	0.219718
machine	0.002287
example	0.002345
some	0.002403
has	0.002432
such as	0.731707
can be	0.502762
this	0.002635
of a	0.081996
system	0.002692
more	0.002750
<s> In	0.074558
-RRB- .	0.284507
:	0.002953
, the	0.058394
have	0.003011
from	0.003011
In	0.003040
words	0.003156
systems	0.003243
not	0.003243
used	0.003271
it	0.003387
recognition	0.003503
such	0.003561
an	0.003822
which	0.003995
in the	0.260300
<s> The	0.112221
language	0.004285
speech	0.004401
text	0.004603
by	0.005066
can	0.005240
with	0.005298
``	0.005472
, and	0.106120
The	0.005559
''	0.005617
of the	0.173797
on	0.006138
or	0.006427
be	0.006861
are	0.006977
for	0.008019
that	0.008164
as	0.008309
-LRB-	0.010683
-RRB-	0.010683
is	0.014244
in	0.015460
and	0.020034
to	0.021800
a	0.023595
of	0.032483
.	0.037115
the	0.041834
,	0.051562
